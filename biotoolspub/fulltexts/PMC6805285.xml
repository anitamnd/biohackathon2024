<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Hum Genomics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Hum. Genomics</journal-id>
    <journal-title-group>
      <journal-title>Human Genomics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1473-9542</issn>
    <issn pub-type="epub">1479-7364</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6805285</article-id>
    <article-id pub-id-type="publisher-id">227</article-id>
    <article-id pub-id-type="doi">10.1186/s40246-019-0227-1</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Using Apache Spark on genome assembly for scalable overlap-graph reduction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Paul</surname>
          <given-names>Alexander J.</given-names>
        </name>
        <address>
          <email>alex.paul@slu.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lawrence</surname>
          <given-names>Dylan</given-names>
        </name>
        <address>
          <email>dylan.lawrence@wustl.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Song</surname>
          <given-names>Myoungkyu</given-names>
        </name>
        <address>
          <email>myoungkyu@unomaha.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lim</surname>
          <given-names>Seung-Hwan</given-names>
        </name>
        <address>
          <email>lims1@ornl.gov</email>
        </address>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pan</surname>
          <given-names>Chongle</given-names>
        </name>
        <address>
          <email>cpan@ou.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Ahn</surname>
          <given-names>Tae-Hyuk</given-names>
        </name>
        <address>
          <email>ted.ahn@slu.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 9342</institution-id><institution-id institution-id-type="GRID">grid.262962.b</institution-id><institution>Bioinformatics and Computational Biology Program, Saint Louis University, </institution></institution-wrap>St. Louis, MO USA </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2355 7002</institution-id><institution-id institution-id-type="GRID">grid.4367.6</institution-id><institution>Computational and Systems Biology Program, Washington University in St. Louis, </institution></institution-wrap>St. Louis, MO USA </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0775 5412</institution-id><institution-id institution-id-type="GRID">grid.266815.e</institution-id><institution>Department of Computer Science, University of Nebraska at Omaha, </institution></institution-wrap>Omaha, NE USA </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 0446 2659</institution-id><institution-id institution-id-type="GRID">grid.135519.a</institution-id><institution>National Center for Computational Sciences, Oak Ridge National Laboratory, </institution></institution-wrap>Oak Ridge, TN USA </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 0447 0018</institution-id><institution-id institution-id-type="GRID">grid.266900.b</institution-id><institution>School of Computer Science, University of Oklahoma, </institution></institution-wrap>Norman, OK USA </aff>
      <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 9342</institution-id><institution-id institution-id-type="GRID">grid.262962.b</institution-id><institution>Department of Computer Science, Saint Louis University, </institution></institution-wrap>St. Louis, MO USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>22</day>
      <month>10</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>22</day>
      <month>10</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>13</volume>
    <issue>Suppl 1</issue>
    <issue-sponsor>Publication of this supplement has not been supported by sponsorship. Information about the source of funding for publication charges can be found in the individual articles. The articles have undergone the journal's standard peer review process for supplements. The Supplement Editor declares no competing interests.</issue-sponsor>
    <elocation-id>48</elocation-id>
    <permissions>
      <copyright-statement>© Paul et al. 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p>De novo genome assembly is a technique that builds the genome of a specimen using overlaps of genomic fragments without additional work with reference sequence. Sequence fragments (called reads) are assembled as contigs and scaffolds by the overlaps. The quality of the de novo assembly depends on the length and continuity of the assembly. To enable faster and more accurate assembly of species, existing sequencing techniques have been proposed, for example, high-throughput next-generation sequencing and long-reads-producing third-generation sequencing. However, these techniques require a large amounts of computer memory when very huge-size overlap graphs are resolved. Also, it is challenging for parallel computation.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>To address the limitations, we propose an innovative algorithmic approach, called <bold>S</bold>calable <bold>O</bold>verlap-graph <bold>R</bold>eduction <bold>A</bold>lgorithms (SORA). SORA is an algorithm package that performs string graph reduction algorithms by Apache Spark. The SORA’s implementations are designed to execute de novo genome assembly on either a single machine or a distributed computing platform. SORA efficiently compacts the number of edges on enormous graphing paths by adapting scalable features of graph processing libraries provided by Apache Spark, GraphX and GraphFrames.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p>We shared the algorithms and the experimental results at our project website, <ext-link ext-link-type="uri" xlink:href="https://github.com/BioHPC/SORA">https://github.com/BioHPC/SORA</ext-link>. We evaluated SORA with the human genome samples. First, it processed a nearly one billion edge graph on a distributed cloud cluster. Second, it processed mid-to-small size graphs on a single workstation within a short time frame. Overall, SORA achieved the linear-scaling simulations for the increased computing instances.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Graph reduction</kwd>
      <kwd>Apache spark</kwd>
      <kwd>Genome assembly</kwd>
      <kwd>Cloud computing</kwd>
      <kwd>Overlap-layout-consensus</kwd>
    </kwd-group>
    <conference xlink:href="http://orienta.ugr.es/bibm2018/">
      <conf-name>IEEE International Conference on Bioinformatics and Biomedicine 2018</conf-name>
      <conf-loc>Madrid, Spain</conf-loc>
      <conf-date>3-6 December 2018</conf-date>
    </conference>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p>Next-generation sequencing (NGS) refers high-throughput and in-parallel DNA sequencing technologies developed around 2007 after the Sanger DNA sequencing method first emerged in 1977 [<xref ref-type="bibr" rid="CR1">1</xref>]. NGS technologies are different from the long dominated Sanger method in that NGS provides massive sequencing analysis with being extremely high-throughput from multiple samples at much reduced cost. Following the introduction of NGS techniques [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>], prodigious changes have occurred in the biological and biomedical sciences, specifically in genomics [<xref ref-type="bibr" rid="CR3">3</xref>]. With reductions in sequencing cost and increased throughput, read length, and read accuracy NGS has drastically recast DNA sequencing; however, NGS requires a significant body of sequencing data for analysis. As reported by previous studies, NGS faces several limitations [<xref ref-type="bibr" rid="CR4">4</xref>]. For example, in comparison to the sequence length generated by first-generation Sanger sequencing (500 ∼1000bp), fragmented DNA sequences (i.e. reads) are generally shorter (50 ∼300bp). Recently developed third-generation sequencing techniques such as Pacific Bio-sciences (PacBio) and Oxford NanoPore provide much longer reads (up to 2 Mbp) to the considerable benefit of the assembly. However, NGS remains dominant due to its low cost and error rate.</p>
    <p>Two different types are generally used for genome assembly: de novo assembly and reference-based assembly. De novo assembly is the process of finding overlaps and merging reads to complete genome sequence that is inherently challenging but essential to bioinformatics research [<xref ref-type="bibr" rid="CR5">5</xref>]. Reference-based assembly can construct a new specimen genome with help of similar assembled genome. Third-generation sequencing can produce reads having nearly similar size of bacterial genomes that usually are few Mbp long, but cannot generate full sequences of eukaryotic genomes up to several Gbp of length. For example, the haploid human genome size is over 3 Gbp and the Genome Reference Consortium Human Build 38 patch release 13 (GRCh38.p13) is the most recently released human genome assembly [<xref ref-type="bibr" rid="CR6">6</xref>].</p>
    <p>The elaboration of genome assembly stems from multiple issues including heterozygosity and ploidy, affected mainly by the length and numbers of the reads. To assemble such large datasets, most de novo assembly programs are highly sensitive to the changes in time and space complexity. To account for both sensitivity and speed, most de novo genome assemblers commonly employed two assembly paradigms. One is overlap-layout-consensus (OLC) algorithm and the other is de Bruijin graph (DBG) [<xref ref-type="bibr" rid="CR7">7</xref>]. During the first-generation Sanger sequencing technique era, OLC approaches, i.e., Celera [<xref ref-type="bibr" rid="CR8">8</xref>], reached accuracy adequate to accommodate the low sequencing depth and longer reads output. Newbler [<xref ref-type="bibr" rid="CR9">9</xref>] that was designed for second-generation Roche / 454 Life Sciences sequences also adapted the OLC approach. The majority of OLC-based genome assemblies produce the sequence assembly of whole, complex genomes using below steps. First, finding <bold>O</bold>verlaps between fragments or among all reads by using a graph model. Second, using the overlay-graph to construct a stretched <bold>L</bold>ayout. Third, establishing the most probable <bold>C</bold>onsensus sequence.</p>
    <p>Various alternate approaches using DBG concept were proposed to assemble a genome with noticeably high-throughput and short reads from NGS technologies. Under NGS, DBG-based assemblers have been commonly employed to degrade reads into <italic>k</italic>-mers where a <italic>k</italic>-mer is a subsequence of a fixed-length, <italic>k</italic>. Various DBG-based assemblers including AbySS [<xref ref-type="bibr" rid="CR10">10</xref>], Velvet [<xref ref-type="bibr" rid="CR11">11</xref>] and SOAPdenovo [<xref ref-type="bibr" rid="CR12">12</xref>] utilize memory-efficient DBG traversal to lessen the memory footprint of assembly including an efficient identification of redundant <italic>k</italic>-mers. As opposed to the less computationally efficient (e.g. costly execution time and memory consumption per assembler) OLC-based approaches, most DBG-based assemblers reduce dependency on sequencing depth using a genome-sized graph at the cost of a larger memory overhead. The DBG-based approach achieves comparably fast overlapping computation for high-throughput short reads, while the OLC-based approach performs more advantageously for longer reads. Most of the DBG-based techniques adapt hashing algorithms that have a chance to acquire higher relative error rates but usually perform faster than the OLC-based approaches [<xref ref-type="bibr" rid="CR13">13</xref>].</p>
    <p>Lately, probabilistic algorithms utilizing the MinHash technique have been developed to efficiently identify multiple overlaps between long, noisy reads from third-generation sequencing data [<xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR15">15</xref>]. Canu, as a successor of the Celera assembler, was designed for long and noisy single-molecule sequences [<xref ref-type="bibr" rid="CR15">15</xref>]. However, the computationally expensive overlap graphs produced by the assembly of raw or processed sequences must be simplified or reduced. Several MPI-based scalable assemblies were proposed previously; including Abyss [<xref ref-type="bibr" rid="CR10">10</xref>], Ray [<xref ref-type="bibr" rid="CR16">16</xref>], and SWAP2-Assembler [<xref ref-type="bibr" rid="CR17">17</xref>]. Apache Spark serves an a general purpose and open source and distribution computing engine for cluster based computation with pre-build libraries such as GraphX, MLlib (Machine Learning library), Spark Steaming, and so on [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>]. Utilizing data intensive cluster computation, Apache Spark processes large scale data quickly though efficient in-memory computation. Unlike the Apache Hadoop, a conventional cloud-based distributed processing framework, Spark can accelerate computational performance by up to 100 times compared to the Hadoop especially for interactive jobs and iterative analytics by cacheing datasets in memory. MPI is a popular framework for high performance parallel computing, but Spark provides an in-memory implementation of MapReduce that is widely used in the big data industry.</p>
    <p>Due to the extensive memory and processing time required, the analysis of reads with significant overlap is not easily parallelized. To address these challenges, we propose a novel OLC-based algorithmic approaches for genome assembly, called <bold>S</bold>calable <bold>O</bold>verlap-graph <bold>R</bold>eduction <bold>A</bold>lgorithms (SORA) by leveraging Apache Spark especially with the GraphX and GraphFrames libraries. Using the computing engine of Apache Spark, SORA accelerates the graph reductions for genome assemblies by compacting repetitive information of sequence overlaps either in the cloud, by a local cluster system, or using a stand-alone workstation. SORA was developed as an open-source framework to provide pre-built modules for graph reduction with useful scripts for genome assembly including sequence overlap finding using BBtools (<ext-link ext-link-type="uri" xlink:href="https://sourceforge.net/projects/bbmap/">https://sourceforge.net/projects/bbmap/</ext-link>). SORA executes genome assembly through the use of three overlap-graph reduction algorithms: <italic>Transitive Edge Reduction</italic>, <italic>Dead-End Removal</italic>, and <italic>Composite Edge Contraction</italic>. It presents a short turnaround time when processing a large-scale dataset consisting of a graph with nearly one billion edges on a distributed cloud computing cluster or when processing a smaller 8 million edge graph dataset on a local computing cluster. Spaler [<xref ref-type="bibr" rid="CR20">20</xref>] is another GraphX and Apache Spark based de novo genome assembler utilizing DBG contraction and construction, but SORA is, to our knowledge, the first proposed Spark-based scalable assembler utilizing the OLC approach. Our previous studies [<xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR22">22</xref>] were extensively extended in this paper. In detail, two primary goals are demonstrated in our benchmark results; (1) SORA actualizes a cloud scalable de novo genome assembler through leveraging Apache Spark graph processing libraries; (2) SORAdemonstrates the applicability of cloud computing infrastructure employing graphing algorithms to genome assembly and alternative biological applications. The increasing popularity of Spark among computational researchers has also influenced our decision to use Spark [<xref ref-type="bibr" rid="CR23">23</xref>].</p>
    <p>The remainder of the article is organized as follows. “<xref rid="Sec2" ref-type="sec">Methods</xref>” section describes the OLC algorithm and Apache Spark, then presents SORA’s algorithms and the implementation in detail. “<xref rid="Sec9" ref-type="sec">Results</xref>” section describes various experiments conducted to evaluate the scalability and usability of SORA using large and small scale datasets on cloud followed by Discussion and Conclusions.</p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <sec id="Sec3">
      <title>Overlap-Layout-Consensus</title>
      <p>The Overlap process, the initial step of OLC, focuses on finding overlaps of all reads using all-to-all pairwise alignments. To efficiently find overlaps between reads, the prefix/suffix technique is commonly used for overlap-based genome assembly [<xref ref-type="bibr" rid="CR24">24</xref>]. This hash table approach allows a nearly constant time search when reads are small of all reads by their prefixes and suffixes. To efficiently search all overlapping reads with a read <italic>r</italic>, each proper substring of minimum overlap in read <italic>r</italic> is found in the hash table, and every retrieved read is compared to the read <italic>r</italic>. Therefore, an overlap-graph that places reads as nodes and assigns edges between nodes whose corresponding reads overlap exceeds a specified cutoff is constructed by the Overlap step. As a result, the number of nodes will be proportionate to the number of unique reads, while the number of overlaps between reads will determine the number of edges.</p>
      <p>During the Layout and Consensus steps, the manufactured overlap-graph is stretched and reduced into the most probable contiguous sequences, labeled, contigs. The Layout step acts as a Hamiltonian path problem where each read in the graph must be visited to generate longer sequences. This is a computationally challenging problem caused by a large number of unnecessary edges that are mostly produced by repeats or sequencing errors. As the final step, Consensus considers the alignment of all original reads onto the draft contigs from the Layout step and employs a straightforward majority-based consensus to improve the draft sequences. To limit extraneous edges in the graph, SORA utilizes three overlaps-graph reduction algorithms: Transitive Edge Reduction (TER), Composite Edge Contraction (CEC), and Dead-End Removal (DER) [<xref ref-type="bibr" rid="CR25">25</xref>].</p>
    </sec>
    <sec id="Sec4">
      <title>Apache Spark</title>
      <p>Apache Spark is a cluster-based engine that processes very large-scale datasets. As opposed to Hadoop’s on-disk data processing, Spark’s incorporated batching system handles input data streams in-memory, separates the data into batches for each node in a cluster, and produces the final stream of results in batches. For fast and scalable distributed graph-parallel computation, Apache Spark provides GraphX library that contributes a set of fundamental operations and graph abstraction models in parallel. This permits SORA to manipulate and execute queries on graphs represented as database entries. The implementation and design in SORA leverages an assortment of computational operations in GraphX for construction, graph reading, transformation, and computation. GraphX extends Spark’s Resilient Distributed Dataset (RDD) that embodies a read-only collection of objects that are partitioned over machines. If any partition of an RDD is lost, Spark rebuilds it by applying the filter on the corresponding block of the file in the file system. An RDD can be cached in memory across machines and reused in multiple MapReduce-like parallel operations.</p>
      <p>To accommodate abstraction for manipulating structured data (e.g., tables or two-dimensional arrays), SORA uses a graph processing library called GraphFrames that is built on Spark’s DataFrame implementation to process real-time exploration of large-volume datasets. SORA leverages GraphFrames to execute pattern matching and relational queries in tandem with GraphX to speed up the most common join in iterative graph processing tasks. SORA was implemented in Scala, but the portable design of the core components allows for adaptive use with other programming languages like Java or Python with lower development costs.</p>
    </sec>
    <sec id="Sec5">
      <title>Overlap-Graph Reduction Algorithms</title>
      <p>This section illustrates SORA’s adaptation of three overlap-graph reduction algorithms to the distributed cloud computing cluster utilizing Spark. Figure <xref rid="Fig1" ref-type="fig">1</xref> represents the synopsis of each workflow as to how each algorithm computes overlap-graph reduction.
<fig id="Fig1"><label>Fig. 1</label><caption><p>The overlap-graph reduction algorithms. <bold>a</bold> Transitive Edge Reduction (TER), <bold>b</bold> Dead-End Removal (DER), and <bold>c</bold> Composite Edge Contraction (CEC)</p></caption><graphic xlink:href="40246_2019_227_Fig1_HTML" id="MO1"/></fig></p>
      <sec id="Sec6">
        <title>Transitive Edge Reduction</title>
        <p>Transitive edge reduction is a method of reducing complexity in graphs and helps provide clearer contigs by eliminating extraneous paths in the graph. After finding overlaps, the initial overlap graph contains many unnecessary edges. For example, say read <italic>a</italic> overlaps with read <italic>b</italic>, which overlaps with read <italic>c</italic> subsequently, which results in a shorter overlap length between read <italic>a</italic> and read <italic>c</italic>. Then, the string graph edge <italic>a</italic>→<italic>c</italic> is unnecessary because one can use the edges <italic>a</italic>→<italic>b</italic>→<italic>c</italic> without <italic>a</italic>→<italic>c</italic> to obtain the same sequence. The edge <italic>a</italic>→<italic>c</italic> is then identified as a transitive edge and is deleted. Removing all transitive edges significantly simplifies the overlap graph without losing information for genome assembly.</p>
        <p>
          <graphic position="anchor" xlink:href="40246_2019_227_Figa_HTML" id="MO2"/>
        </p>
        <p>
          <graphic position="anchor" xlink:href="40246_2019_227_Figb_HTML" id="MO3"/>
        </p>
        <p>The general transitive edge reduction algorithm takes <italic>O</italic>(<italic>E</italic><italic>D</italic>) time where <italic>E</italic> is the number of edges and <italic>D</italic> is the maximum out degree for the read, but Myer proposed a linear <italic>O</italic>(<italic>E</italic>) expected time transitive reduction algorithm shown in Algorithm 1 [<xref ref-type="bibr" rid="CR25">25</xref>]. After the initial marking of every vertex and all related edges in the graph, each vertex is then investigated to find eliminable edges of the vertex using the marking strategies.</p>
        <p>In Algorithm 2 we use the GraphX library operators to implement the transitive edge reduction algorithm based on the graph-parallel abstraction. The GraphX library supports the graph-parallel computation APIs aggregateMessages(), outerJoinVertices(), mapTriplets(), subgraph(), sendToSrc(), and sendToDst(). After constructing the initial property graph from the edge properties, the aggregateMessages operator can compute the set of neighbors for each vertex and retrieve the edge properties including overlap length at the same time. The required set of neighbors can be joined with the graph using outerJoinVertices. After comparing overlap lengths of the edges for each vertex in parallel, the edges are marked as TRUE if the edges can be removed. The subgraph operator returns a new graph containing only the edges not marked for removal.</p>
      </sec>
      <sec id="Sec7">
        <title>Dead-End Removal</title>
        <p>Dead-End Removal (DER) eliminates short dead-ends or spurs from the graph, reduces erroneous reads, and decreases the graph complexity. The short dead-end paths are mostly caused by sequencing errors and false-positive joins of overlapping of chimeric sequences. Most assemblers identify the dead-ends by considering short length edges with low-depth coverage to be dead-ends. The DER algorithm iterates over all reads, then stamps the edges if the reads have only one incoming edge and the edges are short with low coverage.</p>
        <p>
          <graphic position="anchor" xlink:href="40246_2019_227_Figc_HTML" id="MO4"/>
        </p>
        <p>Algorithm 3 describes the DER algorithm based on the GraphX operators. Algorithm 3 takes as input the reduced graph that Algorithm 2 has produced as the output and executes the aggregateMessages operator to compute the number of edges going in and out of each vertex depending on the orientation of the edge. This information can be joined with the input reduced graph by using outerJoinVertices. In parallel, if the number of outgoing edges from a node is zero and the edge can be removed mark the edge TRUE. The subgraph operator returns a new graph with the edges marked TRUE removed.</p>
        <p>
          <graphic position="anchor" xlink:href="40246_2019_227_Figd_HTML" id="MO5"/>
        </p>
      </sec>
      <sec id="Sec8">
        <title>Composite Edge Contraction</title>
        <p>Composite Edge Contraction (CEC) reduces the computational complexity by processing larger volumes of data in the graph. Especially, CEC merges vertices guaranteed to process the graph without loss of information. In the case of Overlap-layout-consensus (OLC), a read is represented for branching to two additional reads which deviate from each other at least one nucleotide, both of which then overlap back to the same read. In contrast to OLC, the CEC algorithm simplifies the path analysis by removing redundancy and reducing complexity of the graph, considering only the contractible edges without loss of important information for the genome assembly. To simplify the overlap graph, a simple vertex, <italic>r</italic>, along with its in-arrow edge (<italic>u</italic>, <italic>r</italic>) and out-arrow edge (<italic>r</italic>,<italic>w</italic>), are replaced by a composite edge (<italic>u</italic>,<italic>w</italic>) in the overlap graph.</p>
        <p>Algorithm 4 describes the composite edge contraction by using the operators of the graph-parallel computations provided by GraphX and GraphFrames. After receiving the reduced graph from Algorithm 3, the operator aggregateMessages computes the number of edges going in and out of each vertex depending on the orientation of the edge. The result of a processed set of vertices and edges is integrated with the input reduced graph by using the operator outerJoinVertices. The operator mapTriplets is parallelized to investigate the edges of each adjacent vertex to determine whether the vertex only includes a pair of incoming and outgoing edges. It then marks the edge TRUE if they can be contracted. The subgraph operator returns a new graph with only the contractable edges.</p>
        <p>The operator connectedComponent identifies the connection relationship among contractible vertices and produces the vertex information with the vertex IDs for the connected contractible subgraphs. Given the contractible vertex information, the operator innerJoin performs an inner join between each contractible and internal vertex to produce a set of the new vertex properties, which is used in the operator aggregateUsingIndex to aggregate the contracted vertices ensuring consistency by joining the IDs among vertices. Then, the operator subgraph filters out the edges marked FALSE to remove the contractible edges from the original graph. Based on the refined vertex set, the operator outerJoinVertices generates the contracted edges, which parameterize the operator graph to construct a new reduced graph.</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec9" sec-type="results">
    <title>Results</title>
    <p>Figure <xref rid="Fig2" ref-type="fig">2</xref> shows a practical pipeline of genome assembly using SORA. In our experiments, we applied three overlap-graph reduction algorithms (Transitive Edge Reduction, Dead-End Removal, and Composite Edge Contraction) in SORA to three different types of benchmark datasets.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Overview of analysis pipeline using SORA. SORA pipeline for genome assembly</p></caption><graphic xlink:href="40246_2019_227_Fig2_HTML" id="MO6"/></fig></p>
    <sec id="Sec10">
      <title>Three Data Sets</title>
      <p>For the first experiment described in Section <xref rid="Sec11" ref-type="sec">6</xref>, we downloaded a metagenomics dataset from the Sequence Read Archive at the National Center for Biotechnology Information (NCBI) [<xref ref-type="bibr" rid="CR24">24</xref>]. The accession number is SRX200676. The metagenomics dataset is considerably large containing mixed DNA from 64 diverse bacterial and archaeal microorganisms. The combined DNA was sequenced using Illumina HiSeq [<xref ref-type="bibr" rid="CR26">26</xref>]. For the second experiment described in Section <xref rid="Sec16" ref-type="sec">6</xref>, we obtained a single genome dataset of <italic>Conyza canadensis</italic> (also known as horseweed) processed by the Illumina HiSeq sequencing system [<xref ref-type="bibr" rid="CR27">27</xref>]. For the third experiment described in Section <xref rid="Sec20" ref-type="sec">6</xref>, we downloaded a human genome dataset provided by the 1000 Genome Project data portal (ISGR: The International Genome Sample Resource <ext-link ext-link-type="uri" xlink:href="http://www.internationalgenome.org/">http://www.internationalgenome.org/</ext-link>). Sample ID is NA12878 (<ext-link ext-link-type="uri" xlink:href="http://www.internationalgenome.org/data-portal/sample/NA12878">http://www.internationalgenome.org/data-portal/sample/NA12878</ext-link>) and we downloaded 3 files of whole genome sequencing (WGS) from the European Bioinformatics Institute (EBI) (<ext-link ext-link-type="uri" xlink:href="ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR622/SRR622461/-SRR622461_1.fastq.gz,ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR622/SRR622461/-SRR622461_2.fastq.gz,ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR622/SRR622461/SRR622461.fastq.gz">ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR622/SRR622461/-SRR622461_1.fastq.gz,ftp: //ftp.sra.ebi.ac.uk/vol1/fastq/SRR622/SRR622461/-SRR622461_2.fastq.gz,ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR622/SRR622461/SRR622461.fastq.gz</ext-link>).</p>
    </sec>
    <sec id="Sec11">
      <title>Metagenomics Dataset Analysis</title>
      <p>We evaluated the scalability of SORA by applying the overlap-graph reduction algorithms to the metagenomics dataset that is extremely large to check the performance capability of SORA. In the experiment, we observed that SORA significantly reduced the number of reads in the metagenomics datasets, which consequently allows binning of the contigs to reconstruct genomic bins more quickly and efficiently. The benchmark has been performed on Amazon Web Service (AWS) Elastic Computing Cloud (EC2) with 15 virtual instances whether each instance (m4.xlarge) has 2.3 GHz Intel Xeon E5-2686 v4 (Broadwell) processors (4 vCPU) and 16 GB memory.</p>
      <sec id="Sec12">
        <title>Overlap Graph Construction</title>
        <p>The sequence dataset obtained from NCBI contains 109 million paired-end reads roughly and 0.4 million single-end reads with 100-bp read length. Sequence reads that are shorter than 60bp and containing multiple N character were removed using Sickle (<ext-link ext-link-type="uri" xlink:href="https://github.com/najoshi/sickle">https://github.com/najoshi/sickle</ext-link>). BBNorm (<ext-link ext-link-type="uri" xlink:href="https://sourceforge.net/projects/bbmap">https://sourceforge.net/projects/bbmap</ext-link>) was used for error correction with the default settings. These are the same techniques used for the OMEGA analysis [<xref ref-type="bibr" rid="CR24">24</xref>].</p>
      </sec>
      <sec id="Sec13">
        <title>Transitive Edge Reduction</title>
        <p>In the experiment with the metagenomics dataset, Transitive Edge Reduction (TER) algorithm performed a drastic reduction on the number of edges in the graph. In Table <xref rid="Tab1" ref-type="table">1</xref>, the reduction results of the TER algorithm were shown using three types of data size as quarter, half, and full data sets. Given the quarter dataset that contains over 217 million edges, the TER algorithm produced the reduced graph comprising 12.5 million edges with 94.24% reduction; given the full size dataset that initially contains 868 million edges, the TER algorithm made the reduced graph comprising of 57.4 million edges with 93.39% reduction.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>The overlap-graph reduction results with the metagenomics dataset</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Algorithm</th><th align="left">Size</th><th align="left">#EDGE (before)</th><th align="left">#EDGE (after)</th><th align="left">TIME</th></tr></thead><tbody><tr><td align="left">TER</td><td align="left">Quarter</td><td align="left">217,002,504</td><td align="left">12,482,946</td><td align="left">0.57</td></tr><tr><td align="left"/><td align="left">Half</td><td align="left">434,005,009</td><td align="left">23,818,401</td><td align="left">0.80</td></tr><tr><td align="left"/><td align="left">Full</td><td align="left">868,010,019</td><td align="left">57,363,515</td><td align="left">1.37</td></tr><tr><td align="left">DER-CEC</td><td align="left">Quarter</td><td align="left">12,482,946</td><td align="left">469,130</td><td align="left">0.13</td></tr><tr><td align="left"/><td align="left">Half</td><td align="left">23,818,401</td><td align="left">763,474</td><td align="left">0.23</td></tr><tr><td align="left"/><td align="left">Full</td><td align="left">57,363,515</td><td align="left">2,341,610</td><td align="left">0.40</td></tr></tbody></table><table-wrap-foot><p>#EDGE denotes the number of edges of the graph and TIME the running time (hours) for the computation</p></table-wrap-foot></table-wrap></p>
        <p>Figure <xref rid="Fig3" ref-type="fig">3</xref> shows the powerful scalability of the TER algorithm where the computational time decreased as the number of cluster nodes increased. For example, the TER algorithm completed the reduction of the graph module in 2.92 h using 5 cluster nodes, while completed the same task in 1.37 h with 15 cluster nodes.
<fig id="Fig3"><label>Fig. 3</label><caption><p>Wall-clock time comparison. Wall-clock time for different number of nodes with the different size of metagenomics datasets</p></caption><graphic xlink:href="40246_2019_227_Fig3_HTML" id="MO7"/></fig></p>
      </sec>
      <sec id="Sec14">
        <title>Dead-End Removal and Composite Edge Contraction</title>
        <p>The evaluation results of the two algorithms, Dead-End Removal (DER) and Composite Edge Contraction (CEC), using the quarter, half, and full size datasets were shown in Table <xref rid="Tab1" ref-type="table">1</xref>. Given the quarter dataset that contains 12.5 million edges, the combined DER-CEC modules created the reduced graph with 0.5 million edges with 96% reduction. In addition, given the full dataset that contains 57.3 million edges, the combined DER-CEC modules resulted in the reduced graph comprising 2.3 million edges with 95.97% reduction.</p>
        <p>Figure <xref rid="Fig3" ref-type="fig">3</xref> represents the capable scalability of the combined DER-CEC algorithms by measuring each running time per different numbers of cluster nodes within the same sized dataset. In the full dataset experiment, we directly compared the running time between 5 and 15 cluster nodes. The DER-CEC algorithm completed the reduction of the graph using 5 virtual instances in 1.35 h, while fast and scalable completing in 0.4 h with 15 virtual instances.</p>
      </sec>
      <sec id="Sec15">
        <title>Benchmark to Omega</title>
        <p>To demonstrate the power of SORA’s distributed cloud computation, we benchmarked two algorithms: Omega and SORA. Omega is an string overlap-graph based metagenome assembler tool implemented in C++ [<xref ref-type="bibr" rid="CR24">24</xref>]. We could choose another baseline application such as Spaler [<xref ref-type="bibr" rid="CR20">20</xref>], which is a Spark-based de novo genome assembler using DBG approach, but Spaler is not publicly available for benchmarking. In Fig. <xref rid="Fig4" ref-type="fig">4</xref>, it shows that SORA’s computation time is only 1.77 h running time compared to Omega with 7.5 h running time. In addition to efficient speedy performance, SORA uses less amount of system memory compared to Omega since it breaks down the graph computation tasks to process them in parallel, thereby allowing more of the graph to be in memory and speeding up the analysis.
<fig id="Fig4"><label>Fig. 4</label><caption><p>Benchmark to Omega. Shows how the analysis of the metagenomics dataset compares with Omega</p></caption><graphic xlink:href="40246_2019_227_Fig4_HTML" id="MO8"/></fig></p>
      </sec>
    </sec>
    <sec id="Sec16">
      <title>Horseweed Dataset Analysis</title>
      <p>To show the flexibility and usability of SORA, we applied SORA to a single genome dataset to generate a reduced graph. Total size of 72 FASTQ paired-end files is 108 GB. We used a local computational workstation that has 32 cores (Intel Xeon Processor E5-2640 V3 2.6GHz) and 128 GB of memory (DDR4 2133MHz ECC).</p>
      <sec id="Sec17">
        <title>Overlap Graph Construction</title>
        <p>To demonstrate the power of SORA for genome assembly with multiple raw reads dataset from a single genome, we implemented and incorporated multiple shell scripts into SORA to perform error correction on the genome dataset, find overlaps of the corrected reads, and generate a large overlap graph as a batch process, and thereafter executes SORA. The dataset that we tested was processed with normalization and graph construction containing 8.3 million edges. Figure <xref rid="Fig5" ref-type="fig">5</xref> represents that the pipeline script including SORA completed the assembly in 9.75 h where SORA core modules (TER, DER, and CEC) only took less than 10 min.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Shows the overall timing of each step from raw reads to reduced graph using SORA</p></caption><graphic xlink:href="40246_2019_227_Fig5_HTML" id="MO9"/></fig></p>
      </sec>
      <sec id="Sec18">
        <title>Transitive Edge Reduction</title>
        <p>Table <xref rid="Tab2" ref-type="table">2</xref> shows the assessment results using the TER algorithm with the single genome dataset that contains 8.3 million edges. After the TER algorithm, SORA produced the reduced graph that contains 5.4 million edges, which was lower reduction rate than the experiment using the metagenomic dataset since the single genome dataset is constructed less redundancies and receives fewer transitive edges potentially to be removed. Figure <xref rid="Fig5" ref-type="fig">5</xref> shows that the TER algorithm completed with the best speedy performance (1.02 min execution time) with efficient memory consumption that is not requiring above 22% of overall memory usage from 128 GB total system memory.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>The SORA results with the horseweed dataset</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">#EDGE (before)</th><th align="left">#EDGE (after)</th><th align="left">TIME (mins)</th></tr></thead><tbody><tr><td align="left">TER</td><td align="left">8,259,543</td><td align="left">5,386,287</td><td align="left">1.02</td></tr><tr><td align="left">DER-CEC</td><td align="left">5,386,287</td><td align="left">1,027,959</td><td align="left">8.23</td></tr></tbody></table><table-wrap-foot><p>#EDGE denotes the number of edges of the graph and TIME denotes the running (wall-clock) time of the computation</p></table-wrap-foot></table-wrap></p>
      </sec>
      <sec id="Sec19">
        <title>Dead-End Removal and Composite Edge Contraction</title>
        <p>Table <xref rid="Tab2" ref-type="table">2</xref> also shows the outcomes of overlap-graph reduction from the DER-CEC algorithms with the dataset where the graph contains 5.4 million edges generated from the TER algorithm. As we executed the algorithms DER and CEC subsequently, the DER algorithm produced the reduced graph with 4.2 million edges, whose output was fed into the CEC algorithms that completed the final graph leading to the reduced 1 million-edge graph. During this overlap-graph reduction, the DER-CEC algorithm completed the computation in 8.23 min with the maximum 37% consumption of the 128 GB total memory.</p>
      </sec>
    </sec>
    <sec id="Sec20">
      <title>Human Genome Dataset Analysis</title>
      <p>In this experiment, we applied SORA to a human genome dataset to generate a reduced graph. Total size of 3 FASTQ paired-end files for one sample is 40 GB. We used a local computational workstation that has 32 cores (Intel Xeon Processor E5-2640 V3 2.6GHz) and 128 GB of memory (DDR4 2133MHz ECC) to show the ability of the SORA for a human genome sample.</p>
      <sec id="Sec21">
        <title>Overlap Graph Construction</title>
        <p>We also used a script in SORA to run BBtools trimming, filtering, error correction, merge, reformatting, merging, and finding overlaps. The duration time was approximately 1 h using 32 cores of the machine. Table <xref rid="Tab3" ref-type="table">3</xref> shows the number of edges of the overlap graph from the human genome dataset.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>The SORA results with the with the human genome dataset</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">#EDGE (before)</th><th align="left">#EDGE (after)</th><th align="left">TIME (mins)</th></tr></thead><tbody><tr><td align="left">TER</td><td align="left">18,942</td><td align="left">10,017</td><td align="left">1</td></tr><tr><td align="left">DER-CEC</td><td align="left">10,017</td><td align="left">4648</td><td align="left">2</td></tr></tbody></table><table-wrap-foot><p>#EDGE denotes the number of edges of the graph and TIME denotes the running (wall-clock) time of the computation</p></table-wrap-foot></table-wrap></p>
      </sec>
      <sec id="Sec22">
        <title>TER, DER, and CEC</title>
        <p>Table <xref rid="Tab3" ref-type="table">3</xref> also shows the results of overlap-graph reduction of the TER and combined DER-CEC algorithms with the human genome dataset. The number of edges decreased to 24% of the original overlap graph. During this overlap-graph reduction, the TER, DER-CEC algorithms completed the computation in 3 min with the maximum 50% consumption of the 128 GB total memory.</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec23" sec-type="discussion">
    <title>Discussion</title>
    <p>The sequencing price continues to drop with increasing of emergence and fine tuning of novel sequencing technologies that increase the amount of sequencing data exponentially. Conventional algorithms can utilize the large influx of raw reads, but most of those algorithms require a large and expensive computing system with a large amount of computer memory. That requirement only limit to the few big labs that can afford to purchase and maintain such a powerful computing machine. SORA helps bridge this gap to small-size research labs by providing an efficient method for generating reduced graphs using distributed computing in the cloud. SORA also provides the ability to analyze any size of input data to generate novel sequenced contigs in fast turn-around time using any size of system resources.</p>
    <p>In reference free de novo assembly, overlap-layout-consensus approach is a well-used method in low-throughput long-reads Sanger sequencing era, but can raise a problem for massive amounts of short reads that can lead many false overlaps. Therefore, it can increase the computational time and memory usage requiring for storing and analyzing large-scale graphs spawned from the massive short reads. SORA has been designed to work efficiently with these problems by using the Apache Spark engine to manage the distributed computation in the cloud or local cluster. SORA with Apache Spark efficiently uses in memory storage across multiple instances to provide a better performance compared to traditional genome assemblers.</p>
  </sec>
  <sec id="Sec24" sec-type="conclusion">
    <title>Conclusions</title>
    <p>As seen in the experimental results the nearly linear scalability of SORA allows altering of the number of computational nodes as the overlap graph data size changes. By using the intrinsic attributes of each node (alignment of reads) the redundant edges in the graph can be removed using the Transitive Edge Reduction algorithm. The long stretches of multiple single edges mapped head to tail can be reduced to a single edge using the Composite Edge Contraction. Overall these algorithms provide a reduced overlap graph which allows for better contigs to be generated for de novo genome assembly.</p>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>AWS</term>
        <def>
          <p>Amazon web service</p>
        </def>
      </def-item>
      <def-item>
        <term>CEC</term>
        <def>
          <p>Composite edge contraction</p>
        </def>
      </def-item>
      <def-item>
        <term>DBG</term>
        <def>
          <p>de Bruijin graph</p>
        </def>
      </def-item>
      <def-item>
        <term>DER</term>
        <def>
          <p>Dead-end removal</p>
        </def>
      </def-item>
      <def-item>
        <term>EBI</term>
        <def>
          <p>The European Bioinformatics Institute</p>
        </def>
      </def-item>
      <def-item>
        <term>EC2</term>
        <def>
          <p>Elastic computing cloud</p>
        </def>
      </def-item>
      <def-item>
        <term>MLlib</term>
        <def>
          <p>Machine learning library</p>
        </def>
      </def-item>
      <def-item>
        <term>NCBI</term>
        <def>
          <p>National center for biotechnology information</p>
        </def>
      </def-item>
      <def-item>
        <term>NGS</term>
        <def>
          <p>Next-generation sequencing</p>
        </def>
      </def-item>
      <def-item>
        <term>OLC</term>
        <def>
          <p>Overlap-layout-consensus</p>
        </def>
      </def-item>
      <def-item>
        <term>PacBio</term>
        <def>
          <p>Pacific bio-sciences</p>
        </def>
      </def-item>
      <def-item>
        <term>RDD</term>
        <def>
          <p>Resilient distributed dataset</p>
        </def>
      </def-item>
      <def-item>
        <term>TER</term>
        <def>
          <p>Transitive edge reduction</p>
        </def>
      </def-item>
      <def-item>
        <term>WGS</term>
        <def>
          <p>Whole genome sequencing</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
    <sec id="d29e1315">
      <title>About this supplement</title>
      <p>This article has been published as part of <italic>Human Genomics Volume 13 Supplement 1, 2019: Selected articles from the IEEE BIBM International Conference on Bioinformatics &amp; Biomedicine (BIBM) 2018: human genomics</italic>. The full contents of the supplement are available online at <ext-link ext-link-type="uri" xlink:href="https://humgenomics.biomedcentral.com/articles/supplements/volume-13-supplement-1">https://humgenomics.biomedcentral.com/articles/supplements/volume-13-supplement-1</ext-link>.</p>
    </sec>
    <sec id="d29e1328">
      <title>Funding</title>
      <p>TA is supported by NSF-1566292, NSF-1564894, Saint Louis University (SLU) Startup, SLU President’s Research Fund 2018, and Amazon Web Service (AWS) Cloud Credits for Research. DL is supported by T32 HG000045 from the National Human Genome Research Institute. Publication were funded by TA’s SLU Startup fund.</p>
    </sec>
    <sec id="d29e1333" sec-type="data-availability">
      <title>Availability of data and materials</title>
      <p>The datasets that support the findings of this study are available in <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra/SRX200676">https://www.ncbi.nlm.nih.gov/sra/SRX200676</ext-link>, <ext-link ext-link-type="uri" xlink:href="http://www.plantphysiol.org/content/166/3/1241">http://www.plantphysiol.org/content/166/3/1241</ext-link>, and <ext-link ext-link-type="uri" xlink:href="ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR622/SRR622461/">ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR622/SRR622461/</ext-link>.</p>
    </sec>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>TA and CP jointly contributed to the design of the study. AJ jointly conceived the study with T.A, performed experiments and data analysis, and prepared the initial draft of the manuscript. D.L performed experiments and data analysis. MS, SL, CP assisted in the design of the SORA algorithm. TA supervised the project. All authors read and approved the final manuscript.</p>
  </notes>
  <notes>
    <title>Publisher’s Note</title>
    <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
  </notes>
  <notes>
    <title>Ethics approval and consent to participate</title>
    <p>Not applicable.</p>
  </notes>
  <notes>
    <title>Consent for publication</title>
    <p>Not applicable.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p>The authors declare that they have no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ansorge</surname>
            <given-names>WJ</given-names>
          </name>
        </person-group>
        <article-title>Next-generation dna sequencing techniques</article-title>
        <source>New Biotechnol</source>
        <year>2009</year>
        <volume>25</volume>
        <issue>4</issue>
        <fpage>195</fpage>
        <lpage>203</lpage>
        <pub-id pub-id-type="doi">10.1016/j.nbt.2008.12.009</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hert</surname>
            <given-names>DG</given-names>
          </name>
          <name>
            <surname>Fredlake</surname>
            <given-names>CP</given-names>
          </name>
          <name>
            <surname>Barron</surname>
            <given-names>AE</given-names>
          </name>
        </person-group>
        <article-title>Advantages and limitations of next-generation sequencing technologies: a comparison of electrophoresis and non-electrophoresis methods</article-title>
        <source>Electrophoresis</source>
        <year>2008</year>
        <volume>29</volume>
        <issue>23</issue>
        <fpage>4618</fpage>
        <lpage>26</lpage>
        <pub-id pub-id-type="doi">10.1002/elps.200800456</pub-id>
        <pub-id pub-id-type="pmid">19053153</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Metzker</surname>
            <given-names>Michael L.</given-names>
          </name>
        </person-group>
        <article-title>Sequencing technologies — the next generation</article-title>
        <source>Nature Reviews Genetics</source>
        <year>2009</year>
        <volume>11</volume>
        <issue>1</issue>
        <fpage>31</fpage>
        <lpage>46</lpage>
        <pub-id pub-id-type="doi">10.1038/nrg2626</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wall</surname>
            <given-names>PK</given-names>
          </name>
          <name>
            <surname>Leebens-Mack</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Chanderbali</surname>
            <given-names>AS</given-names>
          </name>
          <name>
            <surname>Barakat</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wolcott</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Landherr</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Tomsho</surname>
            <given-names>LP</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Carlson</surname>
            <given-names>JE</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Comparison of next generation sequencing technologies for transcriptome characterization</article-title>
        <source>BMC Genom</source>
        <year>2009</year>
        <volume>10</volume>
        <issue>1</issue>
        <fpage>347</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2164-10-347</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Flicek</surname>
            <given-names>Paul</given-names>
          </name>
          <name>
            <surname>Birney</surname>
            <given-names>Ewan</given-names>
          </name>
        </person-group>
        <article-title>Sense from sequence reads: methods for alignment and assembly</article-title>
        <source>Nature Methods</source>
        <year>2009</year>
        <volume>6</volume>
        <issue>S11</issue>
        <fpage>S6</fpage>
        <lpage>S12</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.1376</pub-id>
        <pub-id pub-id-type="pmid">19844229</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schneider</surname>
            <given-names>Valerie A.</given-names>
          </name>
          <name>
            <surname>Graves-Lindsay</surname>
            <given-names>Tina</given-names>
          </name>
          <name>
            <surname>Howe</surname>
            <given-names>Kerstin</given-names>
          </name>
          <name>
            <surname>Bouk</surname>
            <given-names>Nathan</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Hsiu-Chuan</given-names>
          </name>
          <name>
            <surname>Kitts</surname>
            <given-names>Paul A.</given-names>
          </name>
          <name>
            <surname>Murphy</surname>
            <given-names>Terence D.</given-names>
          </name>
          <name>
            <surname>Pruitt</surname>
            <given-names>Kim D.</given-names>
          </name>
          <name>
            <surname>Thibaud-Nissen</surname>
            <given-names>Françoise</given-names>
          </name>
          <name>
            <surname>Albracht</surname>
            <given-names>Derek</given-names>
          </name>
          <name>
            <surname>Fulton</surname>
            <given-names>Robert S.</given-names>
          </name>
          <name>
            <surname>Kremitzki</surname>
            <given-names>Milinn</given-names>
          </name>
          <name>
            <surname>Magrini</surname>
            <given-names>Vincent</given-names>
          </name>
          <name>
            <surname>Markovic</surname>
            <given-names>Chris</given-names>
          </name>
          <name>
            <surname>McGrath</surname>
            <given-names>Sean</given-names>
          </name>
          <name>
            <surname>Steinberg</surname>
            <given-names>Karyn Meltz</given-names>
          </name>
          <name>
            <surname>Auger</surname>
            <given-names>Kate</given-names>
          </name>
          <name>
            <surname>Chow</surname>
            <given-names>William</given-names>
          </name>
          <name>
            <surname>Collins</surname>
            <given-names>Joanna</given-names>
          </name>
          <name>
            <surname>Harden</surname>
            <given-names>Glenn</given-names>
          </name>
          <name>
            <surname>Hubbard</surname>
            <given-names>Timothy</given-names>
          </name>
          <name>
            <surname>Pelan</surname>
            <given-names>Sarah</given-names>
          </name>
          <name>
            <surname>Simpson</surname>
            <given-names>Jared T.</given-names>
          </name>
          <name>
            <surname>Threadgold</surname>
            <given-names>Glen</given-names>
          </name>
          <name>
            <surname>Torrance</surname>
            <given-names>James</given-names>
          </name>
          <name>
            <surname>Wood</surname>
            <given-names>Jonathan M.</given-names>
          </name>
          <name>
            <surname>Clarke</surname>
            <given-names>Laura</given-names>
          </name>
          <name>
            <surname>Koren</surname>
            <given-names>Sergey</given-names>
          </name>
          <name>
            <surname>Boitano</surname>
            <given-names>Matthew</given-names>
          </name>
          <name>
            <surname>Peluso</surname>
            <given-names>Paul</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Heng</given-names>
          </name>
          <name>
            <surname>Chin</surname>
            <given-names>Chen-Shan</given-names>
          </name>
          <name>
            <surname>Phillippy</surname>
            <given-names>Adam M.</given-names>
          </name>
          <name>
            <surname>Durbin</surname>
            <given-names>Richard</given-names>
          </name>
          <name>
            <surname>Wilson</surname>
            <given-names>Richard K.</given-names>
          </name>
          <name>
            <surname>Flicek</surname>
            <given-names>Paul</given-names>
          </name>
          <name>
            <surname>Eichler</surname>
            <given-names>Evan E.</given-names>
          </name>
          <name>
            <surname>Church</surname>
            <given-names>Deanna M.</given-names>
          </name>
        </person-group>
        <article-title>Evaluation of GRCh38 and de novo haploid genome assemblies demonstrates the enduring quality of the reference assembly</article-title>
        <source>Genome Research</source>
        <year>2017</year>
        <volume>27</volume>
        <issue>5</issue>
        <fpage>849</fpage>
        <lpage>864</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.213611.116</pub-id>
        <pub-id pub-id-type="pmid">28396521</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Miller</surname>
            <given-names>Jason R.</given-names>
          </name>
          <name>
            <surname>Koren</surname>
            <given-names>Sergey</given-names>
          </name>
          <name>
            <surname>Sutton</surname>
            <given-names>Granger</given-names>
          </name>
        </person-group>
        <article-title>Assembly algorithms for next-generation sequencing data</article-title>
        <source>Genomics</source>
        <year>2010</year>
        <volume>95</volume>
        <issue>6</issue>
        <fpage>315</fpage>
        <lpage>327</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ygeno.2010.03.001</pub-id>
        <pub-id pub-id-type="pmid">20211242</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Myers</surname>
            <given-names>E. W.</given-names>
          </name>
        </person-group>
        <article-title>A Whole-Genome Assembly of Drosophila</article-title>
        <source>Science</source>
        <year>2000</year>
        <volume>287</volume>
        <issue>5461</issue>
        <fpage>2196</fpage>
        <lpage>2204</lpage>
        <pub-id pub-id-type="doi">10.1126/science.287.5461.2196</pub-id>
        <pub-id pub-id-type="pmid">10731133</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9</label>
      <mixed-citation publication-type="other">Margulies M, et al.Genome sequencing in microfabricated high-density picolitre reactors. Nature; 437(7057):376–80.</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Simpson</surname>
            <given-names>J. T.</given-names>
          </name>
          <name>
            <surname>Wong</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Jackman</surname>
            <given-names>S. D.</given-names>
          </name>
          <name>
            <surname>Schein</surname>
            <given-names>J. E.</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>S. J.M.</given-names>
          </name>
          <name>
            <surname>Birol</surname>
            <given-names>I.</given-names>
          </name>
        </person-group>
        <article-title>ABySS: A parallel assembler for short read sequence data</article-title>
        <source>Genome Research</source>
        <year>2009</year>
        <volume>19</volume>
        <issue>6</issue>
        <fpage>1117</fpage>
        <lpage>1123</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.089532.108</pub-id>
        <pub-id pub-id-type="pmid">19251739</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zerbino</surname>
            <given-names>D. R.</given-names>
          </name>
          <name>
            <surname>Birney</surname>
            <given-names>E.</given-names>
          </name>
        </person-group>
        <article-title>Velvet: Algorithms for de novo short read assembly using de Bruijn graphs</article-title>
        <source>Genome Research</source>
        <year>2008</year>
        <volume>18</volume>
        <issue>5</issue>
        <fpage>821</fpage>
        <lpage>829</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.074492.107</pub-id>
        <pub-id pub-id-type="pmid">18349386</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Ruan</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Qian</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Shan</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Kristiansen</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>De novo assembly of human genomes with massively parallel short read sequencing</article-title>
        <source>Genome Research</source>
        <year>2009</year>
        <volume>20</volume>
        <issue>2</issue>
        <fpage>265</fpage>
        <lpage>272</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.097261.109</pub-id>
        <pub-id pub-id-type="pmid">20019144</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pop</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Genome assembly reborn: recent computational challenges</article-title>
        <source>Briefings in Bioinformatics</source>
        <year>2009</year>
        <volume>10</volume>
        <issue>4</issue>
        <fpage>354</fpage>
        <lpage>366</lpage>
        <pub-id pub-id-type="doi">10.1093/bib/bbp026</pub-id>
        <pub-id pub-id-type="pmid">19482960</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14</label>
      <mixed-citation publication-type="other">Berlin K, Koren S, Chin CS, Drake JP, Landolin JM, Phillippy AM. Assembling large genomes with single-molecule sequencing and locality-sensitive hashing. Nat Biotechnol; 33(6):623–30.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15</label>
      <mixed-citation publication-type="other">Koren S, Walenz BP, Berlin K, Miller JR, Bergman NH, Phillippy AM. Canu: scalable and accurate long-read assembly via adaptive k-mer weighting and repeat separation. Genome Res; 27(5):722–36.</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16</label>
      <mixed-citation publication-type="other">Boisvert S, Laviolette F, Corbeil J. Ray: Simultaneous assembly of reads from a mix of high-throughput sequencing technologies. J Comput Biol; 17(11):1519–33.</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17</label>
      <mixed-citation publication-type="other">Meng J, Seo S, Balaji P, Wei Y, Wang B, Feng S. Swap-assembler 2: Optimization of de novo genome assembler at extreme scale, 2016 45th International Conference on Parallel Processing (ICPP), Philadelphia.2016. p. 195–204. 10.1109/ICPP.2016.29.</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Zaharia</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Chowdhury</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Franklin</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Shenker</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Stoica</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Spark: cluster computing with working sets</article-title>
        <source>Proceedings of the 2nd USENIX conference on Hot topics in cloud computing (HotCloud’10)</source>
        <year>2010</year>
        <publisher-loc>Berkeley</publisher-loc>
        <publisher-name>USENIX Association</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Zaharia</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Chowdhury</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Das</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Dave</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>McCauley</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Franklin</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Shenker</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Stoica</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Resilient distributed datasets: a fault-tolerant abstraction for in-memory cluster computing</article-title>
        <source>Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation (NSDI’12)</source>
        <year>2012</year>
        <publisher-loc>Berkeley</publisher-loc>
        <publisher-name>USENIX Association</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20</label>
      <mixed-citation publication-type="other">Abu-Doleh A, Catalyurek UV. Spaler: Spark and graphx based de novo genome assembler, 2015 IEEE International Conference on Big Data (Big Data), Santa Clara.2015. p. 1013–8. 10.1109/BigData.2015.7363853.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Paul</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Lawrence</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Ahn</surname>
            <given-names>T-H</given-names>
          </name>
        </person-group>
        <article-title>Overlap graph reduction for genome assembly using apache spark</article-title>
        <source>Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology,and Health Informatics, ACM-BCB ’17</source>
        <year>2017</year>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>ACM</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22</label>
      <mixed-citation publication-type="other">Paul AJ, Lawrence D, Song M, Lim S, Pan C, Ahn T. Sora: Scalable overlap-graph reduction algorithms for genome assembly using apache spark in the cloud. In: 2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM): 2018. p. 718–23. 10.1109/BIBM.2018.8621546.</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23</label>
      <mixed-citation publication-type="other">Meng X, Bradley J, Yavuz B, Sparks E, Venkataraman S, Liu D, Freeman J, Tsai D, Amde M, Owen S, et al.Mllib: Machine learning in apache spark. J Mach Learn Res. 2016; 17(1):1235–41.</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Haider</surname>
            <given-names>Bahlul</given-names>
          </name>
          <name>
            <surname>Ahn</surname>
            <given-names>Tae-Hyuk</given-names>
          </name>
          <name>
            <surname>Bushnell</surname>
            <given-names>Brian</given-names>
          </name>
          <name>
            <surname>Chai</surname>
            <given-names>Juanjuan</given-names>
          </name>
          <name>
            <surname>Copeland</surname>
            <given-names>Alex</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>Chongle</given-names>
          </name>
        </person-group>
        <article-title>Omega: an Overlap-graph de novo Assembler for Metagenomics</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <issue>19</issue>
        <fpage>2717</fpage>
        <lpage>2722</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu395</pub-id>
        <pub-id pub-id-type="pmid">24947750</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Myers</surname>
            <given-names>EW</given-names>
          </name>
        </person-group>
        <article-title>The fragment assembly string graph</article-title>
        <source>Bioinformatics</source>
        <year>2005</year>
        <volume>21</volume>
        <issue>2</issue>
        <fpage>ii79</fpage>
        <lpage>85</lpage>
        <?supplied-pmid 16204131?>
        <pub-id pub-id-type="pmid">16204131</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shakya</surname>
            <given-names>Migun</given-names>
          </name>
          <name>
            <surname>Quince</surname>
            <given-names>Christopher</given-names>
          </name>
          <name>
            <surname>Campbell</surname>
            <given-names>James H.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Zamin K.</given-names>
          </name>
          <name>
            <surname>Schadt</surname>
            <given-names>Christopher W.</given-names>
          </name>
          <name>
            <surname>Podar</surname>
            <given-names>Mircea</given-names>
          </name>
        </person-group>
        <article-title>Comparative metagenomic and rRNA microbial diversity characterization using archaeal and bacterial synthetic communities</article-title>
        <source>Environmental Microbiology</source>
        <year>2013</year>
        <volume>15</volume>
        <issue>6</issue>
        <fpage>1882</fpage>
        <lpage>1899</lpage>
        <pub-id pub-id-type="doi">10.1111/1462-2920.12086</pub-id>
        <pub-id pub-id-type="pmid">23387867</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peng</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Lai</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Lane</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Nageswara-Rao</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Okada</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Jasieniuk</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>O’Geen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>RW</given-names>
          </name>
          <name>
            <surname>Sammons</surname>
            <given-names>RD</given-names>
          </name>
          <name>
            <surname>Rieseberg</surname>
            <given-names>LH</given-names>
          </name>
          <name>
            <surname>Stewart</surname>
            <given-names>CN</given-names>
          </name>
        </person-group>
        <article-title>De novo genome assembly of the economically important weed horseweed using integrated data from multiple sequencing platforms</article-title>
        <source>Plant Physiol</source>
        <year>2014</year>
        <volume>166</volume>
        <issue>3</issue>
        <fpage>1241</fpage>
        <lpage>54</lpage>
        <pub-id pub-id-type="doi">10.1104/pp.114.247668</pub-id>
        <pub-id pub-id-type="pmid">25209985</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
