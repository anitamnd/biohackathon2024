<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS One</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLoS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9462789</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-21-24846</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0274338</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Genomics</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Database and Informatics Methods</subject>
          <subj-group>
            <subject>Bioinformatics</subject>
            <subj-group>
              <subject>Sequence Analysis</subject>
              <subj-group>
                <subject>Sequence Motif Analysis</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Mathematical Functions</subject>
            <subj-group>
              <subject>Convolution</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
            <subj-group>
              <subject>Support Vector Machines</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Neural Networks</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Neural Networks</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Network Analysis</subject>
          <subj-group>
            <subject>Network Motifs</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Information Technology</subject>
          <subj-group>
            <subject>Information Architecture</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Gnocis: An integrated system for interactive and reproducible analysis and modelling of <italic toggle="yes">cis</italic>-regulatory elements in Python 3</article-title>
      <alt-title alt-title-type="running-head">Gnocis: Interactive and reproducible analysis and modelling of cis-regulatory elements in Python 3</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7171-2265</contrib-id>
        <name>
          <surname>Bredesen-Aa</surname>
          <given-names>Bjørn André</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="currentaff001" ref-type="author-notes">
          <sup>¤</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rehmsmeier</surname>
          <given-names>Marc</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="econtrib001" ref-type="author-notes">
          <sup>†</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Computational Biology Unit, Department of Informatics, University of Bergen, Bergen, Norway</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Department of Biology, Humboldt-Universität zu Berlin, Berlin, Germany</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Cai</surname>
          <given-names>Ying</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Yeshiva University Albert Einstein College of Medicine, UNITED STATES</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
      </fn>
      <fn fn-type="current-aff" id="currentaff001">
        <p>¤ Current Address: Kavli Institute for Systems Neuroscience and Centre for Neural Computation, Faculty of Medicine and Health Sciences, Norwegian University of Science and Technology, Trondheim, Norway</p>
      </fn>
      <fn fn-type="other" id="econtrib001">
        <p>† Deceased.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>bjorn.a.bredesen@ntnu.no</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>9</day>
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <volume>17</volume>
    <issue>9</issue>
    <elocation-id>e0274338</elocation-id>
    <history>
      <date date-type="received">
        <day>7</day>
        <month>8</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>25</day>
        <month>8</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 Bredesen-Aa, Rehmsmeier</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Bredesen-Aa, Rehmsmeier</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pone.0274338.pdf"/>
    <abstract>
      <p>Gene expression is regulated through <italic toggle="yes">cis</italic>-regulatory elements (CREs), among which are promoters, enhancers, Polycomb/Trithorax Response Elements (PREs), silencers and insulators. Computational prediction of CREs can be achieved using a variety of statistical and machine learning methods combined with different feature space formulations. Although Python packages for DNA sequence feature sets and for machine learning are available, no existing package facilitates the combination of DNA sequence feature sets with machine learning methods for the genome-wide prediction of candidate CREs. We here present Gnocis, a Python package that streamlines the analysis and the modelling of CRE sequences by providing extensible APIs and implementing the glue required for combining feature sets and models for genome-wide prediction. Gnocis implements a variety of base feature sets, including motif pair occurrence frequencies and the k-spectrum mismatch kernel. It integrates with Scikit-learn and TensorFlow for state-of-the-art machine learning. Gnocis additionally implements a broad suite of tools for the handling and preparation of sequence, region and curve data, which can be useful for general DNA bioinformatics in Python. We also present Deep-MOCCA, a neural network architecture inspired by SVM-MOCCA that achieves moderate to high generalization without prior motif knowledge. To demonstrate the use of Gnocis, we applied multiple machine learning methods to the modelling of <italic toggle="yes">D. melanogaster</italic> PREs, including a Convolutional Neural Network (CNN), making this the first study to model PREs with CNNs. The models are readily adapted to new CRE modelling problems and to other organisms. In order to produce a high-performance, compiled package for Python 3, we implemented Gnocis in Cython. Gnocis can be installed using the PyPI package manager by running ‘<monospace>pip install gnocis</monospace>’. The source code is available on GitHub, at <ext-link xlink:href="https://github.com/bjornbredesen/gnocis" ext-link-type="uri">https://github.com/bjornbredesen/gnocis</ext-link>.</p>
    </abstract>
    <funding-group>
      <funding-statement>The author(s) received no specific funding for this work.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="5"/>
      <table-count count="4"/>
      <page-count count="20"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>All data used in the present manuscript can be found in the tutorial folder for Gnocis, available on GitHub: <ext-link xlink:href="https://github.com/bjornbredesen/gnocis" ext-link-type="uri">https://github.com/bjornbredesen/gnocis</ext-link>. The sources of the data are stated in the Materials and Methods section of the article and also in the tutorial.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>All data used in the present manuscript can be found in the tutorial folder for Gnocis, available on GitHub: <ext-link xlink:href="https://github.com/bjornbredesen/gnocis" ext-link-type="uri">https://github.com/bjornbredesen/gnocis</ext-link>. The sources of the data are stated in the Materials and Methods section of the article and also in the tutorial.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>Gene expression is regulated through <italic toggle="yes">cis</italic>-regulatory elements (CREs) [<xref rid="pone.0274338.ref001" ref-type="bibr">1</xref>]. Multiple classes of CREs have been identified, with functions ranging from directly stimulating target gene activity [<xref rid="pone.0274338.ref002" ref-type="bibr">2</xref>] over maintaining epigenetic memory [<xref rid="pone.0274338.ref003" ref-type="bibr">3</xref>] to delimiting the effects of other CREs [<xref rid="pone.0274338.ref004" ref-type="bibr">4</xref>]. CREs are typically enriched in a variety of protein binding sites which can be characterized as sequence motifs [<xref rid="pone.0274338.ref005" ref-type="bibr">5</xref>].</p>
    <p>Advances in experimental methods have given rise to a growing body of genome-wide experimental data from a multitude of organisms, capturing binding patterns of DNA- and chromatin-binding proteins, histone tail modifications, chromatin conformation, and DNA accessibility [<xref rid="pone.0274338.ref006" ref-type="bibr">6</xref>]. Given a set of CREs, analyses of the underlying sequences can shed light on the defining sequence criteria and enable the training of predictive models. Knowledge of the defining sequence criteria can yield new insights about the function of the CRE class under investigation, and predictive models can yield predictions beyond the confines of available experimental data.</p>
    <p>We previously observed improved generalization when training models with genome-wide experimental data for Polycomb/Trithorax Response Elements (PREs) [<xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>], a CRE class that maintains epigenetic memory [<xref rid="pone.0274338.ref008" ref-type="bibr">8</xref>]. Given sets of relevant experimental data for a CRE class of interest, several steps are necessary in order to produce candidate CRE predictions, including data preparation, model specification, comparison with alternative models and genome-wide prediction. Models of CRE sequences can be specified in a number of ways, for example by combining a feature set with a machine learning method, such as Support Vector Machines (SVMs) [<xref rid="pone.0274338.ref009" ref-type="bibr">9</xref>] or Random Forests (RFs) [<xref rid="pone.0274338.ref010" ref-type="bibr">10</xref>]. Feature spaces for CRE sequence models can also be defined in numerous ways, including singular and paired motif occurrence frequencies [<xref rid="pone.0274338.ref003" ref-type="bibr">3</xref>] and k-spectra—the set of occurrence frequencies of all motifs of length k—with or without mismatches allowed [<xref rid="pone.0274338.ref011" ref-type="bibr">11</xref>]. Alternatively, Convolutional Neural Networks (CNNs) can be used to learn predictive features directly from data without the need for a predefined feature set and have yielded notable success for complex recognition tasks such as in the area of image classification [<xref rid="pone.0274338.ref012" ref-type="bibr">12</xref>].</p>
    <p>In order to decide what models yield the best generalization, unbiased comparison should be employed, for example using cross-validation on the same training and test data for all models. When data is highly imbalanced, as is typically the case with CREs versus non-CREs, the Precision/Recall curve reflects expected generalization in light of the imbalance [<xref rid="pone.0274338.ref013" ref-type="bibr">13</xref>]. The use of Jupyter Notebooks [<xref rid="pone.0274338.ref014" ref-type="bibr">14</xref>] enables interactive and reproducible workflows in Python, with integrated visualization.</p>
    <p>Powerful machine learning packages are available for Python, such as Scikit-learn [<xref rid="pone.0274338.ref015" ref-type="bibr">15</xref>] for classical machine learning and TensorFlow [<xref rid="pone.0274338.ref016" ref-type="bibr">16</xref>] for neural networks. Packages also exist for Python that enable the specification of motifs and the search for their occurrences [<xref rid="pone.0274338.ref017" ref-type="bibr">17</xref>] and for k-spectrum feature sets [<xref rid="pone.0274338.ref018" ref-type="bibr">18</xref>–<xref rid="pone.0274338.ref020" ref-type="bibr">20</xref>]. These contributions notwithstanding, a package that provides base functionality for combining machine learning methods with DNA sequence feature sets has been absent, leaving the end-user to implement this functionality on his or her own. Such functionality includes the bridging of outputs of feature set modules and inputs of machine learning models, the scoring of sequences using sliding windows, prediction threshold calibration and genome-wide prediction. Additionally, such a package could simplify the comparison of alternative models and feature sets. It could also implement a variety of optimizations to reduce run-time cost for the end-user, for example through parallel model application and efficient data handling.</p>
    <p>We here present Gnocis (read no-cis), a Python package that streamlines the modelling of CRE sequences. Gnocis facilitates interactive and reproducible CRE sequence analysis and machine learning by providing a broad suite of tools for data preparation and analysis, a flexible vocabulary for the specification of feature sets, flexible and extensible APIs for feature set and model specification, and base functionality for the combination of machine learning methods and feature sets and for the application of models. The broad suite of data preparation and handling functionality implemented in Gnocis also makes our package useful for more general DNA bioinformatics in Python. Gnocis facilitates interactive use through integration with IPython [<xref rid="pone.0274338.ref021" ref-type="bibr">21</xref>] and provides interoperability with existing packages through integration with NumPy [<xref rid="pone.0274338.ref022" ref-type="bibr">22</xref>] and Pandas [<xref rid="pone.0274338.ref023" ref-type="bibr">23</xref>, <xref rid="pone.0274338.ref024" ref-type="bibr">24</xref>]. In order to facilitate model comparison, Gnocis provides a cross-validation engine that supports imbalanced, multi-class data. Gnocis is open source and extensible and can be installed via the PyPI package manager.</p>
  </sec>
  <sec id="sec002">
    <title>Implementation</title>
    <sec id="sec003">
      <title>A rich vocabulary for the preparation and interactive analysis of genomic data</title>
      <p>Multiple types of data are relevant for CRE machine learning, including DNA sequences, genomic region coordinates and genome-wide factor binding profiles. For example, we previously used genomic coordinates of experimentally determined clusters of Polycomb/Trithorax binding data to train sequence models of PREs [<xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>]. Multiple formats have been formulated for DNA sequences (e.g. FASTA and 2bit) and genomic regions (e.g. GFF and BED). A variety of operations on data are useful for the preparation of training data, including the clustering of experimentally determined protein binding data and the extraction of the underlying DNA sequences. Although packages exist for the handling of DNA sequences [<xref rid="pone.0274338.ref017" ref-type="bibr">17</xref>] and genomic regions [<xref rid="pone.0274338.ref025" ref-type="bibr">25</xref>], they each support only subsets of relevant file formats, and interoperability is limited, requiring code to bridge them. The Pandas [<xref rid="pone.0274338.ref023" ref-type="bibr">23</xref>, <xref rid="pone.0274338.ref024" ref-type="bibr">24</xref>] package provides a broad suite of intuitive tools for preparing and handling tabular data in Python and has achieved high popularity in the data science community.</p>
      <p>Inspired by the success of Pandas, we saw that there was an opportunity for improving on how data can be handled and prepared in Python for CRE machine learning by providing a broad suite of tools for handling multiple types of data, with interoperability and support for established file formats. To facilitate the preparation and handling of sequence data, we implemented classes for DNA sequences, with support for loading both FASTA and 2-bit format files. To optimize memory efficiency, we implemented support for streaming sequences in chunks from disk, including the streaming of sliding windows with a desired length and step size. This avoids the need for loading large sequences to memory. Generative sequence models can be useful for defining negative training data, and we accordingly implemented an i.i.d. sequence generator and an nth-order Markov chain. To facilitate the preparation of genome-wide region data, we implemented classes for regions and for sets of regions, and we implemented a broad selection of transformation operations, including intersection, merging and exclusion and the acquisition of overlaps and non-overlaps. Gnocis supports the loading of regions in General Feature Format (GFF), Browser Extensible Data format (BED) and as coordinate lists. We also implemented the extraction of underlying sequences based on sets of regions and source sequences or a genome. Genome-wide curves are useful for representing experimentally determined genome-wide binding of factors and for scores made by predictive models. We implemented a class for handling curves, with support for the saving and loading of Wiggle format files, and with functionality for deriving a set of regions by thresholding. With the aim of high expressiveness with minimal verbosity, we implemented operations on data as transformations that can be chained, with short and intuitive naming. For run-time efficiency, we implemented the sequence and region data handling in Cython. The data preparation facilities of Gnocis are listed in <xref rid="pone.0274338.t001" ref-type="table">Table 1</xref>.</p>
      <table-wrap position="float" id="pone.0274338.t001">
        <object-id pub-id-type="doi">10.1371/journal.pone.0274338.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>Core data preparation features.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pone.0274338.t001" id="pone.0274338.t001g" position="float"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <tbody>
              <tr>
                <td align="left" rowspan="4" colspan="1">
                  <bold>Sequence file operations</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">FASTA (loading/saving)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">2bit (loading)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Streaming from disk</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Sliding window extraction</td>
              </tr>
              <tr>
                <td align="left" rowspan="5" colspan="1">
                  <bold>Region file operations</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Coordinate lists (loading/saving)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">General Feature Format (GFF) (loading/saving)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Browser Extensible Data (BED) (loading/saving)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">G-zipped GFF (loading)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">G-zipped BED (loading)</td>
              </tr>
              <tr>
                <td align="left" rowspan="3" colspan="1">
                  <bold>Curve file operations</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Wiggle (loading/saving)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">G-zipped Wiggle (loading)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Thresholding</td>
              </tr>
              <tr>
                <td align="left" rowspan="8" colspan="1">
                  <bold>Region set operations</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Merge</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Intersect</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Exclude</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Get overlapping</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Get non-overlapping</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Resize</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Randomly recentre</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Extract underlying sequences</td>
              </tr>
              <tr>
                <td align="left" rowspan="2" colspan="1">
                  <bold>Genome operations</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Genomic sequences via sequence file operations</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Loading of annotation (Ensembl General Transfer Format, GTF)</td>
              </tr>
              <tr>
                <td align="left" rowspan="3" colspan="1">
                  <bold>Biomarker set operations</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Define biomarker set based on sets of experimental signals</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Extract highly biomarker-enriched (HBME) genomic regions</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Extract lowly biomarker-enriched (LBME) genomic regions</td>
              </tr>
              <tr>
                <td align="left" rowspan="2" colspan="1">
                  <bold>Generative sequence models</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Training of i.i.d. sequence model and generation of sequences</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Training of nth-order sequence model and generation of sequences</td>
              </tr>
              <tr>
                <td align="left" rowspan="2" colspan="1">
                  <bold>Visualization</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Plotting of genomic regions and curves with Matplotlib [<xref rid="pone.0274338.ref026" ref-type="bibr">26</xref>]</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Plotting barplots of region overlap statistics with Matplotlib</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t001fn001">
            <p>Gnocis supports standard file formats for regions, curves and sequences, and implements a wide selection of operations in order to facilitate data preparation and handling.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="sec004">
      <title>An expressive language for the specification and application of DNA sequence feature sets</title>
      <p>In order to train machine learning models on DNA sequences, a mapping must be established from the input sequences to numerical vectors, where the mapping is commonly referred to as a feature set. Among the feature sets that have been successfully employed for CRE machine learning are motif occurrence frequencies [<xref rid="pone.0274338.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>, <xref rid="pone.0274338.ref027" ref-type="bibr">27</xref>] and k-spectra [<xref rid="pone.0274338.ref028" ref-type="bibr">28</xref>, <xref rid="pone.0274338.ref029" ref-type="bibr">29</xref>]. A variety of packages useful for DNA sequence analysis in Python have been published, including packages that implement motif occurrence search [<xref rid="pone.0274338.ref017" ref-type="bibr">17</xref>] and DNA sequence feature sets such as k-spectra [<xref rid="pone.0274338.ref018" ref-type="bibr">18</xref>–<xref rid="pone.0274338.ref020" ref-type="bibr">20</xref>]. However, a Python package for generating feature sets based on known motifs, such as motif pair occurrence frequencies, is absent. Furthermore, existing packages do not provide or employ a general and extensible API for DNA sequence features with base functionality such as sequence window application.</p>
      <p>We noticed the potential for a general feature set API to facilitate powerful and flexible feature set specification, combination and filtering of features, and efficient feature extraction for DNA sequence analysis and machine learning. We also noticed that certain feature sets can be most efficiently extracted in bulk, including motif pair occurrence frequencies and k-spectra. In order to exploit this efficiency, we implemented feature sets in Gnocis as directed, acyclic graphs, henceforth referred to as feature networks. The input nodes of a feature network are base feature sets (such as k-spectra), and subsequent nodes are transformations. Transformations can be chained, facilitating short and flexible feature network specification. Feature network nodes can be trained recursively, enabling feature scaling and model training. Base features and transformations implemented in Gnocis are listed in <xref rid="pone.0274338.t002" ref-type="table">Table 2</xref>.</p>
      <table-wrap position="float" id="pone.0274338.t002">
        <object-id pub-id-type="doi">10.1371/journal.pone.0274338.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>Sequence feature analysis.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pone.0274338.t002" id="pone.0274338.t002g" position="float"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <tbody>
              <tr>
                <td align="left" rowspan="3" colspan="1">
                  <bold>Motifs</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">IUPAC nucleotide code motifs</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Position Weight Matrices (PWMs)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Transformation of motif sets into feature sets</td>
              </tr>
              <tr>
                <td align="left" rowspan="4" colspan="1">
                  <bold>Base feature sets</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Motif occurrence frequencies</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Motif pair occurrence frequencies</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">k-spectrum kernel</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">k-spectrum mismatch kernel</td>
              </tr>
              <tr>
                <td align="left" rowspan="4" colspan="1">
                  <bold>Feature set transformations</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Combination of feature sets</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Filtering of feature sets</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Feature pairing by product</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Scaling</td>
              </tr>
              <tr>
                <td align="left" rowspan="5" colspan="1">
                  <bold>Feature tables</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Construction of feature value tables</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Output of summary statistics</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Output of differential summary statistics</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Conversion to NumPy [<xref rid="pone.0274338.ref022" ref-type="bibr">22</xref>] array</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Conversion to Pandas [<xref rid="pone.0274338.ref023" ref-type="bibr">23</xref>] data frame</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t002fn001">
            <p>Gnocis provides a flexible framework for the specification of sequence feature sets and integrates with NumPy [<xref rid="pone.0274338.ref022" ref-type="bibr">22</xref>] and Pandas [<xref rid="pone.0274338.ref023" ref-type="bibr">23</xref>] for analyses with external packages.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>For ease of use, we implemented base functionality for extracting features from sequences, including the extraction of features from sliding windows of sequences streamed from disk. To facilitate interoperability with existing analytical tools, we implemented the output of features to NumPy [<xref rid="pone.0274338.ref022" ref-type="bibr">22</xref>] arrays and Pandas data frames [<xref rid="pone.0274338.ref023" ref-type="bibr">23</xref>]. We implemented the feature network system in Cython, which resulted in a compiled module with efficient feature extraction.</p>
    </sec>
    <sec id="sec005">
      <title>A flexible and extensible modelling API provides the glue required for efficiently combining sequence feature sets and machine learning methods and to apply them for prediction</title>
      <p>A variety of machine learning methods have been developed that can be combined with arbitrary numerical feature sets, including Support Vector Machines [<xref rid="pone.0274338.ref009" ref-type="bibr">9</xref>] and Random Forests [<xref rid="pone.0274338.ref010" ref-type="bibr">10</xref>]. In order to successfully apply these methods for the modelling and genome-wide prediction of CREs, bridging between the feature sets and the machine learning methods is required, and also implementations of sequence scoring and genome-wide application. Models not based on feature sets, such as DNA sequence Convolutional Neural Networks, also require this logic for performing genome-wide prediction. Genome-wide prediction can output scores for sliding windows, and thresholding can yield discrete predictions of candidate CREs. To our knowledge, no prior Python package has been published that implements this base functionality, leaving the prospective CRE modeller to implement this logic on his or her own.</p>
      <p>We were interested in the potential ease of use and experimentation that a general DNA sequence modelling API could enable, and we implemented a modelling API with logic for sequence scoring, prediction threshold calibration and genome-wide prediction. Model application can be performed in parallel, and we implemented the optional use of multiprocessing. We further noticed that a flexible and compact model specification could be achieved by extending the feature network system. We added the transformation of feature sets into sequence models, given a base model as an argument. The recursive training of feature networks, including scaling and modelling methods, enables the re-training of models on new data, for example for cross-validation. Multi-class model training in Gnocis is achieved by assigning labels to sequences. We implemented a log-odds base model, and we created wrappers for Scikit-learn [<xref rid="pone.0274338.ref015" ref-type="bibr">15</xref>] implementations of Support Vector Machines (SVMs) and Random Forests. For SVMs, we additionally implemented GPU-based kernel application with CuPy [<xref rid="pone.0274338.ref030" ref-type="bibr">30</xref>]. We also implemented DNA sequence Convolutional Neural Networks and general Neural Networks via Keras [<xref rid="pone.0274338.ref031" ref-type="bibr">31</xref>] by integrating with TensorFlow [<xref rid="pone.0274338.ref016" ref-type="bibr">16</xref>]. We list features of the Gnocis modelling API in <xref rid="pone.0274338.t003" ref-type="table">Table 3</xref>.</p>
      <table-wrap position="float" id="pone.0274338.t003">
        <object-id pub-id-type="doi">10.1371/journal.pone.0274338.t003</object-id>
        <label>Table 3</label>
        <caption>
          <title>Models.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pone.0274338.t003" id="pone.0274338.t003g" position="float"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <tbody>
              <tr>
                <td align="left" rowspan="5" colspan="1">
                  <bold>Base models</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Unweighted sum</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Log-odds</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Support Vector Machine via Scikit-learn [<xref rid="pone.0274338.ref015" ref-type="bibr">15</xref>]</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Support Vector Machine with GPU application via Scikit-learn [<xref rid="pone.0274338.ref015" ref-type="bibr">15</xref>] and CuPy [<xref rid="pone.0274338.ref030" ref-type="bibr">30</xref>]</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Random Forest via Scikit-learn [<xref rid="pone.0274338.ref015" ref-type="bibr">15</xref>]</td>
              </tr>
              <tr>
                <td align="left" rowspan="7" colspan="1">
                  <bold>Sequence models</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Combination of base models and feature sets</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Keras Neural Networks via TensorFlow [<xref rid="pone.0274338.ref016" ref-type="bibr">16</xref>]</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Convolutional Neural Networks via TensorFlow [<xref rid="pone.0274338.ref016" ref-type="bibr">16</xref>]</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">PyPREdictor, a reimplementation of the PREdictor [<xref rid="pone.0274338.ref003" ref-type="bibr">3</xref>]</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Dummy PREdictor as used in [<xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>]</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Wrapper for SVM-MOCCA [<xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>]</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Deep-MOCCA</td>
              </tr>
              <tr>
                <td align="left" rowspan="7" colspan="1">
                  <bold>Sequence model features</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Operations on feature sets for the definition of models</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Multi-core processing</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Validation</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Prediction threshold calibration</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Genome-wide prediction</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Multi-class model specification via sequence labels</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Retraining</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t003fn001">
            <p>Gnocis provides a flexible and extensible modelling API, with implementations of a variety of models and integrations with Scikit-learn [<xref rid="pone.0274338.ref015" ref-type="bibr">15</xref>] and TensorFlow [<xref rid="pone.0274338.ref016" ref-type="bibr">16</xref>].</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="sec006">
      <title>A cross-validation workbench for DNA sequence models with support for imbalanced, multi-class data facilitates unbiased assessment of generalization</title>
      <p>An important step when applying machine learning is that of cross-validation, which enables the quantification of model generalization to independent data and the unbiased comparison of models. CRE data is typically imbalanced, with a genome containing relatively few CREs compared to non-CRE regions. Model generalization can be visualized using Receiver Operating Characteristic (ROC) curves and Precision/Recall (PR) curves. PR curves are more informative than ROC curves when data is imbalanced [<xref rid="pone.0274338.ref013" ref-type="bibr">13</xref>]. To our knowledge, no Python cross-validation workbench for imbalanced, multi-class DNA sequence data has been published.</p>
      <p>We seized the opportunity to implement a flexible cross-validation workbench for Gnocis that facilitates analyses of model generalization. The modelling API of Gnocis allows the retraining of models. Our cross-validation workbench takes a training set, which can be multi-class, and a binary test set of positives and controls. In order to reflect random variation, Gnocis constructs independent pairs of training and test sets. In order to facilitate multi-class training, when constructing cross-validation training sets, an equal number of examples are randomly selected without replacement from each class, leaving out a desired minimal number of sequences for testing. This procedure yields a balanced training set. When constructing the test sets, sequences are randomly selected from the positives and negatives with a desired ratio, leaving out any sequences that are included in the corresponding training sets. After constructing the cross-validation training and test sets, Gnocis applies models to the sets in order to measure generalization. In order to aid flexible experimentation, a Gnocis cross-validation is constructed as a class that contains pairs of training and test sets, as well as models to cross-validate, and supports the incremental addition of new models. In order to visualize generalization, the Gnocis cross-validation workbench implements the generation of ROC and PR curves with confidence intervals and integrates with Matplotlib [<xref rid="pone.0274338.ref026" ref-type="bibr">26</xref>].</p>
      <p>Once models have been trained, prediction thresholds can be set and models can be applied for the genome-wide prediction of CREs. The CREs that are predicted can vary depending on the particular training set that was employed. Gnocis implements cross-validated genome-wide prediction, in which the models trained for each cross-validation repeat are applied. When visualizing measures of predictions, means and confidence intervals are calculated and plotted. When visualizing predicted loci, the fraction of model cross-validation repeats that predict each locus is indicated with prediction opacity.</p>
    </sec>
    <sec id="sec007">
      <title>Interactive and reproducible analysis</title>
      <p>The Python read-eval-print loop (REPL) and Jupyter Notebooks [<xref rid="pone.0274338.ref014" ref-type="bibr">14</xref>] enable the user to interactively write and execute code in Python. Jupyter Notebooks furthermore can store all steps and display formatted tables and graphics. Packages that implement human-readable printout or formatted tables of data structures, such as Pandas [<xref rid="pone.0274338.ref023" ref-type="bibr">23</xref>], enable interactive and reproducible data analysis. Matplotlib [<xref rid="pone.0274338.ref026" ref-type="bibr">26</xref>] can generate figures and display them in Jupyter Notebooks, further empowering Python with Jupyter Notebooks as an analytical platform.</p>
      <p>In order to facilitate interactive and reproducible analysis and modelling with Gnocis, we implemented the formatted table output of region sets, sequence sets and extracted feature values. Gnocis implements table objects that can be printed as formatted ASCII text or displayed as formatted HTML tables in Jupyter Notebooks. Additionally, Gnocis tables can be converted to NumPy arrays [<xref rid="pone.0274338.ref022" ref-type="bibr">22</xref>] and Pandas data frames [<xref rid="pone.0274338.ref023" ref-type="bibr">23</xref>]. Gnocis integrates with Matplotlib in order to generate ROC and PR curves for cross-validation and barplots for region overlap statistics. Additionally, Gnocis implements the visualization of genomic regions using Matplotlib.</p>
    </sec>
  </sec>
  <sec sec-type="materials|methods" id="sec008">
    <title>Materials and methods</title>
    <sec id="sec009">
      <title>Genome</title>
      <p>We used the <italic toggle="yes">Drosophila melanogaster</italic> genome assembly R5.57 for all analyses, downloaded from FlyBase [<xref rid="pone.0274338.ref032" ref-type="bibr">32</xref>]. We downloaded genes from Ensembl [<xref rid="pone.0274338.ref033" ref-type="bibr">33</xref>] in GTF-format. The genome and the gene annotations are included with Gnocis in the tutorial folder.</p>
    </sec>
    <sec id="sec010">
      <title>Region sets</title>
      <p>For the Kahn et al. PREs [<xref rid="pone.0274338.ref034" ref-type="bibr">34</xref>], we downloaded coordinates from their Supplementary Table S1 and manually converted them to GFF format. For the Enderle et al. PREs [<xref rid="pone.0274338.ref035" ref-type="bibr">35</xref>], we downloaded coordinates from their Supplementary Table 3 and manually converted them to GFF format. We downloaded peaks for the following factors and marks from ModENCODE [<xref rid="pone.0274338.ref006" ref-type="bibr">6</xref>]: Pc (ID: 3957_1816), Psc (ID: 3960_1817), dRING (ID: 5071_1819) and H3K27me3 (ID: 3955_1820).</p>
    </sec>
    <sec id="sec011">
      <title>Training and cross-validation set</title>
      <p>We based the positives in the training set on Kahn et al. PREs [<xref rid="pone.0274338.ref034" ref-type="bibr">34</xref>] (see above). For the unbiased comparison with known PREs at the <italic toggle="yes">invected</italic> and <italic toggle="yes">vestigial</italic> gene loci, we removed PREs that were within 100kb of the bodies of these genes. We extended each PRE from its centre position to a length of 3kb each. Finally, we extracted the underlying genomic sequences (196 sequences).</p>
      <p>We generated four sets of non-PREs: dummy genomic sequences (as in [<xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>]), dummy PREs (as in [<xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>]), coding sequences (as in [<xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>]) and genomic non-PREs. For dummy genomic sequences, we trained a 4th-order Markov chain genome-wide and generated 19,600 sequences (100 times as many as there are positives). For dummy PREs, we trained a 4th-order Markov chain on the Kahn et al. PREs [<xref rid="pone.0274338.ref034" ref-type="bibr">34</xref>] and generated 19,600 sequences. For coding sequences, we extracted coding regions from the genome annotation (described above) and merged overlapping regions. We then extracted the genomic sequences, concatenated them and split them into 3kb fragments. For genomic non-PREs, we extracted genomic regions that were depleted of Pc, Psc, dRING and H3K27me3 (see above). We then identified all 3kb windows (with a step size of 250) that were not enriched in any of the four markers, merged the PcG-depleted windows and removed regions within 100kb from the <italic toggle="yes">invected</italic> and <italic toggle="yes">vestigial</italic> gene bodies. Finally, we extracted the sequences from the genome and extracted non-overlapping 3kb windows from the sequences.</p>
    </sec>
    <sec id="sec012">
      <title>Cross-validation</title>
      <p>Cross-validation was performed using functionality implemented in Gnocis, using 20 repeats per model. Genome-wide prediction was performed for each of the 20 repeats of each model, and means and confidence intervals calculated for each measure considered. All confidence intervals were calculated using functionality implemented in Scipy [<xref rid="pone.0274338.ref036" ref-type="bibr">36</xref>, <xref rid="pone.0274338.ref037" ref-type="bibr">37</xref>], with a t-distribution with 19 degrees of freedom and the confidence level set to 95%.</p>
    </sec>
    <sec id="sec013">
      <title>PyPREdictor</title>
      <p>We re-implemented the PREdictor [<xref rid="pone.0274338.ref003" ref-type="bibr">3</xref>] with Gnocis using a feature network, henceforth called the PyPREdictor. We trained the PyPREdictor with PREs as positives and dummy PREs as negatives (see above), as we did previously in [<xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>]. We used a step size of 250bp and we used the motifs from [<xref rid="pone.0274338.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>].</p>
    </sec>
    <sec id="sec014">
      <title>SVM-MOCCA</title>
      <p>In our experiments, we used the wrapper for the SVM-MOCCA implementation in the MOCCA suite [<xref rid="pone.0274338.ref038" ref-type="bibr">38</xref>] that is included in Gnocis. We used a window size of 3kb, a step size of 1kb, a quadratic kernel and the motifs from [<xref rid="pone.0274338.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>]. We trained one SVM-MOCCA model with PREs, dummy genomic sequences, dummy PREs and coding sequences (as in [<xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>]), and one SVM-MOCCA model with PREs, dummy PREs, coding sequences and genomic non-PREs. For the core-PRE prediction, we used the default core prediction algorithm implemented in the MOCCA suite.</p>
    </sec>
    <sec id="sec015">
      <title>5-spectrum mismatch SVM</title>
      <p>We trained the 5-spectrum mismatch SVM with a quadratic kernel (polynomial degree 2) using a feature network in Gnocis and CUDA SVM, with PREs as positives and genomic non-PREs as negatives. We used a window size of 500bp and a step size of 250bp.</p>
    </sec>
    <sec id="sec016">
      <title>Convolutional neural network</title>
      <p>We constructed a CNN using TensorFlow and Keras, with four convolutional layers, each with 25 three-nucleotide convolutions and followed by an average pooling layer that halved the resolution of the preceding convolution. The final convolution and average pooling layer is followed by a global max pooling layer and a dense softmax layer for class label prediction. We trained the CNN with PREs, dummy PREs, coding sequences and genomic non-PREs. We used a window size of 500bp and a step size of 250bp.</p>
    </sec>
    <sec id="sec017">
      <title>Deep-MOCCA</title>
      <p>Deep-MOCCA uses a layer of sequence convolutions and dinucleotide convolutions. For efficiency, the input convolutions are followed by an average pooling layer for 10-fold downscaling of resolution. In order to model local motif occurrence combinatorics within a bidirectional cut-off distance, the third layer is a convolution of length 50 (corresponding to 500bp) with constant and equal weights (weight = 1/50), effectively averaging with a sliding window. This is followed by a layer of motif/dinucleotide pairing convolutions of width 1. Finally, a global max pooling layer and a dense softmax layer are used to predict sequence labels. The model architecture is visualized in <xref rid="pone.0274338.g001" ref-type="fig">Fig 1</xref>.</p>
      <fig position="float" id="pone.0274338.g001">
        <object-id pub-id-type="doi">10.1371/journal.pone.0274338.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>Deep-MOCCA schematic.</title>
          <p>Deep-MOCCA is a convolutional neural network architecture that mimics the structure of SVM-MOCCA [<xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>].</p>
        </caption>
        <graphic xlink:href="pone.0274338.g001" position="float"/>
      </fig>
      <p>In our experiments, we used 25 motif convolutions of length 10, 25 dinucleotide convolutions and 25 pairing convolutions. We used a window size of 500bp and a step size of 250bp. We trained Deep-MOCCA with PREs, dummy PREs, coding sequences and genomic non-PREs for 350 epochs.</p>
    </sec>
    <sec id="sec018">
      <title>Software and packages</title>
      <p>The present analyses were performed using Python version 3.8.5 and Gnocis version 0.9.12. For Support Vector Machines, we used the implementation available in Scikit-learn [<xref rid="pone.0274338.ref015" ref-type="bibr">15</xref>] version 0.23.2. For neural networks, we used the TensorFlow [<xref rid="pone.0274338.ref016" ref-type="bibr">16</xref>] version 2.4.1 package for Python. For CuPy, we used version 7.8.0. For the calculation of confidence intervals we used Scipy [<xref rid="pone.0274338.ref036" ref-type="bibr">36</xref>, <xref rid="pone.0274338.ref037" ref-type="bibr">37</xref>] version 1.6.3. For SVM-MOCCA, we used the implementation in the MOCCA suite [<xref rid="pone.0274338.ref038" ref-type="bibr">38</xref>] version 1.4.7.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="sec019">
    <title>Results</title>
    <p>We applied Gnocis to the problem of modelling PREs. The code used to generate all results is available in a Jupyter Notebook on GitHub, at <ext-link xlink:href="https://github.com/bjornbredesen/gnocis/tree/master/tutorial/tutorial.ipynb" ext-link-type="uri">https://github.com/bjornbredesen/gnocis/tree/master/tutorial/tutorial.ipynb</ext-link>.</p>
    <sec id="sec020">
      <title>A quadratic 5-spectrum mismatch SVM achieves moderate generalization to independent PREs without prior motif knowledge</title>
      <p>We have previously found that SVM-MOCCA improves the generalization to independent PREs over the PREdictor [<xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>]. Gnocis implements the k-spectrum kernel, which has previously been applied with SVMs for the prediction of Polycomb targets in <italic toggle="yes">Xenopus tropicalis</italic> [<xref rid="pone.0274338.ref029" ref-type="bibr">29</xref>] and for other regulatory elements [<xref rid="pone.0274338.ref028" ref-type="bibr">28</xref>, <xref rid="pone.0274338.ref039" ref-type="bibr">39</xref>]. An important benefit of the k-spectrum kernel is that no prior motif knowledge is required. Gnocis additionally implements the k-spectrum mismatch kernel [<xref rid="pone.0274338.ref040" ref-type="bibr">40</xref>], which to our knowledge has not previously been applied to PREs. We were interested in how well a k-spectrum mismatch SVM would generalize to PREs.</p>
      <p>We cross-validated the PyPREdictor (re-implementation of the PREdictor [<xref rid="pone.0274338.ref003" ref-type="bibr">3</xref>]), SVM-MOCCA and a 5-spectrum mismatch SVM with PREs and non-PREs (see <xref rid="sec008" ref-type="sec">Materials and methods</xref>). For the PyPREdictor, we used PREs as positives and dummy PREs as negatives (as in [<xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>]). For the 5-spectrum mismatch SVM, we reasoned that the dummy PREs, which model 5-mer occurrence frequencies of PREs, are too similar in the model feature space. For increased realism, we trained the 5-spectrum mismatch SVM with PREs as positives and genomic non-PREs (see <xref rid="sec008" ref-type="sec">Materials and methods</xref>) as negatives. For SVM-MOCCA, we trained one model with PREs as positives and dummy genomic, dummy PREs and coding sequences as negatives, as in [<xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>]. Additionally, we trained an SVM-MOCCA model where we replaced the dummy genomic sequences with genomic non-PREs (SVM-MOCCA T2021). For the k-spectrum mismatch SVM, we used a quadratic (second-degree polynomial) kernel in order to model motif pairing—which is predictive of PREs [<xref rid="pone.0274338.ref003" ref-type="bibr">3</xref>]—, and we set k to 5, since multiple known PRE motifs are 4-mers or 5-mers (GTGT, GCCAT and GAGAG).</p>
      <p>For PREs versus dummy PREs, the quadratic 5-spectrum mismatch SVM achieves a 1.13-fold improvement in PRC AUC over that of the PyPREdictor (<xref rid="pone.0274338.g002" ref-type="fig">Fig 2</xref>, panel A). Both SVM-MOCCA models yield similar and superior generalization over that of the spectrum SVM (<xref rid="pone.0274338.g002" ref-type="fig">Fig 2</xref>, panel A). For PREs versus coding sequences (<xref rid="pone.0274338.g002" ref-type="fig">Fig 2</xref>, panel B), the PyPREdictor and SVM-MOCCA achieve high generalization (PRC AUC &gt;60%), and the 5-spectrum mismatch SVM achieves moderate generalization (PRC AUC &gt;30%). We also trained the quadratic 5-spectrum mismatch SVM with PREs and dummy PREs, which resulted in overfitting to the negative training set and close to random generalization with other negative test sets (<xref rid="pone.0274338.s001" ref-type="supplementary-material">S1 Fig</xref>).</p>
      <fig position="float" id="pone.0274338.g002">
        <object-id pub-id-type="doi">10.1371/journal.pone.0274338.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>Cross-validation Precision/Recall curves.</title>
          <p>We cross-validated our models trained with PREs and non-PREs, and tested with independent A) PREs versus dummy PREs and B) PREs versus coding sequences.</p>
        </caption>
        <graphic xlink:href="pone.0274338.g002" position="float"/>
      </fig>
      <p>In conclusion, the quadratic 5-spectrum mismatch SVM achieves moderate generalization to independent PREs, without prior motif knowledge. The moderate generalization to PREs versus dummy PREs indicates that the spectrum SVM learns to model motif pair occurrence frequencies. Overall, the quadratic 5-spectrum mismatch SVM achieves respectable generalization to independent PREs without prior motif knowledge. However, SVM-MOCCA—which uses known motifs—yields superior generalization.</p>
    </sec>
    <sec id="sec021">
      <title>GPU-based SVM application reduces running time by an order of magnitude</title>
      <p>Gnocis implements support for multiprocessing for machine learning models. Additionally, for SVMs, Gnocis implements GPU-based model application. We were interested in how the parallelism implemented in Gnocis affects run-time performance.</p>
      <p>In order to yield a fair comparison, we trained three 5-spectrum mismatch kernel SVMs on the same data (PREs as positives and genomic non-PREs as negatives) and the same hyper-parameters (quadratic kernel): one with multiprocessing disabled, one with multiprocessing enabled (12 processes) and one with GPU-based application. We timed the application of each SVM to the same set of 19,600 dummy genomic sequences. The run-times are listed in <xref rid="pone.0274338.t004" ref-type="table">Table 4</xref>.</p>
      <table-wrap position="float" id="pone.0274338.t004">
        <object-id pub-id-type="doi">10.1371/journal.pone.0274338.t004</object-id>
        <label>Table 4</label>
        <caption>
          <title>Multiprocessing and GPU application of SVMs significantly reduces run-times.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pone.0274338.t004" id="pone.0274338.t004g" position="float"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Application method</th>
                <th align="left" rowspan="1" colspan="1">Running time (h:mm:ss)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">1 core</td>
                <td align="left" rowspan="1" colspan="1">0:10:24</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">12 cores/threads</td>
                <td align="left" rowspan="1" colspan="1">0:05:18</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GPU</td>
                <td align="left" rowspan="1" colspan="1">0:01:28</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t004fn001">
            <p>We applied a quadratic 5-spectrum mismatch SVM to 19,600 3kb-long dummy genomic sequences using a single core, twelve cores/threads and a GPU. CPU: Intel Core i9–9900K, 3.6 GHz, 8 cores, 16 threads. GPU: GeForce GTX 980.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Multiprocessing almost halves the running time. GPU-based model application further improves running time, shortening it to almost a tenth of the single-threaded model application.</p>
      <p>In conclusion, parallel application of SVMs significantly reduces run-time cost. That multithreaded run-time cost does not scale with the number of threads can be attributed to how Python implements multiprocessing. GPU-based application of SVMs further reduces running time by an order of magnitude.</p>
    </sec>
    <sec id="sec022">
      <title>Convolutional neural networks achieve low to moderate generalization to PREs</title>
      <p>Convolutional neural networks (CNNs) [<xref rid="pone.0274338.ref041" ref-type="bibr">41</xref>] have recently shown great success in computer vision [<xref rid="pone.0274338.ref012" ref-type="bibr">12</xref>]. A successful CNN architecture in computer vision is one with multiple layers of small convolutions, combined by pooling layers [<xref rid="pone.0274338.ref012" ref-type="bibr">12</xref>]. A convolution over one-hot-encoded DNA sequences is effectively a Position Weight Matrix (PWM). CNNs have not previously been applied to the task of modelling PREs, and we were interested in how well CNNs would perform in this modelling task.</p>
      <p>We trained a CNN with four layers of 25 3bp convolutions each (see <xref rid="sec008" ref-type="sec">Materials and methods</xref>), and a dense softmax layer with four classes: PREs, dummy PREs, coding sequences and genomic non-PREs.</p>
      <p>The CNN achieved low generalization (PRC AUC &lt;20%) to PREs versus dummy PREs (<xref rid="pone.0274338.g002" ref-type="fig">Fig 2</xref>, panel A), and moderate generalization (PRC AUC &gt;30%) to PREs versus coding sequences (<xref rid="pone.0274338.g002" ref-type="fig">Fig 2</xref>, panel B).</p>
      <p>In summary, a multilayer CNN with short convolutions achieves low to moderate generalization to independent PREs. The low generalization might be attributed to multiple factors. The CNN preserves positional information, which previous models do not, and which increases model complexity but may be irrelevant to the modelling problem. It is also possible that tuning the number of layers, the number of convolutions per layer and the length of the convolutions may improve generalization.</p>
    </sec>
    <sec id="sec023">
      <title>The convolutional neural network architecture Deep-MOCCA improves the state-of-the-art of PRE models without prior motif knowledge</title>
      <p>There is significant freedom in how artificial neural networks can be architected. Inspired by this freedom and the high generalization of SVM-MOCCA to independent PREs [<xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>], we were interested in how an artificial neural network architecture with similar model structure would perform at the task of modelling PREs.</p>
      <p>We designed Deep-MOCCA, a convolutional neural network architecture that mimics the structure of SVM-MOCCA by modelling local motif occurrence combinatorics and dinucleotide patterns but without the need for prior motif knowledge. The model architecture is described in detail in Materials and methods. In order to learn motifs, Deep-MOCCA has a layer of longer convolutions, and in order to model dinucleotides, a layer of 2bp convolutions. These two convolutional layers are concatenated. In order to model local motif occurrence combinatorics, Deep-MOCCA uses a sliding window averaging layer and a layer of single-nucleotide pairing convolutions. Finally, Deep-MOCCA outputs predicted class probabilities with a dense softmax layer. We trained Deep-MOCCA with four classes: PREs, dummy PREs, coding sequences and genomic non-PREs.</p>
      <p>Deep-MOCCA achieves the highest generalization to PREs versus dummy PREs of all models tested, with a 1.31-fold improvement in PRC AUC over that of SVM-MOCCA (<xref rid="pone.0274338.g002" ref-type="fig">Fig 2</xref>, panel A). For PREs versus coding sequences, Deep-MOCCA achieves a lower generalization than that of SVM-MOCCA, but a higher one than the 5-spectrum mismatch SVM and the conventional CNN (1.35-fold improvement in PRC AUC; <xref rid="pone.0274338.g002" ref-type="fig">Fig 2</xref>, panel B).</p>
      <p>In summary, we have developed a convolutional neural network architecture, Deep-MOCCA, that improves the state-of-the art for PRE models that require no prior motif knowledge by exploiting prior knowledge about successful PRE sequence model structure (SVM-MOCCA [<xref rid="pone.0274338.ref007" ref-type="bibr">7</xref>]). Deep-MOCCA significantly improves generalization over a more conventional CNN with more layers and smaller convolutions. Part of the improvement in Deep-MOCCA over the conventional CNN may be attributed to a lower model complexity (Deep-MOCCA has 2,629 trainable parameters, the conventional CNN has 6,129), which in turn may reduce overfitting. Also, Deep-MOCCA discards spatial information beyond local pairing. When motifs are known, there is still a benefit in including these motifs in PRE models, as SVM-MOCCA achieves superior generalization to PREs versus coding sequences. Gnocis includes an implementation of Deep-MOCCA that can be adapted to new modelling problems.</p>
    </sec>
    <sec id="sec024">
      <title>Deep-MOCCA precisely predicts independent PREs without prior motif knowledge</title>
      <p>We were interested in how well models implemented in Gnocis can predict PREs genome-wide.</p>
      <p>We calibrated the prediction threshold of each model (six models with 20 cross-validation repeats each) for an expected genome-wide precision of 80%, based on independent PREs from the corresponding cross-validation test set and a 7th-order Markov chain trained genome-wide. We then applied each model genome-wide for prediction of candidate PREs using a sliding window, predicting windows with scores above the prediction threshold and merging overlapping predictions. For SVM-MOCCA, we additionally predicted core-PREs using the algorithm from the MOCCA suite [<xref rid="pone.0274338.ref038" ref-type="bibr">38</xref>]. For validation of predictions, we did not train on regions from the <italic toggle="yes">invected</italic> and <italic toggle="yes">vestigial</italic> loci, where multiple known PREs reside. Additionally, we extracted the subset of PREs from Enderle et al. (2011) [<xref rid="pone.0274338.ref035" ref-type="bibr">35</xref>] that are at least 1kb away from all PREs from the Kahn et al. (2014) [<xref rid="pone.0274338.ref034" ref-type="bibr">34</xref>] set.</p>
      <p>Of the models tested, the quadratic 5-spectrum mismatch SVM yielded the largest number of candidate PRE predictions genome-wide and Deep-MOCCA the second largest (<xref rid="pone.0274338.g003" ref-type="fig">Fig 3</xref>). Training the SVM-MOCCA model with genomic non-PREs instead of dummy genomic sequences resulted in a drop of the number of predictions. At the <italic toggle="yes">invected</italic> locus, Deep-MOCCA predicts three known PREs (<xref rid="pone.0274338.g004" ref-type="fig">Fig 4</xref>, panel A). At the <italic toggle="yes">vestigial</italic> locus, Deep-MOCCA predicts one known PRE for the majority of cross-validation repeats, and another known PRE for a subset of repeats (<xref rid="pone.0274338.g004" ref-type="fig">Fig 4</xref>, panel B). In addition, Deep-MOCCA predicts multiple other regions for subsets of repeats. At the <italic toggle="yes">invected</italic> locus, the 5-spectrum SVM and both SVM-MOCCA models predict two out of three known PREs (<xref rid="pone.0274338.g004" ref-type="fig">Fig 4</xref>, panel A). At the <italic toggle="yes">vestigial</italic> locus, the 5-spectrum SVM predicts one known PRE, both SVM-MOCCA models predict one (different) known PRE, and the SVM-MOCCA model trained with dummy genomic sequences predicts an additional PRE (<xref rid="pone.0274338.g004" ref-type="fig">Fig 4</xref>, panel B). The conventional CNN predicts no known PREs for either of the two loci. Of the models tested, the quadratic 5-spectrum mismatch SVM achieves the highest sensitivity to independent PREs from [<xref rid="pone.0274338.ref035" ref-type="bibr">35</xref>], with Deep-MOCCA in second and SVM-MOCCA in third (<xref rid="pone.0274338.g005" ref-type="fig">Fig 5</xref>). SVM-MOCCA trained with genomic non-PREs achieves the highest nucleotide precision (fraction of predicted nucleotides that land inside a [<xref rid="pone.0274338.ref035" ref-type="bibr">35</xref>] PRE), with the PyPREdictor in second place, SVM-MOCCA trained with dummy genomic sequences in third and Deep-MOCCA in fourth.</p>
      <fig position="float" id="pone.0274338.g003">
        <object-id pub-id-type="doi">10.1371/journal.pone.0274338.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <title>Numbers of predictions.</title>
        </caption>
        <graphic xlink:href="pone.0274338.g003" position="float"/>
      </fig>
      <fig position="float" id="pone.0274338.g004">
        <object-id pub-id-type="doi">10.1371/journal.pone.0274338.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <title>Predictions at the A) <italic toggle="yes">invected</italic> and B) <italic toggle="yes">vestigial</italic> loci.</title>
          <p>Visualized using the Gnocis genomic track plotting, which uses Matplotlib [<xref rid="pone.0274338.ref026" ref-type="bibr">26</xref>]. Opaque predictions are predicted in the majority of cross-validation repeats, and semi-transparent predictions in a subset of repeats.</p>
        </caption>
        <graphic xlink:href="pone.0274338.g004" position="float"/>
      </fig>
      <fig position="float" id="pone.0274338.g005">
        <object-id pub-id-type="doi">10.1371/journal.pone.0274338.g005</object-id>
        <label>Fig 5</label>
        <caption>
          <title>Prediction overlap with experimental data.</title>
          <p>A) Overlap sensitivity of predictions to Enderle et al. (2011) [<xref rid="pone.0274338.ref035" ref-type="bibr">35</xref>] PREs. B) Nucleotide precision of predictions to Enderle et al. (2011) [<xref rid="pone.0274338.ref035" ref-type="bibr">35</xref>] PREs. In order to avoid bias, for the calculations in both A) and B), we removed PREs from [<xref rid="pone.0274338.ref035" ref-type="bibr">35</xref>] and predictions that were within 1kb of overlapping with a Kahn et al. (2014) [<xref rid="pone.0274338.ref034" ref-type="bibr">34</xref>] PRE.</p>
        </caption>
        <graphic xlink:href="pone.0274338.g005" position="float"/>
      </fig>
      <p>In conclusion, Deep-MOCCA precisely predicts independent PREs without prior motif knowledge. Of the models tested without prior motif knowledge, Deep-MOCCA achieves the second highest sensitivity and the highest nucleotide precision. Nucleotide precision is low for all models (&lt;13%), which is expected if experimental signals of PcG-binding may be shifted from the PREs. Furthermore, our models may predict PREs that are not active in the cells that Enderle et al. (2011) [<xref rid="pone.0274338.ref035" ref-type="bibr">35</xref>] used.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec025">
    <title>Discussion</title>
    <p>Gnocis is a versatile and extensible system for interactive and reproducible analysis and modelling of CRE sequences, and for predicting candidate CREs genome-wide. Gnocis fills a gap left by existing Python packages by implementing the base functionality that is necessary in order to efficiently combine machine learning methods and feature sets. Gnocis provides data preparation facilities and feature-rich APIs for feature set and model specification and application. The data preparation facilities implement common data preparation operations and employ standardized file formats, streamlining the use of published data, integration with external tools and collaboration. In addition to being useful for the preparation and handling of data for CRE machine learning, the data handling facilities in Gnocis can also be useful for general DNA sequence bioinformatics.</p>
    <p>The Gnocis feature set API provides the user with a flexible vocabulary for the specification and application of sequence feature sets, with integration with NumPy [<xref rid="pone.0274338.ref022" ref-type="bibr">22</xref>] and Pandas [<xref rid="pone.0274338.ref023" ref-type="bibr">23</xref>] for advanced analyses. In order to enable efficient feature extraction, feature sets in Gnocis are implemented as graphs that can be transformed via a variety of operations. This enables the user to specify feature sets and models with a short syntax, and simplifies retraining, for example for cross-validation. To our knowledge, Gnocis is the first DNA sequence feature package for Python to employ this design. The modelling API implements common procedures for model validation and prediction. For additional efficiency, the modelling API implements multiprocessing support.</p>
    <p>When multiple candidate models are available, it is useful to have a platform for unbiased benchmarking. Gnocis provides a cross-validation engine that constructs multiple training and test sets, trains and applies models, and calculates measures of generalization. The Gnocis cross-validation engine supports imbalanced, multi-class data.</p>
    <p>In order to facilitate interactive data analysis and modelling, Gnocis integrates with IPython [<xref rid="pone.0274338.ref021" ref-type="bibr">21</xref>] and Matplotlib [<xref rid="pone.0274338.ref026" ref-type="bibr">26</xref>]. Gnocis outputs tables for sequence feature enrichment, simplifying interactive analysis. Gnocis also implements visualization of model generalization via Receiver Operating Characteristic (ROC) and Precision/Recall curves, with means and confidence intervals visualized for cross-validation. In order to probe predictions at genomic loci of interest, Gnocis implements visualization of genomic tracks, enabling visual inspection of genomic loci in Jupyter Notebooks [<xref rid="pone.0274338.ref014" ref-type="bibr">14</xref>].</p>
    <p>To demonstrate the utility and ease of use of Gnocis, we applied six models for the prediction of PREs: the PyPREdictor (a Python re-implementation of the PREdictor method [<xref rid="pone.0274338.ref003" ref-type="bibr">3</xref>]), a quadratic 5-spectrum mismatch SVM, a (conventional) CNN, two versions of SVM-MOCCA, and Deep-MOCCA—a neural network architecture inspired by SVM-MOCCA. The 5-spectrum SVM achieves the highest sensitivity to independent PREs, but also the lowest precision. Deep-MOCCA achieves the second highest sensitivity to independent PREs and the highest precision of models without prior motif knowledge. SVM-MOCCA achieves the highest precision of the models tested. Our present work is the first to apply Convolutional Neural Networks to the modelling of PRE sequences. Notably, there are numerous potential network structures that can be employed for a CNN, and other network architectures may outperform the ones we tested here. Gnocis provides the user with the tools necessary in order to test new neural network architectures. Additionally, Gnocis includes Deep-MOCCA, which can be trained on new problems. We previously demonstrated the applicability of SVM-MOCCA to new problems by training it to predict Boundary Elements [<xref rid="pone.0274338.ref038" ref-type="bibr">38</xref>]. We expect similar broader applicability for Deep-MOCCA, and as Deep-MOCCA requires no prior motif knowledge, it may also be interesting to apply it to problems where motif knowledge is lacking. Gnocis is species agnostic and our methods can be trained for prediction tasks in other species where appropriate data can be collected. For example, Support Vector Machines have previously been applied for modelling H3K27me3 nucleation sites in Western clawed frog (<italic toggle="yes">X. tropicalis</italic>) [<xref rid="pone.0274338.ref029" ref-type="bibr">29</xref>], and methods implemented in Gnocis could in principle be trained using the same or similar data.</p>
    <p>The PyPI package manager makes Gnocis easy to install on multiple operating systems and, with Gnocis having no dependencies, further improves the portability of our package. In addition to internally implementing a broad suite for data preparation, Gnocis abstractly implements DNA sequence feature spaces and sequence modelling, facilitating the exploration of different modelling approaches, both in terms of feature space definitions and of machine learning methods. The suite of tools that Gnocis provides can aid in elucidating the sequence criteria that define a CRE class, and in predicting new CREs genome-wide.</p>
  </sec>
  <sec id="sec026">
    <title>Software availability and requirements</title>
    <list list-type="bullet">
      <list-item>
        <p>Project name: Gnocis</p>
      </list-item>
      <list-item>
        <p>Project home page: <ext-link xlink:href="https://github.com/bjornbredesen/gnocis" ext-link-type="uri">https://github.com/bjornbredesen/gnocis</ext-link></p>
      </list-item>
      <list-item>
        <p>Operating systems: GNU/Linux, Windows, MacOS X</p>
      </list-item>
      <list-item>
        <p>Programming languages: Python, Cython</p>
      </list-item>
      <list-item>
        <p>Requirements: Python 3.6/3.7/3.8/3.9</p>
      </list-item>
      <list-item>
        <p>License: MIT license</p>
      </list-item>
    </list>
    <p>The code for generating all results presented here is available as Jupyter Notebooks on the Gnocis GitHub repository.</p>
  </sec>
  <sec id="sec027" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pone.0274338.s001" position="float" content-type="local-data">
      <label>S1 Fig</label>
      <caption>
        <title>Training with dummy PREs as negatives leads to overfitting to the training classes.</title>
        <p>Shown are the dummy PREdictor, the PyPREdictor trained with PREs (positives) and dummy PREs (negatives), a quadratic 5-spectrum mismatch kernel SVM trained with PREs (positives) and genomic non-PREs (negatives) and finally a quadratic 5-spectrum mismatch kernel SVM trained with PREs (positives) and dummy PREs (negatives). Models were tested with A) PREs versus dummy PREs, B) PREs versus coding sequences and C) PREs versus genomic non-PREs. AUC is high for the SVM trained with dummy PREs when tested with dummy PREs (A) but low otherwise (B, C).</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pone.0274338.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="pone.0274338.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Hardison</surname><given-names>RC</given-names></name>, <name><surname>Taylor</surname><given-names>J</given-names></name>. <article-title>Genomic approaches towards finding cis-regulatory modules in animals</article-title>. <source>Nat Rev Genet</source>. <year>2012</year>;<volume>13</volume>(<issue>7</issue>):<fpage>469</fpage>–<lpage>483</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nrg3242</pub-id><?supplied-pmid 22705667?><pub-id pub-id-type="pmid">22705667</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Wittkopp</surname><given-names>PJ</given-names></name>, <name><surname>Kalay</surname><given-names>G</given-names></name>. <article-title>Cis-regulatory elements: molecular mechanisms and evolutionary processes underlying divergence</article-title>. <source>Nat Rev Genet</source>. <year>2012</year>;<volume>13</volume>(<issue>1</issue>):<fpage>59</fpage>–<lpage>69</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nrg3095</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Ringrose</surname><given-names>L</given-names></name>, <name><surname>Rehmsmeier</surname><given-names>M</given-names></name>, <name><surname>Dura</surname><given-names>JM</given-names></name>, <name><surname>Paro</surname><given-names>R</given-names></name>. <article-title>Genome-Wide Prediction of Polycomb/Trithorax Response Elements in Drosophila melanogaster</article-title>. <source>Dev Cell</source>. <year>2003</year>;<volume>5</volume>(<issue>5</issue>):<fpage>759</fpage>–<lpage>771</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/S1534-5807(03)00337-X</pub-id><?supplied-pmid 14602076?><pub-id pub-id-type="pmid">14602076</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Chetverina</surname><given-names>D</given-names></name>, <name><surname>Aoki</surname><given-names>T</given-names></name>, <name><surname>Erokhin</surname><given-names>M</given-names></name>, <name><surname>Georgiev</surname><given-names>P</given-names></name>, <name><surname>Schedl</surname><given-names>P</given-names></name>. <article-title>Making connections: Insulators organize eukaryotic chromosomes into independent cis-regulatory networks</article-title>. <source>Bioessays</source>. <year>2014</year>;<volume>36</volume>(<issue>2</issue>):<fpage>163</fpage>–<lpage>172</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/bies.201300125</pub-id><?supplied-pmid 24277632?><pub-id pub-id-type="pmid">24277632</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>D’haeseleer</surname><given-names>P</given-names></name>. <article-title>What are DNA sequence motifs?</article-title><source>Nat Biotechnol</source>. <year>2006</year>;<volume>24</volume>(<issue>4</issue>):<fpage>423</fpage>–<lpage>425</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nbt0406-423</pub-id><?supplied-pmid 16601727?><pub-id pub-id-type="pmid">16601727</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Celniker</surname><given-names>SE</given-names></name>, <name><surname>Dillon</surname><given-names>LA</given-names></name>, <name><surname>Gerstein</surname><given-names>MB</given-names></name>, <name><surname>Gunsalus</surname><given-names>KC</given-names></name>, <name><surname>Henikoff</surname><given-names>S</given-names></name>, <name><surname>Karpen</surname><given-names>GH</given-names></name>, <etal>et al</etal>. <article-title>Unlocking the secrets of the genome</article-title>. <source>Nature</source>. <year>2009</year>;<volume>459</volume>(<issue>7249</issue>):<fpage>927</fpage>–<lpage>930</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/459927a</pub-id><?supplied-pmid 19536255?><pub-id pub-id-type="pmid">19536255</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Bredesen</surname><given-names>BA</given-names></name>, <name><surname>Rehmsmeier</surname><given-names>M</given-names></name>. <article-title>DNA sequence models of genome-wide Drosophila melanogaster Polycomb binding sites improve generalization to independent Polycomb Response Elements</article-title>. <source>Nucleic Acids Res</source>. <year>2019</year>;<volume>47</volume>(<issue>15</issue>):<fpage>7781</fpage>–<lpage>7797</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkz617</pub-id><?supplied-pmid 31340029?><pub-id pub-id-type="pmid">31340029</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Steffen</surname><given-names>PA</given-names></name>, <name><surname>Ringrose</surname><given-names>L</given-names></name>. <article-title>What are memories made of? How Polycomb and Trithorax proteins mediate epigenetic memory</article-title>. <source>Nat Rev Mol Cell Biol</source>. <year>2014</year>;<volume>15</volume>(<issue>5</issue>):<fpage>340</fpage>–<lpage>356</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nrm3789</pub-id><?supplied-pmid 24755934?><pub-id pub-id-type="pmid">24755934</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Cortes</surname><given-names>C</given-names></name>, <name><surname>Vapnik</surname><given-names>V</given-names></name>. <article-title>Support-vector networks</article-title>. <source>Mach Learn</source>. <year>1995</year>;<volume>20</volume>(<issue>3</issue>):<fpage>273</fpage>–<lpage>297</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/BF00994018</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Breiman</surname><given-names>L</given-names></name>. <article-title>Random forests</article-title>. <source>Mach Learn</source>. <year>2001</year>;<volume>45</volume>(<issue>1</issue>):<fpage>5</fpage>–<lpage>32</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Ben-Hur</surname><given-names>A</given-names></name>, <name><surname>Ong</surname><given-names>CS</given-names></name>, <name><surname>Sonnenburg</surname><given-names>S</given-names></name>, <name><surname>Schölkopf</surname><given-names>B</given-names></name>, <name><surname>Rätsch</surname><given-names>G</given-names></name>. <article-title>Support Vector Machines and Kernels for Computational Biology</article-title>. <source>PLoS Comput Biol</source>. <year>2008</year>;<volume>4</volume>(<issue>10</issue>):<fpage>e1000173</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000173</pub-id><?supplied-pmid 18974822?><pub-id pub-id-type="pmid">18974822</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref012">
      <label>12</label>
      <mixed-citation publication-type="book"><name><surname>Krizhevsky</surname><given-names>A</given-names></name>, <name><surname>Sutskever</surname><given-names>I</given-names></name>, <name><surname>Hinton</surname><given-names>GE</given-names></name>. <part-title>ImageNet Classification with Deep Convolutional Neural Networks</part-title>. In: <name><surname>Pereira</surname><given-names>F</given-names></name>, <name><surname>Burges</surname><given-names>CJ</given-names></name>, <name><surname>Bottou</surname><given-names>L</given-names></name>, <name><surname>Weinberger</surname><given-names>KQ</given-names></name>, editors. <source>Advances in Neural Information Processing Systems</source>. <volume>vol. 25</volume>. <publisher-name>Curran Associates, Inc.</publisher-name>; <year>2012</year>. Available from: <ext-link xlink:href="https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf" ext-link-type="uri">https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0274338.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Saito</surname><given-names>T</given-names></name>, <name><surname>Rehmsmeier</surname><given-names>M</given-names></name>. <article-title>The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets</article-title>. <source>PloS One</source>. <year>2015</year>;<volume>10</volume>(<issue>3</issue>):<fpage>e0118432</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0118432</pub-id><?supplied-pmid 25738806?><pub-id pub-id-type="pmid">25738806</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref014">
      <label>14</label>
      <mixed-citation publication-type="book"><name><surname>Kluyver</surname><given-names>T</given-names></name>, <name><surname>Ragan-Kelley</surname><given-names>B</given-names></name>, <name><surname>Pérez</surname><given-names>F</given-names></name>, <name><surname>Granger</surname><given-names>BE</given-names></name>, <name><surname>Bussonnier</surname><given-names>M</given-names></name>, <name><surname>Frederic</surname><given-names>J</given-names></name>, <etal>et al</etal>. <part-title>Jupyter Notebooks—a publishing format for reproducible computational workflows</part-title>. In: <name><surname>Loizides</surname><given-names>F</given-names></name>, <name><surname>Schmidt</surname><given-names>B</given-names></name>, editors. <source>Positioning and Power in Academic Publishing: Players, Agents and Agendas</source>. <publisher-name>IOS Press</publisher-name>; <year>2016</year>. p. <fpage>87</fpage>–<lpage>90</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0274338.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Gramfort</surname><given-names>A</given-names></name>, <name><surname>Michel</surname><given-names>V</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <name><surname>Grisel</surname><given-names>O</given-names></name>, <etal>et al</etal>. <article-title>Scikit-learn: Machine learning in Python</article-title>. <source>J Mach Learn Res</source>. <year>2011</year>;<volume>12</volume>:<fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0274338.ref016">
      <label>16</label>
      <mixed-citation publication-type="other">Abadi M, Agarwal A, Barham P, Brevdo E, Chen Z, Citro C, et al.. TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems; 2015. Available from: <ext-link xlink:href="https://www.tensorflow.org/" ext-link-type="uri">https://www.tensorflow.org/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0274338.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Cock</surname><given-names>PJ</given-names></name>, <name><surname>Antao</surname><given-names>T</given-names></name>, <name><surname>Chang</surname><given-names>JT</given-names></name>, <name><surname>Chapman</surname><given-names>BA</given-names></name>, <name><surname>Cox</surname><given-names>CJ</given-names></name>, <name><surname>Dalke</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Biopython: freely available Python tools for computational molecular biology and bioinformatics</article-title>. <source>Bioinformatics</source>. <year>2009</year>;<volume>25</volume>(<issue>11</issue>):<fpage>1422</fpage>–<lpage>1423</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btp163</pub-id><?supplied-pmid 19304878?><pub-id pub-id-type="pmid">19304878</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>B</given-names></name>, <name><surname>Liu</surname><given-names>F</given-names></name>, <name><surname>Fang</surname><given-names>L</given-names></name>, <name><surname>Wang</surname><given-names>X</given-names></name>, <name><surname>Chou</surname><given-names>KC</given-names></name>. <article-title>repDNA: a Python package to generate various modes of feature vectors for DNA sequences by incorporating user-defined physicochemical properties and sequence-order effects</article-title>. <source>Bioinformatics</source>. <year>2015</year>;<volume>31</volume>(<issue>8</issue>):<fpage>1307</fpage>–<lpage>1309</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btu820</pub-id><?supplied-pmid 25504848?><pub-id pub-id-type="pmid">25504848</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Muhammod</surname><given-names>R</given-names></name>, <name><surname>Ahmed</surname><given-names>S</given-names></name>, <name><surname>Md Farid</surname><given-names>D</given-names></name>, <name><surname>Shatabda</surname><given-names>S</given-names></name>, <name><surname>Sharma</surname><given-names>A</given-names></name>, <name><surname>Dehzangi</surname><given-names>A</given-names></name>. <article-title>PyFeat: a Python-based effective feature generation tool for DNA, RNA and protein sequences</article-title>. <source>Bioinformatics</source>. <year>2019</year>;<volume>35</volume>(<issue>19</issue>):<fpage>3831</fpage>–<lpage>3833</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btz165</pub-id><?supplied-pmid 30850831?><pub-id pub-id-type="pmid">30850831</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Blakely</surname><given-names>D</given-names></name>, <name><surname>Collins</surname><given-names>E</given-names></name>, <name><surname>Singh</surname><given-names>R</given-names></name>, <name><surname>Norton</surname><given-names>A</given-names></name>, <name><surname>Lanchantin</surname><given-names>J</given-names></name>, <name><surname>Qi</surname><given-names>Y</given-names></name>. <article-title>FastSK: fast sequence analysis with gapped string kernels</article-title>. <source>Bioinformatics</source>. <year>2020</year>;<volume>36</volume>(<issue>Supplement_2</issue>):<fpage>i857</fpage>–<lpage>i865</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btaa817</pub-id><?supplied-pmid 33381828?><pub-id pub-id-type="pmid">33381828</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Pérez</surname><given-names>F</given-names></name>, <name><surname>Granger</surname><given-names>BE</given-names></name>. <article-title>IPython: a system for interactive scientific computing</article-title>. <source>Comput Sci Eng</source>. <year>2007</year>;<volume>9</volume>(<issue>3</issue>):<fpage>21</fpage>–<lpage>29</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/MCSE.2007.53</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>van der Walt</surname><given-names>S</given-names></name>, <name><surname>Colbert</surname><given-names>SC</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>. <article-title>The NumPy array: a structure for efficient numerical computation</article-title>. <source>Comput Sci Eng</source>. <year>2011</year>;<volume>13</volume>(<issue>2</issue>):<fpage>22</fpage>–<lpage>30</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/MCSE.2011.37</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref023">
      <label>23</label>
      <mixed-citation publication-type="other">McKinney W. Data Structures for Statistical Computing in Python. In: Stéfan van der Walt, Jarrod Millman, editors. Proceedings of the 9th Python in Science Conference; 2010. p. 56 – 61.</mixed-citation>
    </ref>
    <ref id="pone.0274338.ref024">
      <label>24</label>
      <mixed-citation publication-type="other">The pandas development team. pandas-dev/pandas: Pandas; 2020. Available from: <pub-id pub-id-type="doi">10.5281/zenodo.3509134</pub-id>.</mixed-citation>
    </ref>
    <ref id="pone.0274338.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Dale</surname><given-names>RK</given-names></name>, <name><surname>Pedersen</surname><given-names>BS</given-names></name>, <name><surname>Quinlan</surname><given-names>AR</given-names></name>. <article-title>Pybedtools: a flexible Python library for manipulating genomic datasets and annotations</article-title>. <source>Bioinformatics</source>. <year>2011</year>;<volume>27</volume>(<issue>24</issue>):<fpage>3423</fpage>–<lpage>3424</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btr539</pub-id><?supplied-pmid 21949271?><pub-id pub-id-type="pmid">21949271</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Hunter</surname><given-names>JD</given-names></name>. <article-title>Matplotlib: A 2D graphics environment</article-title>. <source>Comput Sci Eng</source>. <year>2007</year>;<volume>9</volume>(<issue>3</issue>):<fpage>90</fpage>–<lpage>95</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref027">
      <label>27</label>
      <mixed-citation publication-type="journal"><name><surname>Zeng</surname><given-names>J</given-names></name>, <name><surname>Kirk</surname><given-names>BD</given-names></name>, <name><surname>Gou</surname><given-names>Y</given-names></name>, <name><surname>Wang</surname><given-names>Q</given-names></name>, <name><surname>Ma</surname><given-names>J</given-names></name>. <article-title>Genome-wide polycomb target gene prediction in Drosophila melanogaster</article-title>. <source>Nucleic Acids Res</source>. <year>2012</year>;<volume>40</volume>(<issue>13</issue>):<fpage>5848</fpage>–<lpage>5863</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gks209</pub-id><?supplied-pmid 22416065?><pub-id pub-id-type="pmid">22416065</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Lee</surname><given-names>D</given-names></name>, <name><surname>Karchin</surname><given-names>R</given-names></name>, <name><surname>Beer</surname><given-names>MA</given-names></name>. <article-title>Discriminative prediction of mammalian enhancers from DNA sequence</article-title>. <source>Genome Res</source>. <year>2011</year>;<volume>21</volume>(<issue>12</issue>):<fpage>2167</fpage>–<lpage>2180</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1101/gr.121905.111</pub-id><?supplied-pmid 21875935?><pub-id pub-id-type="pmid">21875935</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>van Heeringen</surname><given-names>SJ</given-names></name>, <name><surname>Akkers</surname><given-names>RC</given-names></name>, <name><surname>van Kruijsbergen</surname><given-names>I</given-names></name>, <name><surname>Arif</surname><given-names>MA</given-names></name>, <name><surname>Hanssen</surname><given-names>LL</given-names></name>, <name><surname>Sharifi</surname><given-names>N</given-names></name>, <etal>et al</etal>. <article-title>Principles of nucleation of H3K27 methylation during embryonic development</article-title>. <source>Genome Res</source>. <year>2014</year>;<volume>24</volume>(<issue>3</issue>):<fpage>401</fpage>–<lpage>410</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1101/gr.159608.113</pub-id><?supplied-pmid 24336765?><pub-id pub-id-type="pmid">24336765</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref030">
      <label>30</label>
      <mixed-citation publication-type="other">Okuta R, Unno Y, Nishino D, Hido S, Loomis C. CuPy: A NumPy-Compatible Library for NVIDIA GPU Calculations. In: Workshop on Machine Learning Systems (LearningSys) in The Thirty-first Annual Conference on Neural Information Processing Systems (NIPS); 2017. Available from: <ext-link xlink:href="http://learningsys.org/nips17/" ext-link-type="uri">http://learningsys.org/nips17/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0274338.ref031">
      <label>31</label>
      <mixed-citation publication-type="other">Chollet F, et al.. Keras; 2015. <ext-link xlink:href="https://keras.io" ext-link-type="uri">https://keras.io</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0274338.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Marygold</surname><given-names>SJ</given-names></name>, <name><surname>Leyland</surname><given-names>PC</given-names></name>, <name><surname>Seal</surname><given-names>RL</given-names></name>, <name><surname>Goodman</surname><given-names>JL</given-names></name>, <name><surname>Thurmond</surname><given-names>J</given-names></name>, <name><surname>Strelets</surname><given-names>VB</given-names></name>, <etal>et al</etal>. <article-title>FlyBase: improvements to the bibliography</article-title>. <source>Nucleic Acids Res</source>. <year>2012</year>;<volume>41</volume>(<issue>D1</issue>):<fpage>D751</fpage>–<lpage>D757</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gks1024</pub-id><?supplied-pmid 23125371?><pub-id pub-id-type="pmid">23125371</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Zerbino</surname><given-names>DR</given-names></name>, <name><surname>Achuthan</surname><given-names>P</given-names></name>, <name><surname>Akanni</surname><given-names>W</given-names></name>, <name><surname>Amode</surname><given-names>MR</given-names></name>, <name><surname>Barrell</surname><given-names>D</given-names></name>, <name><surname>Bhai</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Ensembl 2018</article-title>. <source>Nucleic Acids Res</source>. <year>2018</year>;<volume>46</volume>(<issue>D1</issue>):<fpage>D754</fpage>–<lpage>D761</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkx1098</pub-id><?supplied-pmid 29155950?><pub-id pub-id-type="pmid">29155950</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Kahn</surname><given-names>TG</given-names></name>, <name><surname>Stenberg</surname><given-names>P</given-names></name>, <name><surname>Pirrotta</surname><given-names>V</given-names></name>, <name><surname>Schwartz</surname><given-names>YB</given-names></name>. <article-title>Combinatorial interactions are required for the efficient recruitment of pho repressive complex (PhoRC) to polycomb response elements</article-title>. <source>PLoS Genet</source>. <year>2014</year>;<volume>10</volume>(<issue>7</issue>):<fpage>e1004495</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pgen.1004495</pub-id><?supplied-pmid 25010632?><pub-id pub-id-type="pmid">25010632</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Enderle</surname><given-names>D</given-names></name>, <name><surname>Beisel</surname><given-names>C</given-names></name>, <name><surname>Stadler</surname><given-names>MB</given-names></name>, <name><surname>Gerstung</surname><given-names>M</given-names></name>, <name><surname>Athri</surname><given-names>P</given-names></name>, <name><surname>Paro</surname><given-names>R</given-names></name>. <article-title>Polycomb preferentially targets stalled promoters of coding and noncoding transcripts</article-title>. <source>Genome Res</source>. <year>2011</year>;<volume>21</volume>(<issue>2</issue>):<fpage>216</fpage>–<lpage>226</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1101/gr.114348.110</pub-id><?supplied-pmid 21177970?><pub-id pub-id-type="pmid">21177970</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Virtanen</surname><given-names>P</given-names></name>, <name><surname>Gommers</surname><given-names>R</given-names></name>, <name><surname>Oliphant</surname><given-names>TE</given-names></name>, <name><surname>Haberland</surname><given-names>M</given-names></name>, <name><surname>Reddy</surname><given-names>T</given-names></name>, <name><surname>Cournapeau</surname><given-names>D</given-names></name>, <etal>et al</etal>. <article-title>SciPy 1.0: fundamental algorithms for scientific computing in Python</article-title>. <source>Nat Methods</source>. <year>2020</year>;<volume>17</volume>(<issue>3</issue>):<fpage>261</fpage>–<lpage>272</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id><?supplied-pmid 32015543?><pub-id pub-id-type="pmid">32015543</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Virtanen</surname><given-names>P</given-names></name>, <name><surname>Gommers</surname><given-names>R</given-names></name>, <name><surname>Oliphant</surname><given-names>TE</given-names></name>, <name><surname>Haberland</surname><given-names>M</given-names></name>, <name><surname>Reddy</surname><given-names>T</given-names></name>, <name><surname>Cournapeau</surname><given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Author Correction: SciPy 1.0: fundamental algorithms for scientific computing in Python</article-title>. <source>Nat Methods</source>. <year>2020</year>;<volume>17</volume>(<issue>352</issue>). <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41592-020-0772-5</pub-id><?supplied-pmid 32094914?><pub-id pub-id-type="pmid">32094914</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref038">
      <label>38</label>
      <mixed-citation publication-type="journal"><name><surname>Bredesen</surname><given-names>BA</given-names></name>, <name><surname>Rehmsmeier</surname><given-names>M</given-names></name>. <article-title>MOCCA: a flexible suite for modelling DNA sequence motif occurrence combinatorics</article-title>. <source>BMC Bioinformatics</source>. <year>2021</year>;<volume>22</volume>(<issue>234</issue>):<fpage>1</fpage>–<lpage>11</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s12859-021-04143-2</pub-id><?supplied-pmid 33962556?><pub-id pub-id-type="pmid">33388027</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref039">
      <label>39</label>
      <mixed-citation publication-type="journal"><name><surname>Bednarz</surname><given-names>P</given-names></name>, <name><surname>Wilczyński</surname><given-names>B</given-names></name>. <article-title>Supervised learning method for predicting chromatin boundary associated insulator elements</article-title>. <source>J Bioinform Comput Biol</source>. <year>2014</year>;<volume>12</volume>(<issue>6</issue>):<fpage>1442006</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1142/S0219720014420062</pub-id><?supplied-pmid 25385081?><pub-id pub-id-type="pmid">25385081</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref040">
      <label>40</label>
      <mixed-citation publication-type="journal"><name><surname>Leslie</surname><given-names>CS</given-names></name>, <name><surname>Eskin</surname><given-names>E</given-names></name>, <name><surname>Cohen</surname><given-names>A</given-names></name>, <name><surname>Weston</surname><given-names>J</given-names></name>, <name><surname>Noble</surname><given-names>WS</given-names></name>. <article-title>Mismatch string kernels for discriminative protein classification</article-title>. <source>Bioinformatics</source>. <year>2004</year>;<volume>20</volume>(<issue>4</issue>):<fpage>467</fpage>–<lpage>476</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btg431</pub-id><?supplied-pmid 14990442?><pub-id pub-id-type="pmid">14990442</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0274338.ref041">
      <label>41</label>
      <mixed-citation publication-type="book"><name><surname>LeCun</surname><given-names>Y</given-names></name>, <name><surname>Boser</surname><given-names>B</given-names></name>, <name><surname>Denker</surname><given-names>J</given-names></name>, <name><surname>Henderson</surname><given-names>D</given-names></name>, <name><surname>Howard</surname><given-names>R</given-names></name>, <name><surname>Hubbard</surname><given-names>W</given-names></name>, <etal>et al</etal>. <part-title>Handwritten Digit Recognition with a Back-Propagation Network</part-title>. In: <name><surname>Touretzky</surname><given-names>D</given-names></name>, editor. <source>Advances in Neural Information Processing Systems</source>. <volume>vol. 2</volume>. <publisher-name>Morgan-Kaufmann</publisher-name>; <year>1989</year>. Available from: <ext-link xlink:href="https://proceedings.neurips.cc/paper/1989/file/53c3bce66e43be4f209556518c2fcb54-Paper.pdf" ext-link-type="uri">https://proceedings.neurips.cc/paper/1989/file/53c3bce66e43be4f209556518c2fcb54-Paper.pdf</ext-link>.</mixed-citation>
    </ref>
  </ref-list>
</back>
