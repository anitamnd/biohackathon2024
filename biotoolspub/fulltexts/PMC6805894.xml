<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Sci Data</journal-id>
    <journal-id journal-id-type="iso-abbrev">Sci Data</journal-id>
    <journal-title-group>
      <journal-title>Scientific Data</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2052-4463</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6805894</article-id>
    <article-id pub-id-type="pmid">31641140</article-id>
    <article-id pub-id-type="publisher-id">229</article-id>
    <article-id pub-id-type="doi">10.1038/s41597-019-0229-9</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Data Descriptor</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Tracking vegetation phenology across diverse biomes using Version 2.0 of the PhenoCam Dataset</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5195-2074</contrib-id>
        <name>
          <surname>Seyednasrollah</surname>
          <given-names>Bijan</given-names>
        </name>
        <address>
          <email>bijan.s.nasr@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2668-2794</contrib-id>
        <name>
          <surname>Young</surname>
          <given-names>Adam M.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5070-8109</contrib-id>
        <name>
          <surname>Hufkens</surname>
          <given-names>Koen</given-names>
        </name>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6234-8967</contrib-id>
        <name>
          <surname>Milliman</surname>
          <given-names>Tom</given-names>
        </name>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6899-2948</contrib-id>
        <name>
          <surname>Friedl</surname>
          <given-names>Mark A.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff7">7</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6414-5004</contrib-id>
        <name>
          <surname>Frolking</surname>
          <given-names>Steve</given-names>
        </name>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Richardson</surname>
          <given-names>Andrew D.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 8040</institution-id><institution-id institution-id-type="GRID">grid.261120.6</institution-id><institution>Northern Arizona University, School of Informatics, Computing, and Cyber Systems, </institution></institution-wrap>Flagstaff, AZ 86011 USA </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 8040</institution-id><institution-id institution-id-type="GRID">grid.261120.6</institution-id><institution>Northern Arizona University, Center for Ecosystem Science and Society, </institution></institution-wrap>Flagstaff, AZ 86011 USA </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">000000041936754X</institution-id><institution-id institution-id-type="GRID">grid.38142.3c</institution-id><institution>Harvard University, Department of Organismic and Evolutionary Biology, </institution></institution-wrap>Cambridge, MA 02138 USA </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2069 7798</institution-id><institution-id institution-id-type="GRID">grid.5342.0</institution-id><institution>Faculty of Bioscience Engineering, Ghent University, </institution></institution-wrap>Ghent, 9000 Belgium </aff>
      <aff id="Aff5"><label>5</label>INRA, UMR ISPA, Villenave d’Ornon, France </aff>
      <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2192 7145</institution-id><institution-id institution-id-type="GRID">grid.167436.1</institution-id><institution>University of New Hampshire, Earth Systems Research Center, </institution></institution-wrap>Durham, NH 03824 USA </aff>
      <aff id="Aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 7558</institution-id><institution-id institution-id-type="GRID">grid.189504.1</institution-id><institution>Boston University, Department of Earth and Environment, </institution></institution-wrap>Boston, MA 02215 USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>22</day>
      <month>10</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>22</day>
      <month>10</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>6</volume>
    <elocation-id>222</elocation-id>
    <history>
      <date date-type="received">
        <day>4</day>
        <month>6</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>3</day>
        <month>9</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
        <license-p>The Creative Commons Public Domain Dedication waiver <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link> applies to the metadata files associated with this article.</license-p>
      </license>
    </permissions>
    <related-article related-article-type="data-paper-referrer" ext-link-type="doi" xlink:href="10.1038/sdata.2018.28" id="d29e72"/>
    <abstract id="Abs1">
      <p id="Par1">Monitoring vegetation phenology is critical for quantifying climate change impacts on ecosystems. We present an extensive dataset of 1783 site-years of phenological data derived from PhenoCam network imagery from 393 digital cameras, situated from tropics to tundra across a wide range of plant functional types, biomes, and climates. Most cameras are located in North America. Every half hour, cameras upload images to the PhenoCam server. Images are displayed in near-real time and provisional data products, including timeseries of the Green Chromatic Coordinate (Gcc), are made publicly available through the project web page (<ext-link ext-link-type="uri" xlink:href="https://phenocam.sr.unh.edu/webcam/gallery/">https://phenocam.sr.unh.edu/webcam/gallery/</ext-link>). Processing is conducted separately for each plant functional type in the camera field of view. The PhenoCam Dataset v2.0, described here, has been fully processed and curated, including outlier detection and expert inspection, to ensure high quality data. This dataset can be used to validate satellite data products, to evaluate predictions of land surface models, to interpret the seasonality of ecosystem-scale CO<sub>2</sub> and H<sub>2</sub>O flux data, and to study climate change impacts on the terrestrial biosphere.</p>
    </abstract>
    <abstract id="Abs2" abstract-type="summary">
      <p id="Par2">
        <table-wrap id="Taba">
          <table frame="hsides" rules="groups">
            <tbody>
              <tr>
                <td>Measurement(s)</td>
                <td>plant phenological trait • plant greenness</td>
              </tr>
              <tr>
                <td>Technology Type(s)</td>
                <td>digital camera</td>
              </tr>
              <tr>
                <td>Sample Characteristic - Organism</td>
                <td>Embryophyta</td>
              </tr>
              <tr>
                <td>Sample Characteristic - Environment</td>
                <td>terrestrial biome</td>
              </tr>
              <tr>
                <td>Sample Characteristic - Location</td>
                <td>Earth (planet)</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </p>
      <p id="Par3">Machine-accessible metadata file describing the reported data: 10.6084/m9.figshare.9913694</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Phenology</kwd>
      <kwd>Environmental impact</kwd>
      <kwd>Ecosystem ecology</kwd>
      <kwd>Ecosystem ecology</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background &amp; Summary</title>
    <p id="Par4">Phenology is broadly defined as the timing of recurring of biological events<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Vegetation phenology exerts significant control over seasonal changes in ecosystem structure and function<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR3">3</xref></sup>. Key examples of this influence include the role of vegetation phenology in dictating the timing and magnitude of ecosystem carbon uptake<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR5">5</xref></sup>, as well as seasonal shifts in energy and water fluxes between the surface and the atmosphere<sup><xref ref-type="bibr" rid="CR6">6</xref>–<xref ref-type="bibr" rid="CR8">8</xref></sup>. Vegetation phenology is also sensitive to climate variability. In temperate and boreal forest ecosystems, phenology is predominantly driven by air temperature<sup><xref ref-type="bibr" rid="CR9">9</xref>–<xref ref-type="bibr" rid="CR11">11</xref></sup>, while in warm, arid grassland ecosystems, phenology responds strongly to the timing and magnitude of precipitation events<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR13">13</xref></sup>.</p>
    <p id="Par5">Standardized and publicly-available phenology datasets can provide a key source of information to aid scientists and land managers in documenting—and anticipating—the impacts of climate change on terrestrial ecosystems<sup><xref ref-type="bibr" rid="CR14">14</xref>,<xref ref-type="bibr" rid="CR15">15</xref></sup>. A range of vegetation phenology datasets are available, varying in spatial and temporal extent and resolution<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. On-the-ground observations of individual organisms have been made by citizen science observers for decades, and contributed to databases such as the U.S. National Phenology Network<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>. At much broader spatial scales, satellite-based remote sensing platforms (e.g., Moderate Resolution Imaging Spectroradiometer (MODIS), Landsat, and Sentinel 2) provide time-series of land-surface greenness (e.g., normalized difference vegetation index), allowing for characterization of vegetation phenology across the earth’s entire surface<sup><xref ref-type="bibr" rid="CR18">18</xref>,<xref ref-type="bibr" rid="CR19">19</xref></sup>. However, landscape heterogeneity is unresolved under relatively course pixel resolutions provided by satellites sensors (e.g., ≈500 meters in MODIS), potentially confounding phenological signals<sup><xref ref-type="bibr" rid="CR20">20</xref>,<xref ref-type="bibr" rid="CR21">21</xref></sup>. Over the last decade, a complementary approach has been developed to monitor vegetation phenology: near-surface remote sensing using high-frequency digital repeat photography<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR22">22</xref>–<xref ref-type="bibr" rid="CR25">25</xref></sup>. While both airborne and ground-based observations have their own strengths, limitations and uncertainties, this so-called “phenocam” approach can serve as a bridge across scales, providing continuous temporal coverage of phenological change at the organism-to-ecosystem level, with comparatively small uncertainties<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>.</p>
    <p id="Par6">Digital repeat photography offers an automated and cost-effective way to characterize temporal changes in vegetation<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. Briefly, digital cameras, mounted overlooking the vegetation of interest, are used in time-lapse mode to record images throughout the day, from sunrise to sunset. Information about vegetation color—most commonly, “canopy greenness”—is extracted from the imagery, and used to quantify phenological changes. Specific phenophase transition dates, e.g. corresponding to the onset of spring green-up, can be identified from the seasonal trajectory of canopy greenness. Image analysis can be conducted for individual organisms or at the canopy scale. For more information, see refs<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR22">22</xref>,<xref ref-type="bibr" rid="CR27">27</xref>,<xref ref-type="bibr" rid="CR28">28</xref></sup>.</p>
    <p id="Par7">The PhenoCam network (<ext-link ext-link-type="uri" xlink:href="http://phenocam.sr.unh.edu">http://phenocam.sr.unh.edu</ext-link>) was established in 2008. PhenoCam, which focuses on terrestrial ecosystems of North America, is one of several networks worldwide to leverage near-surface remote sensing for tracking of vegetation phenology. Similar networks include the European Phenology Camera Network (EuroPhen)<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> and the Japanese Phenological Eyes Network (PEN)<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>. Phenocams are also being deployed as part of the NEON (National Ecological Observatory Network) and LTAR (Long Term Agricultural Research) networks in the USA, ICOS (Integrated Carbon Observation System) in Europe, TERN (Terrestrial Ecosystem Research Network) and the Australian Phenocam Network in Australia, and the e-Phenology project in Brazil<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR31">31</xref>–<xref ref-type="bibr" rid="CR34">34</xref></sup>.</p>
    <p id="Par8">The previously-released PhenoCam Dataset v1.0<sup><xref ref-type="bibr" rid="CR28">28</xref></sup> is a curated and publicly available (CC0 Public Domain Dedication) data set that includes both digital camera imagery (10.3334/ORNLDAAC/1560)<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> and data derived from that imagery (10.3334/ORNLDAAC/1511)<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. This initial public release of data from PhenoCam included imagery through the end of 2015 from 130 cameras, comprising almost 750 site-years of data<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. Here, we describe a major update—v2.0—to the PhenoCam Dataset, with two significant improvements. First, coverage has been substantially increased. The new dataset includes imagery through the end of 2018 from 393 cameras, comprising 1783 site-years of data (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>). Second, data and imagery have been screened to exclude cameras programmed for “grey world” automatic white–balancing (AWB), as AWB can negatively impact the quality of the derived time series. In addition, we also present here an analysis of the representativeness of the current distribution of PhenoCam network cameras, to identify ecoregions and climate zones that are under-represented.<fig id="Fig1"><label>Fig. 1</label><caption><p>Spatial distribution of PhenoCam data across ecological regions of North America. Background map illustrates USA Environmental Protection Agency Level I Ecoregions<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR51">51</xref></sup>. Data counts have been aggregated to a spatial resolution of 4°, and the size of each circle corresponds to the number of site-years of data in the 4 × 4° grid cell. Sites in Hawaii, Puerto Rico, Central and South America, Europe, Asia and Africa (total of 88 site years) are not shown.</p></caption><graphic xlink:href="41597_2019_229_Fig1_HTML" id="d29e602"/></fig></p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <p id="Par9">Details on camera installation and configuration protocols, site classification, and image and data processing routines have been previously documented by Richardson, <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. Here we provide a brief summary.</p>
    <p id="Par10">Each PhenoCam camera is classified into one of three classes: Type I, Type II or Type III. Type I cameras (406 cameras) follow a standardized protocol, and site personnel are actively engaged as PhenoCam collaborators, e.g. providing camera maintenance and troubleshooting as required. For Type II cameras (70 cameras), there is some deviation from the standard protocol (e.g., non-standard camera brand or model), but site personnel are still actively engaged. For Type III cameras (52 cameras), there is some deviation from the standard protocol, and no active collaboration of personnel on-site.</p>
    <p id="Par11">All cameras in the PhenoCam network record three-layer JPEG images, from which we extract information about the mean intensity of each of the red, green and blue (RGB) color channels, calculated across a user-defined region of interest (ROI). The ROI corresponds to the vegetation under study. While there are a variety of ways in which this color information can be used<sup><xref ref-type="bibr" rid="CR3">3</xref>,<xref ref-type="bibr" rid="CR37">37</xref></sup>, the Green Chromatic Coordinate (<italic>G</italic><sub>CC</sub>) is a commonly-used metric which has been applied successfully in many ecosystems<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR22">22</xref></sup>:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${G}_{CC}=\frac{{G}_{DN}}{{R}_{DN}+{G}_{DN}+{B}_{DN}}$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>C</mml:mi><mml:mi>C</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mstyle></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mstyle></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41597_2019_229_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <italic>R</italic><sub><italic>DN</italic></sub>, <italic>G</italic><sub><italic>DN</italic></sub> and <italic>B</italic><sub><italic>DN</italic></sub> are the average red, green and blue digital numbers (a measure of intensity) across the ROI, respectively. Similarly, the red and blue chromatic coordinates are defined as normalized red and blue digital numbers. The red chromatic coordinate has been shown to be particularly well-suited to characterizing the timing of peak autumn colors in many deciduous forests<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>.</p>
    <p id="Par12">While a single image per day would be generally sufficient to document phenological changes in most ecosystems, it is typical for cameras in the PhenoCam network to upload an image every 15 or 30 minutes. This ensures high quality data by minimizing data discontinuity in cases of unfavorable weather (rain or snow), adverse illumination conditions (clouds or aerosols), or short-term power outages. Following previously-developed methods<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>, we use the sub-daily <italic>G</italic><sub>CC</sub> time-series (calculated for each image) to generate 1-day and 3-day “summary product” <italic>G</italic><sub>CC</sub> timeseries. The 1-day and 3-day time series were obtained from the 90th percentile of canopy greenness at 1-day and 3-day intervals, respectively<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. The 1-day time series have finer temporal resolution, whereas the 3-day time series generally have less high-frequency noise. From the summary product time series, we then calculate phenological transition dates corresponding to the start of each “greenness rising” phenological phase, and the end of each “greenness falling” phenological phase. Uncertainties are quantified for all transition date estimates. In Richardson, <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>, we erroneously indicated that a spline-based method was used to detect outliers in the greenness time-series data. The method we used was locally weighted scatterplot smoothing (i.e. LOESS).</p>
  </sec>
  <sec id="Sec3">
    <title>Data Records</title>
    <p id="Par13">The PhenoCam Dataset v2.0 consists of five different Data Records. Data Record 1 contains general metadata for each camera site, whereas Data Records 2 through 5 have been calculated for specific ROIs from each camera. For example, Data Record 2 contains the files used for image processing steps, i.e. ROI mask files, and information about the range of images over which these should be applied. Data Record 3 contains time-series of color-based statistics (e.g., chromatic coordinates), calculated for each image in the archive. Data Record 4 contains “summary product” 1-day and 3-day time-series for a variety of phenologically-relevant color-based metrics. Data Record 5 contains phenological transitional dates (i.e., phenophases) obtained from the 1-day and 3-day summary time-series. The data records are organized as follows for each camera site.</p>
    <p id="Par14">&lt;sitename&gt;</p>
    <p id="Par15">└─── data_record_1 (contains general metadata for each camera site)<list list-type="bullet"><list-item><p id="Par16">&lt;sitename&gt;_meta.json</p></list-item><list-item><p id="Par17">&lt;sitename&gt;_meta.txt</p><p id="Par18">└───data_record_2 (contains the ROI list files and image mask files used for image processing)</p></list-item><list-item><p id="Par19">&lt;sitename&gt;_ &lt;veg_type&gt; _ &lt;ROI_ID_number&gt; _roi.csv</p></list-item><list-item><p id="Par20">&lt;sitename&gt;_ &lt;veg_type&gt; _ &lt;ROI_ID_number&gt; _ &lt;mask_index&gt; .tif</p><p id="Par21">└─── data_record_3 (contains time series of ROI color statistics, calculated for each image in the archive, using data_record_2)</p></list-item><list-item><p id="Par22">&lt;sitename&gt;_ &lt;veg_type&gt; _ &lt;ROI_ID_number&gt; _roistats.csv</p><p id="Par23">└─── data_record_4 (contains time series of ROI color summary statistics, calculated for 1 and 3 day aggregation periods from data_record_3)</p></list-item><list-item><p id="Par24">&lt;sitename&gt;_ &lt;veg_type&gt; _ &lt;ROI_ID_number&gt; _1day.csv</p></list-item><list-item><p id="Par25">&lt;sitename&gt;_ &lt;veg_type&gt; _ &lt;ROI_ID_number&gt; _3day.csv</p><p id="Par26">└─── data_record_5 (contains phenological transition dates, calculated from data_record_4)</p></list-item><list-item><p id="Par27">&lt;sitename&gt;_ &lt;veg_type&gt; _ &lt;ROI_ID_number&gt; _1day_ transition_dates.csv</p></list-item><list-item><p id="Par28">&lt;sitename&gt;_ &lt;veg_type&gt; _ &lt;ROI_ID_number&gt; _3day_transition_dates.csv</p></list-item></list></p>
    <p id="Par29">Here, &lt;sitename&gt; is the name of each camera site, &lt; veg_type &gt; is a two-letter code defining the type of vegetation for which data have been processed (see Table <xref rid="Tab1" ref-type="table">1</xref>), and &lt; ROI_ID_number &gt; is a unique identifier to distinguish between multiple ROIs of the same vegetation type for a given site. Together, these five data records are contained within Seyednasrollah<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>, and are derived from the imagery in Milliman<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Vegetation type abbreviations for ROIs (region of interests), and the corresponding number of site-years of data in the PhenoCam dataset described here (v2.0). For comparative purposes, the number of site-years of data in the previous dataset release (v1.0) is also presented. The absence of MX ROIs in the v2.0 data release is due to the fact that we have delineated separate ROIs for the plant functional types comprising the mixed stand (i.e., separation of EN and DN ROIs). Note that non-vegetated ROIs are not included in the v2.0 data release.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Abbreviation</th><th>Description</th><th>Site-years in Dataset v1.0</th><th>Site-years in Dataset v2.0</th></tr></thead><tbody><tr><td>AG</td><td>agriculture</td><td>50</td><td>226</td></tr><tr><td>DB</td><td>deciduous broadleaf</td><td>392</td><td>643</td></tr><tr><td>DN</td><td>deciduous needleleaf</td><td>4</td><td>45</td></tr><tr><td>EB</td><td>evergreen broadleaf</td><td>2</td><td>28</td></tr><tr><td>EN</td><td>evergreen needleleaf</td><td>80</td><td>265</td></tr><tr><td>GR</td><td>grassland</td><td>121</td><td>279</td></tr><tr><td>MX</td><td>mixed vegetation (generally EN/DN, DB/EN, or DB/EB)</td><td>5</td><td>—</td></tr><tr><td>NV</td><td>non-vegetated</td><td>14</td><td>—</td></tr><tr><td>SH</td><td>shrubs</td><td>46</td><td>142</td></tr><tr><td>TN</td><td>tundra (includes sedges, lichens, mosses, etc.)</td><td>22</td><td>62</td></tr><tr><td>UN</td><td>understory</td><td>—</td><td>18</td></tr><tr><td>WL</td><td>wetland</td><td>11</td><td>64</td></tr></tbody></table></table-wrap></p>
    <p id="Par30">The structure of the data records in the PhenoCam Dataset v2.0 is identical to that of the PhenoCam Dataset v1.0, and users of the Dataset v2.0 are directed to the user guide (<ext-link ext-link-type="uri" xlink:href="https://daac.ornl.gov/VEGETATION/guides/PhenoCam_V2.html">https://daac.ornl.gov/VEGETATION/guides/PhenoCam_V2.html</ext-link>) and our previous data descriptor<sup><xref ref-type="bibr" rid="CR28">28</xref></sup> for an explanation of the headers and columns in each data record.</p>
  </sec>
  <sec id="Sec4">
    <title>Technical Validation</title>
    <sec id="Sec5">
      <title>Efforts to maintain quality control</title>
      <p id="Par31">The PhenoCam image archive and derived data products are regularly reviewed by the PhenoCam project team (the authors of this Data Descriptor) to maintain the quality of the dataset. This consists of visual inspection of the imagery for each site, and of the <italic>G</italic><sub>CC</sub> time series data derived from the imagery and displayed in near-real time on the project web page. Imagery from each PhenoCam is also checked for field of view shifts, interruptions to data continuity, and camera misconfigurations. Should any issues be identified, site contacts are notified by email, and asked to investigate and implement corrective measures if possible. In the case of field of view shifts, ROI masks are adjusted or redrawn as needed, and the imagery is reprocessed to ensure that the effects of field-of-view shifts are minimized<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>.</p>
      <p id="Par32">We previously presented extensive documentation of the steps taken to ensure that data derived from PhenoCam imagery are of the highest quality<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. This documentation included analyses of independent data sources. For example, we demonstrated excellent agreement between both direct observations of vegetation phenology and phenocam-derived metrics, as well as between vegetation indices derived from radiometrically-calibrated measurements of surface reflectance (e.g. with narrow-band, tower-mounted sensors) and phenocam-derived vegetation indices such as <italic>G</italic><sub>CC</sub>.</p>
      <p id="Par33">Here we report more recent efforts (1) to identify and exclude data and imagery from cameras erroneously set to auto white balance; and (2) to assess the spatial representativeness of the PhenoCam network in the context of the biological and climatological variability of ecosystems across North America.</p>
    </sec>
    <sec id="Sec6">
      <title>Auto white balancing</title>
      <p id="Par34">In digital photography and image processing, “white balancing” is the practice of adjusting digital numbers for each color channel in order to produce a neutral image (i.e. the “grey world” model) for given red (R), green (G), and blue (B) values. This can be useful under varying conditions of illumination, with the intended effect of rendering white and grey tones correctly<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>. Therefore, most digital cameras (particularly consumer-grade “point-and-shoot” cameras) perform some sort of automatic white balance (AWB) “correction.” The outcome may appear more pleasant to the human eye, as the adjusted colors correspond more closely to human perception of the scene. While this could compensate for changing illumination conditions in PhenoCam images, the AWB correction often results in color inconsistency as the scene changes, for example as leaves emerge in spring, or as the sky color changes from grey to blue. As a result, the chromatic coordinates obtained from AWB images may not be suitable for quantifying vegetation phenology: the data may be noisy<sup><xref ref-type="bibr" rid="CR42">42</xref></sup>, or even wrong.</p>
      <p id="Par35">Figure <xref rid="Fig2" ref-type="fig">2</xref> shows an example of how AWB can affect both the digital images themselves, and the extracted <italic>G</italic><sub>CC</sub> time-series, using imagery from the Snipe Lake PhenoCam site. In 2011, the Snipe Lake camera was set to fixed white balance, whereas in 2017 the camera was set to AWB. The purple cast of the sky, visible in the 2017 image (Fig. <xref rid="Fig2" ref-type="fig">2a</xref>), is the direct result of AWB compensating for the greenness of the foreground vegetation. The white balance setting also influences the derived <italic>G</italic><sub>CC</sub> time series, which is not only noisier for the 2017 (AWB) imagery than the 2011 (non-AWB) imagery, but also leads to mischaracterization of vegetation seasonality: the rise in <italic>G</italic><sub>CC</sub> in March 2017 is due to snowmelt, rather than vegetation greening up. These artifacts are the product of AWB counteracting changes in scene and illumination by adjusting the color sensitivity of the imaging sensor so that across the entire image, the mean color is grey, and each of the red, green, and blue chromatic coordinates is approximately equal (0.33). The lack of any seasonal patterns in the whole-image chromatic coordinates in 2017 contrasts sharply with the seasonality evident in 2011 (Fig. <xref rid="Fig2" ref-type="fig">2c</xref>), and provides confirmation that the camera is configured for AWB using the “grey world” method.<fig id="Fig2"><label>Fig. 2</label><caption><p>Qualitative and quantitative effects of Auto-White Balance (AWB) on phenological data. The left and right panels show when AWB was off and on at the Snipe Lake PhenoCam site (60.6°N, 154.3°W, tundra), respectively: (<bold>a</bold>) sample images taken on the same day (summer solstice) of the year in 2011 and 2017, (<bold>b</bold>) full-year green chromatic coordinates extracted from an ROI representative of vegetation greenness, and (<bold>c)</bold> the red, green and blue chromatic coordinates (<italic>R</italic><sub>CC</sub>, G<sub>CC</sub> and <italic>B</italic><sub>CC</sub>) and the deviation from grey (Δ) extracted from the whole image.</p></caption><graphic xlink:href="41597_2019_229_Fig2_HTML" id="d29e1114"/></fig></p>
      <p id="Par36">The PhenoCam configuration protocol specifies that all cameras should be set to fixed white balance. On the StarDot cameras that are used at Type I sites, this involves setting the color balance to “manual” and adjusting the color skew values to custom settings (R = 385, G = 256, B = 330). This configuration is implemented by the PhenoCam Installation Tool (PIT; <ext-link ext-link-type="uri" xlink:href="http://khufkens.github.io/phenocam-installation-tool/">http://khufkens.github.io/phenocam-installation-tool/</ext-link>).</p>
      <p id="Par37">Because of the negative impact of AWB on PhenoCam imagery and data products, we have implemented several procedures to identify whether a given camera may be recording imagery using the “grey world” AWB model. For standard PhenoCam cameras (Type I), configured using the PIT, the metadata text file associated with each image reports whether the camera is on manual (i.e. fixed) color balance (“balance = 0”) or AWB (“balance = 1”), and these files are scanned regularly to identify cameras which have been erroneously set to AWB.</p>
      <p id="Par38">For non-standard cameras (Type II and Type III), we have developed an <italic>ad hoc</italic> method to identify potential AWB cameras. Briefly, we define the deviation from grey, Δ, as in Eq. <xref rid="Equ2" ref-type="">2</xref>:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta ={\left[{\left(\frac{\bar{{R}_{DN}}}{\bar{{R}_{DN}}+\bar{{G}_{DN}}+\bar{{B}_{DN}}}-\frac{1}{3}\right)}^{2}+{\left(\frac{\bar{{G}_{DN}}}{\bar{{R}_{DN}}+\bar{{G}_{DN}}+\bar{{B}_{DN}}}-\frac{1}{3}\right)}^{2}+{\left(\frac{\bar{{B}_{DN}}}{\bar{{R}_{DN}}+\bar{{G}_{DN}}+\bar{{B}_{DN}}}-\frac{1}{3}\right)}^{2}\right]}^{1/2}$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mstyle mathsize="8pt"><mml:mstyle mathvariant="normal"><mml:mi mathvariant="normal">Δ</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mfrac><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mfrac><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mfrac><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math><graphic xlink:href="41597_2019_229_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par39">Here <inline-formula id="IEq1"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{{R}_{DN}}$$\end{document}</tex-math><mml:math id="M6"><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="41597_2019_229_Article_IEq1.gif"/></alternatives></inline-formula>, <inline-formula id="IEq2"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{{G}_{DN}}$$\end{document}</tex-math><mml:math id="M8"><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="41597_2019_229_Article_IEq2.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq3"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{{B}_{DN}}$$\end{document}</tex-math><mml:math id="M10"><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="41597_2019_229_Article_IEq3.gif"/></alternatives></inline-formula> are the average red, green and blue (respectively) digital numbers, calculated across the <italic>entire</italic> image. As shown for the Snipe Lake imagery in Fig. <xref rid="Fig2" ref-type="fig">2c</xref>, Δ tends to be very close to zero when cameras are on AWB. We identify images with Δ &lt; 0.02 for more than 30 consecutive days as “AWB suspects” and conduct further investigation. In some cases, imagery from cameras not on AWB has low Δ because the image is dominated by neutral tones—when the ground is snow-covered, for example. But, if further investigation leads to the conclusion that the camera was likely on AWB, that imagery has been excluded from this dataset. Data from roughly a dozen camera sites has been excluded because of concerns about poor-quality data resulting from AWB.</p>
      <p id="Par40">We note that this approach is imperfect; on some cameras, for example, only the brightest pixels are used to determine the white balance, and in this case our method would not necessarily work. We are working on the development of more general methods to detect AWB imagery.</p>
    </sec>
    <sec id="Sec7">
      <title>Comparison of Transition Dates between the PhenoCam Dataset v1.0 and v2.0</title>
      <p id="Par41">As discussed above, the processing steps and data quality of the PhenoCam dataset have been improved from v1.0 to v2.0 but the new release of the dataset does not invalidate the previous version. We showed this by comparing 535 rising and 577 falling seasonal cycles that were common between the two versions (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). We compared the rising and the falling 10%, 25% and 50% transition dates between the two datasets, based on the 3-day 90<sup>th</sup> percentile GCC timeseries. The intercomparison showed a strong agreement (R<sup>2</sup> &gt; 0.99 for all the 10%, 25 and 50% transition dates) between v1.0 and v2.0. Median absolute error was only 1 day for all the 10%, 25 and 50% transition dates. Root mean square deviation (RMSD) was 3.9, 3.6 and 4.3 days for the 10%, 25 and 50% transition dates, respectively. We identified less than 1% of the transition dates were the difference was more than 20 days. The small discrepancies between the two datasets may be caused by several factors, including updated masks, and newly available data since the last release. For example, the revised masks for howland1 EN 2000 resulted in a shift of 22 days in transition 50% of year 2008, because the old mask had contaminated with a deciduous signal. In another instance, the 2015 end-of-season transition dates for turkeypointenf39 EN 1000 shifted more than two weeks, caused by the properly constrained winter baseline with the additional data for 2016 onward.<fig id="Fig3"><label>Fig. 3</label><caption><p>Comparison of transition dates between the PhenoCam dataset v1.0 and v2.0. The intercomparison showed a strong agreement between the two versions.</p></caption><graphic xlink:href="41597_2019_229_Fig3_HTML" id="d29e1482"/></fig></p>
    </sec>
    <sec id="Sec8">
      <title>Representativeness of the PhenoCam Network</title>
      <p id="Par42">Cameras in the PhenoCam network are widely distributed across North America, and the over-arching objective of the network is to sample the diversity of ecosystems and climate zones across the continent. Cameras located at sites with a range of different vegetation types (Table <xref rid="Tab1" ref-type="table">1</xref>), including agriculture (226 site years), deciduous broadleaf (643 site years), deciduous needleleaf (45 site years), evergreen broadleaf (28 site years), evergreen needleleaf (265 site years), grassland (279 site years), shrub (142 site years), tundra (62 site years), understory (18 site years), and wetland (64 site years).</p>
      <p id="Par43">To more comprehensively investigate the degree to which PhenoCams are distributed across the biotic and abiotic variability of ecosystems in North America, we use two approaches. First, using the Level II Ecoregion classification of North America (<ext-link ext-link-type="uri" xlink:href="https://www.epa.gov/eco-research/ecoregions-north-america">https://www.epa.gov/eco-research/ecoregions-north-america</ext-link>), we identified those areas where coverage is lowest. From about 30°N to 55°N, virtually every Level II ecoregion has at least three (and in many cases substantially more) PhenoCams in it (Fig. <xref rid="Fig4" ref-type="fig">4a</xref>). Ecoregions of interior Alaska, central and far northern Canada (much of this area is sparsely vegetated<sup><xref ref-type="bibr" rid="CR43">43</xref></sup> and also relatively inaccessible), the gulf coast of Texas, the southern tip of Florida, and most of Mexico emerge as poorly-represented in this analysis. These are areas that should be targeted for further expansion of the network.<fig id="Fig4"><label>Fig. 4</label><caption><p>Representativeness of the PhenoCam cameras. (<bold>a</bold>) Distribution of PhenoCam sites across North America, with Level II Ecoregions colored by the number of PhenoCams per region; and (<bold>b</bold>) Distribution of PhenoCams across the global vegetation biomes defined by the Whittaker classification. Ecoregions boundaries are obtained from Ecoregion Level II of United States Environmental Protection Agency (<ext-link ext-link-type="uri" xlink:href="https://www.epa.gov/eco-research/ecoregions-north-america">https://www.epa.gov/eco-research/ecoregions-north-america</ext-link>).</p></caption><graphic xlink:href="41597_2019_229_Fig4_HTML" id="d29e1524"/></fig></p>
      <p id="Par44">Second, using the Whittaker Biome Classification<sup><xref ref-type="bibr" rid="CR44">44</xref>,<xref ref-type="bibr" rid="CR45">45</xref></sup>, we examined the distribution of PhenoCam sites across global climate-space (Fig. <xref rid="Fig4" ref-type="fig">4b</xref>). Mean annual temperature at PhenoCam sites spans almost 40 °C, ranging from −12.3 °C to 25.8 °C, while mean annual precipitation varies 30-fold, from just over 100 mm to over 3000 mm. Among the biomes corresponding to this climatic variability, boreal forest, temperate forest, temperate grassland desert, temperate rain forest, tropical forest savanna, and woodland/shrubland biomes are generally well-represented by the current distribution of PhenoCam network sites. However, the climate representativeness of the network would benefit from the installation of more cameras in subtropical desert, tundra, and tropical rain forest biomes.</p>
    </sec>
  </sec>
  <sec id="Sec9">
    <title>Usage Notes</title>
    <p id="Par45">The curated PhenoCam Dataset v2.0 is permanently and publicly available through the Oak Ridge National Lab (ORNL) DAAC (Distributed Active Archive Center for Biogeochemical Dynamics) data repository (10.3334/ORNLDAAC/1674). We have also developed an interface (<ext-link ext-link-type="uri" xlink:href="http://explore.phenocam.us/">http://explore.phenocam.us/</ext-link>) to facilitate data exploration and visualization, from which the user can also download data on a site-by-site basis. All imagery and data (updated in near-real time, and including data from sites where the data record is shorter than six months, or the data are not considered to be high enough quality, for inclusion in a curated data release) are also available through the project web page (<ext-link ext-link-type="uri" xlink:href="http://phenocam.sr.unh.edu">http://phenocam.sr.unh.edu</ext-link>).</p>
  </sec>
  <sec id="Sec10">
    <title>Software Applications</title>
    <p id="Par46">The PhenoCam team has developed several software application and packages to facilitate extraction and processing of data from PhenoCam imagery. Code for each of these tools is made available on an open-source basis, for reuse and development by the community.</p>
    <sec id="Sec11">
      <title>xROI</title>
      <p id="Par47"><italic>xROI</italic> is an open-source <italic>R</italic> package to extract time-series data from large sets of digital images. With a graphical user interface, <italic>xROI</italic> provides functionality to delineate ROIs, to detect data discontinuities (FOV shifts, clouds, etc.), and to derive high-quality color-based statistics (digital numbers, chromatic coordinates) from stacks of images. The <italic>xROI</italic> software can be used to extract data from PhenoCam imagery for custom ROIs, or from imagery not included in the PhenoCam archive. While the package is available from the <italic>R</italic> Comprehensive Archive Network (CRAN), the source code (<ext-link ext-link-type="uri" xlink:href="https://github.com/bnasr/xROI">https://github.com/bnasr/xROI</ext-link>) is open under the GNU Affero General Public License (AGPLv3) and can be downloaded from refs<sup><xref ref-type="bibr" rid="CR46">46</xref>,<xref ref-type="bibr" rid="CR47">47</xref></sup>. For more details see Seyednasrollah <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>.</p>
    </sec>
    <sec id="Sec12">
      <title>Hazer</title>
      <p id="Par48"><italic>hazer</italic> is an open-source <italic>R</italic> package for detecting foggy or hazy images. Haze statistics are calculated from the frequency distribution of RGB digital numbers across the image. The <italic>getHazeFactor</italic> function returns the “haze degree” value, varying from 0 to 100%. High haze degree values indicate high probabilities of haze or fogginess (Fig. <xref rid="Fig5" ref-type="fig">5a</xref>). We consider images with haze degree &gt; 40% to be foggy or hazy; the distribution of the haze degree value across all PhenoCam sites is shown in Fig. <xref rid="Fig5" ref-type="fig">5b</xref>. While the haze degree values are used for quality check, the hazy images are not excluded from the data release v2.0. The package also presents additional functionalities to obtain brightness, darkness and contrast matrices for an image. <italic>Hazer</italic> is open source under the GNU Affero General Public License (AGPL-v3)<sup><xref ref-type="bibr" rid="CR49">49</xref></sup>.<fig id="Fig5"><label>Fig. 5</label><caption><p>Haze degree estimated by hazer R package. (<bold>a</bold>) Haze degree values for different fogginess at the Point Reyes PhenoCam site located at 123.02°W and 37.99°N, and (<bold>b</bold>) distribution of haze degree across all PhenoCam sites (including sites not included in the dataset). On panel b, x-axis indicate PhenoCam sites sorted by their median haze degree values.</p></caption><graphic xlink:href="41597_2019_229_Fig5_HTML" id="d29e1642"/></fig></p>
    </sec>
    <sec id="Sec13">
      <title>Phenocamr</title>
      <p id="Par49">The <italic>phenocamr R</italic> package facilitates the retrieval and post-processing of PhenoCam time series<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>. The post-processing of PhenoCam data includes outlier removal and the generation of data products, in particular the phenological transition dates as included in this dataset. The package is available from the <italic>R</italic> Comprehensive Archive Network (CRAN) while the source code is open under the GNU Affero General Public License v3.0 and available from <ext-link ext-link-type="uri" xlink:href="https://github.com/khufkens/phenocamr">https://github.com/khufkens/phenocamr</ext-link>.</p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
    <fn>
      <p>
        <bold>Change history</bold>
      </p>
      <p>11/1/2019</p>
      <p>An amendment to this paper has been published and can be accessed via a link at the top of the paper.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank our many collaborators, including site PI’s and technicians, for their efforts in support of PhenoCam. The development of PhenoCam has been funded by the Northeastern States Research Cooperative, NSF’s Macrosystems Biology program (awards EF-1065029 and EF-1702697), and DOE’s Regional and Global Climate Modeling program (award DE-SC0016011). We acknowledge additional support from the US National Park Service Inventory and Monitoring Program and the USA National Phenology Network (grant number G10AP00129 from the United States Geological Survey), and from the USA National Phenology Network and North Central Climate Science Center (cooperative agreement number G16AC00224 from the United States Geological Survey). We also thank the USDA Forest Service Air Resource Management program and the National Park Service Air Resources program for contributing their camera imagery to the PhenoCam archive. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the opinions or policies of the U.S. Geological Survey or the National Science Foundation. Mention of trade names or commercial products does not constitute their endorsement by the U.S. Geological Survey or the National Science Foundation.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>A.D.R. initiated the PhenoCam network, obtained funding to develop and support the network, designed the observational protocol, and proposed the format of the standardized data sets. A.D.R., M.A.F. and S.F. oversaw project development. B.S. led the efforts to draft this Data Descriptor with contributions from A.M.Y. and A.D.R. B.S. developed software tools to facilitate image processing. B.S., A.M.Y. and T.M. were responsible for image processing and data set development. T.M. and K.H. coded the data processing routines. T.M. was responsible for management of the data archive. All authors reviewed and approved of this Data Descriptor.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par50">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <mixed-citation publication-type="other">Lieth, H. <italic>Phenology and Seasonality Modeling</italic>, (Springer-Verlag, 1974).</mixed-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <mixed-citation publication-type="other">Tang, J. W. <italic>et al</italic>. Emerging opportunities and challenges in phenology: a review. <italic>Ecosphere</italic>. <bold>7</bold> (2016).</mixed-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Richardson</surname>
            <given-names>AD</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Climate change, phenology, and phenological control of vegetation feedbacks to the climate system</article-title>
        <source>Agr. Forest Meteorol.</source>
        <year>2013</year>
        <volume>169</volume>
        <fpage>156</fpage>
        <lpage>173</lpage>
        <pub-id pub-id-type="doi">10.1016/j.agrformet.2012.09.012</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Keenan</surname>
            <given-names>TF</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Net carbon uptake has increased through warming-induced changes in temperate forest phenology</article-title>
        <source>Nat. Clim. Change.</source>
        <year>2014</year>
        <volume>4</volume>
        <fpage>598</fpage>
        <lpage>604</lpage>
        <pub-id pub-id-type="doi">10.1038/nclimate2253</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wolf</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Warm spring reduced carbon cycle impact of the 2012 US summer drought</article-title>
        <source>Proc. Natl. Acad. Sci. USA.</source>
        <year>2016</year>
        <volume>113</volume>
        <fpage>5880</fpage>
        <lpage>5885</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1519620113</pub-id>
        <pub-id pub-id-type="pmid">27114518</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schwartz</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Crawford</surname>
            <given-names>TM</given-names>
          </name>
        </person-group>
        <article-title>Detecting energy balance modifications at the onset of spring</article-title>
        <source>Phys. Geogr.</source>
        <year>2001</year>
        <volume>22</volume>
        <fpage>394</fpage>
        <lpage>409</lpage>
        <pub-id pub-id-type="doi">10.1080/02723646.2001.10642751</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fitzjarrald</surname>
            <given-names>DR</given-names>
          </name>
          <name>
            <surname>Acevedo</surname>
            <given-names>OC</given-names>
          </name>
          <name>
            <surname>Moore</surname>
            <given-names>KE</given-names>
          </name>
        </person-group>
        <article-title>Climatic consequences of leaf presence in the eastern United States</article-title>
        <source>J. Clim.</source>
        <year>2001</year>
        <volume>14</volume>
        <fpage>598</fpage>
        <lpage>614</lpage>
        <pub-id pub-id-type="doi">10.1175/1520-0442(2001)014&lt;0598:CCOLPI&gt;2.0.CO;2</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Seyednasrollah</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Domec</surname>
            <given-names>J-C</given-names>
          </name>
          <name>
            <surname>Clark</surname>
            <given-names>JS</given-names>
          </name>
        </person-group>
        <article-title>Spatiotemporal sensitivity of thermal stress for monitoring canopy hydrological stress in near real-time</article-title>
        <source>Agr Forest Meteorol.</source>
        <year>2019</year>
        <volume>269</volume>
        <fpage>220</fpage>
        <lpage>230</lpage>
        <pub-id pub-id-type="doi">10.1016/j.agrformet.2019.02.016</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Migliavacca</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>On the uncertainty of phenological responses to climate change, and implications for a terrestrial biosphere model</article-title>
        <source>Biogeosciences.</source>
        <year>2012</year>
        <volume>9</volume>
        <fpage>2063</fpage>
        <lpage>2083</lpage>
        <pub-id pub-id-type="doi">10.5194/bg-9-2063-2012</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Archetti</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Richardson</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>O’Keefe</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Delpierre</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Predicting Climate Change Impacts on the Amount and Duration of Autumn Colors in a New England Forest</article-title>
        <source>Plos One.</source>
        <year>2013</year>
        <volume>8</volume>
        <fpage>e57373</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0057373</pub-id>
        <pub-id pub-id-type="pmid">23520468</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Richardson</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>Hufkens</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Ault</surname>
            <given-names>TR</given-names>
          </name>
        </person-group>
        <article-title>Testing the Hopkins Law of Bioclimatics with PhenoCam data</article-title>
        <source>Appl. Plant Sci.</source>
        <year>2019</year>
        <volume>7</volume>
        <fpage>e01228</fpage>
        <pub-id pub-id-type="doi">10.1002/aps3.1228</pub-id>
        <pub-id pub-id-type="pmid">30937220</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hufkens</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Productivity of North American grasslands is increased under future climate scenarios despite rising aridity</article-title>
        <source>Nat. Clim. Change.</source>
        <year>2016</year>
        <volume>6</volume>
        <fpage>710</fpage>
        <pub-id pub-id-type="doi">10.1038/nclimate2942</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lesica</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Kittelson</surname>
            <given-names>PM</given-names>
          </name>
        </person-group>
        <article-title>Precipitation and temperature are associated with advanced flowering phenology in a semi-arid grassland</article-title>
        <source>J. Arid Environ.</source>
        <year>2010</year>
        <volume>74</volume>
        <fpage>1013</fpage>
        <lpage>1017</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jaridenv.2010.02.002</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Browning</surname>
            <given-names>DM</given-names>
          </name>
          <name>
            <surname>Karl</surname>
            <given-names>JW</given-names>
          </name>
          <name>
            <surname>Morin</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Richardson</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>Tweedie</surname>
            <given-names>CE</given-names>
          </name>
        </person-group>
        <article-title>Phenocams bridge the gap between field and satellite observations in an arid grassland ecosystem</article-title>
        <source>Remote Sens.</source>
        <year>2017</year>
        <volume>9</volume>
        <fpage>1071</fpage>
        <pub-id pub-id-type="doi">10.3390/rs9101071</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Richardson, A. D., Weltzin, J. F. &amp; Morisette, J. T. Integrating multiscale seasonal data for resource management. <italic>EOS</italic>. <bold>98</bold> (2017).</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Richardson, A. D. Tracking seasonal rhythms of plants in diverse ecosystems with digital camera imagery. <italic>New Phyto</italic>. (2018).</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schwartz</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Betancourt</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Weltzin</surname>
            <given-names>JF</given-names>
          </name>
        </person-group>
        <article-title>From Caprio’s lilacs to the USA National Phenology Network</article-title>
        <source>Front. Ecol. Environ.</source>
        <year>2012</year>
        <volume>10</volume>
        <fpage>324</fpage>
        <lpage>327</lpage>
        <pub-id pub-id-type="doi">10.1890/110281</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>XY</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Monitoring vegetation phenology using MODIS</article-title>
        <source>Remote Sens. Environ.</source>
        <year>2003</year>
        <volume>84</volume>
        <fpage>471</fpage>
        <lpage>475</lpage>
        <pub-id pub-id-type="doi">10.1016/S0034-4257(02)00135-9</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Melaas</surname>
            <given-names>EK</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Multisite analysis of land surface phenology in North American temperate and boreal deciduous forests from Landsat</article-title>
        <source>Remote Sens. Environ.</source>
        <year>2016</year>
        <volume>186</volume>
        <fpage>452</fpage>
        <lpage>464</lpage>
        <pub-id pub-id-type="doi">10.1016/j.rse.2016.09.014</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Klosterman</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Fine-scale perspectives on landscape phenology from unmanned aerial vehicle (UAV) photography</article-title>
        <source>Agr. Forest Meteorol.</source>
        <year>2018</year>
        <volume>248</volume>
        <fpage>397</fpage>
        <lpage>407</lpage>
        <pub-id pub-id-type="doi">10.1016/j.agrformet.2017.10.015</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Richardson</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>Hufkens</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Milliman</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Frolking</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Intercomparison of phenological transition dates derived from the PhenoCam Dataset V1.0 and MODIS satellite remote sensing</article-title>
        <source>Sci. Rep.</source>
        <year>2018</year>
        <volume>8</volume>
        <fpage>5679</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-018-23804-6</pub-id>
        <pub-id pub-id-type="pmid">29632311</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sonnentag</surname>
            <given-names>O</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Digital repeat photography for phenological research in forest ecosystems</article-title>
        <source>Agricultural and Forest Meteorology.</source>
        <year>2012</year>
        <volume>152</volume>
        <fpage>159</fpage>
        <lpage>177</lpage>
        <pub-id pub-id-type="doi">10.1016/j.agrformet.2011.09.009</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brown</surname>
            <given-names>TB</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Using phenocams to monitor our changing Earth: toward a global phenocam network</article-title>
        <source>Front. Ecol. Environ.</source>
        <year>2016</year>
        <volume>14</volume>
        <fpage>84</fpage>
        <lpage>93</lpage>
        <pub-id pub-id-type="doi">10.1002/fee.1222</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Richardson</surname>
            <given-names>AD</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Use of digital webcam images to track spring green-up in a deciduous broadleaf forest</article-title>
        <source>Oecologia.</source>
        <year>2007</year>
        <volume>152</volume>
        <fpage>323</fpage>
        <lpage>334</lpage>
        <pub-id pub-id-type="doi">10.1007/s00442-006-0657-z</pub-id>
        <pub-id pub-id-type="pmid">17342508</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Richardson</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>Braswell</surname>
            <given-names>BH</given-names>
          </name>
          <name>
            <surname>Hollinger</surname>
            <given-names>DY</given-names>
          </name>
          <name>
            <surname>Jenkins</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Ollinger</surname>
            <given-names>SV</given-names>
          </name>
        </person-group>
        <article-title>Near-surface remote sensing of spatial and temporal variation in canopy phenology</article-title>
        <source>Ecol. Appl.</source>
        <year>2009</year>
        <volume>19</volume>
        <fpage>1417</fpage>
        <lpage>1428</lpage>
        <pub-id pub-id-type="doi">10.1890/08-2022.1</pub-id>
        <pub-id pub-id-type="pmid">19769091</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Klosterman</surname>
            <given-names>ST</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Evaluating remote sensing of deciduous forest phenology at multiple spatial scales using PhenoCam imagery</article-title>
        <source>Biogeosciences.</source>
        <year>2014</year>
        <volume>11</volume>
        <fpage>4305</fpage>
        <lpage>4320</lpage>
        <pub-id pub-id-type="doi">10.5194/bg-11-4305-2014</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Keenan</surname>
            <given-names>TF</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Tracking forest phenology and seasonal physiology using digital repeat photography: a critical assessment</article-title>
        <source>Ecol. Appl.</source>
        <year>2014</year>
        <volume>24</volume>
        <fpage>1478</fpage>
        <lpage>1489</lpage>
        <pub-id pub-id-type="doi">10.1890/13-0652.1</pub-id>
        <pub-id pub-id-type="pmid">29160668</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Richardson</surname>
            <given-names>AD</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Tracking vegetation phenology across diverse North American biomes using PhenoCam imagery</article-title>
        <source>Sci. Data.</source>
        <year>2018</year>
        <volume>5</volume>
        <fpage>180028</fpage>
        <pub-id pub-id-type="doi">10.1038/sdata.2018.28</pub-id>
        <pub-id pub-id-type="pmid">29533393</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wingate</surname>
            <given-names>L</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Interpreting canopy development and physiology using a European phenology camera network at flux sites</article-title>
        <source>Biogeosciences.</source>
        <year>2015</year>
        <volume>12</volume>
        <fpage>5995</fpage>
        <lpage>6015</lpage>
        <pub-id pub-id-type="doi">10.5194/bg-12-5995-2015</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nasahara</surname>
            <given-names>KN</given-names>
          </name>
          <name>
            <surname>Nagai</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Review: Development of an <italic>in situ</italic> observation network for terrestrial ecological remote sensing: the Phenological Eyes Network (PEN)</article-title>
        <source>Ecol. Res.</source>
        <year>2015</year>
        <volume>30</volume>
        <fpage>211</fpage>
        <lpage>223</lpage>
        <pub-id pub-id-type="doi">10.1007/s11284-014-1239-x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hufkens</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Assimilating phenology datasets automatically across ICOS ecosystem stations</article-title>
        <source>Int. Agrophys.</source>
        <year>2018</year>
        <volume>32</volume>
        <fpage>677</fpage>
        <lpage>687</lpage>
        <pub-id pub-id-type="doi">10.1515/intag-2017-0050</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Moore</surname>
            <given-names>CE</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Reviews and syntheses: Australian vegetation phenology: new insights from satellite remote sensing and digital repeat photography</article-title>
        <source>Biogeosciences.</source>
        <year>2016</year>
        <volume>13</volume>
        <fpage>5085</fpage>
        <lpage>5102</lpage>
        <pub-id pub-id-type="doi">10.5194/bg-13-5085-2016</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Morellato</surname>
            <given-names>LPC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Linking plant phenology to conservation biology</article-title>
        <source>Biol Conserv.</source>
        <year>2016</year>
        <volume>195</volume>
        <fpage>60</fpage>
        <lpage>72</lpage>
        <pub-id pub-id-type="doi">10.1016/j.biocon.2015.12.033</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nagai</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>8 million phenological and sky images from 29 ecosystems from the Arctic to the tropics: the Phenological Eyes Network</article-title>
        <source>Ecol Res.</source>
        <year>2018</year>
        <volume>33</volume>
        <fpage>1091</fpage>
        <lpage>1092</lpage>
        <pub-id pub-id-type="doi">10.1007/s11284-018-1633-x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="data">
        <name>
          <surname>Milliman</surname>
          <given-names>T</given-names>
        </name>
        <etal/>
        <year>2017</year>
        <data-title>PhenoCam Dataset v1.0: Digital Camera Imagery from the PhenoCam Network, 2000-2015</data-title>
        <source>ORNL Distributed Active Archive Center</source>
        <pub-id pub-id-type="doi">10.3334/ORNLDAAC/1560</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="data">
        <name>
          <surname>Richardson</surname>
          <given-names>AD</given-names>
        </name>
        <etal/>
        <year>2017</year>
        <data-title>PhenoCam Dataset v1.0: Vegetation Phenology from Digital Camera Imagery, 2000-2015</data-title>
        <source>ORNL Distributed Active Archive Center</source>
        <pub-id pub-id-type="doi">10.3334/ORNLDAAC/1511</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Richardson, A. D., Klosterman, S. &amp; Toomey, M. In <italic>Phenology:</italic> An <italic>Integrative Environmental Science</italic>(ed Schwartz, M.) 413–430 (Springer Netherlands, 2013).</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Crall</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Volunteer recruitment and retention in online citizen science projects using marketing strategies: lessons from Season Spotter</article-title>
        <source>JCOM.</source>
        <year>2017</year>
        <volume>16</volume>
        <fpage>A01</fpage>
        <pub-id pub-id-type="doi">10.22323/2.16010201</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="data">
        <name>
          <surname>Seyednasrollah</surname>
          <given-names>B</given-names>
        </name>
        <etal/>
        <year>2019</year>
        <data-title>PhenoCam Dataset v2.0: Vegetation Phenology from Digital Camera Imagery, 2000-2018</data-title>
        <source>ORNL Distributed Active Archive Center</source>
        <pub-id pub-id-type="doi">10.3334/ORNLDAAC/1674</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="data">
        <name>
          <surname>Milliman</surname>
          <given-names>T</given-names>
        </name>
        <etal/>
        <year>2019</year>
        <data-title>PhenoCam Dataset v2.0: Digital Camera Imagery from the PhenoCam Network, 2000-2018</data-title>
        <source>ORNL Distributed Active Archive Center</source>
        <pub-id pub-id-type="doi">10.3334/ORNLDAAC/1689</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">Lam, E. Y. In <italic>Proceedings of the Ninth International Symposium on Consumer Electronics</italic>, <italic>2005 (ISCE 2005)</italic>. 134–139 (Macau, 2005).</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <mixed-citation publication-type="other">Jacobs, N. <italic>et al</italic>. In <italic>Proceedings of the 17th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems</italic>. 111–120 (Seattle, Washington, 2009).</mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Walker</surname>
            <given-names>DA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The Circumpolar Arctic vegetation map</article-title>
        <source>Journal of Vegetation Science.</source>
        <year>2005</year>
        <volume>16</volume>
        <fpage>267</fpage>
        <lpage>282</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1654-1103.2005.tb02365.x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <mixed-citation publication-type="other">Ricklefs, R. E. <italic>The Economy of Nature</italic> 6th edn, (W. H. Freeman and Company New York, 2008).</mixed-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <mixed-citation publication-type="other">Whittaker, R. <italic>Communities and Ecosystems</italic> 2nd edn, (Macmillan New York, 1975).</mixed-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="data">
        <name>
          <surname>Seyednasrollah</surname>
          <given-names>B</given-names>
        </name>
        <year>2017</year>
        <data-title>drawROI: An interactive toolkit to extract phenological time series data from digital repeat photography</data-title>
        <source>Zenodo</source>
        <pub-id pub-id-type="doi">10.5281/zenodo.1066588</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="data">
        <name>
          <surname>Seyednasrollah</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Milliman</surname>
          <given-names>T</given-names>
        </name>
        <name>
          <surname>Richardson</surname>
          <given-names>AD</given-names>
        </name>
        <year>2018</year>
        <data-title>xROI: A Toolkit to Delinate Region of Interests (ROI’s) and Extract Time-series Data from Digital Repeat Photography Images</data-title>
        <source>Zenodo</source>
        <pub-id pub-id-type="doi">10.5281/zenodo.1204366</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Seyednasrollah</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Milliman</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Richardson</surname>
            <given-names>AD</given-names>
          </name>
        </person-group>
        <article-title>Data extraction from digital repeat photography using xROI: An interactive framework to facilitate the process</article-title>
        <source>ISPRS Journal of Photogrammetry and Remote Sensing.</source>
        <year>2019</year>
        <volume>152</volume>
        <fpage>132</fpage>
        <lpage>144</lpage>
        <pub-id pub-id-type="doi">10.1016/j.isprsjprs.2019.04.009</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="data">
        <name>
          <surname>Seyednasrollah</surname>
          <given-names>B</given-names>
        </name>
        <year>2017</year>
        <data-title>hazer: Quantifying haze factor for RGB images to identify cloudy and foggy weather</data-title>
        <source>Zenodo</source>
        <pub-id pub-id-type="doi">10.5281/zenodo.1008568</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hufkens</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Basler</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Milliman</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Melaas</surname>
            <given-names>EK</given-names>
          </name>
          <name>
            <surname>Richardson</surname>
            <given-names>AD</given-names>
          </name>
        </person-group>
        <article-title>An integrated phenology modelling framework in R</article-title>
        <source>Methods in Ecology and Evolution.</source>
        <year>2018</year>
        <volume>9</volume>
        <fpage>1276</fpage>
        <lpage>1285</lpage>
        <pub-id pub-id-type="doi">10.1111/2041-210X.12970</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Omernik</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Griffith</surname>
            <given-names>GE</given-names>
          </name>
        </person-group>
        <article-title>Ecoregions of the Conterminous United States: Evolution of a Hierarchical Spatial Framework</article-title>
        <source>Environ. Manage.</source>
        <year>2014</year>
        <volume>54</volume>
        <fpage>1249</fpage>
        <lpage>1266</lpage>
        <pub-id pub-id-type="doi">10.1007/s00267-014-0364-1</pub-id>
        <pub-id pub-id-type="pmid">25223620</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
