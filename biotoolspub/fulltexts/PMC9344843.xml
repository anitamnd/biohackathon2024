<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9344843</article-id>
    <article-id pub-id-type="pmid">35731214</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac405</article-id>
    <article-id pub-id-type="publisher-id">btac405</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Gene Expression</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Identifying interactions in omics data for clinical biomarker discovery using symbolic regression</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Christensen</surname>
          <given-names>Niels Johan</given-names>
        </name>
        <aff><institution>Department of Chemistry, University of Copenhagen</institution>, Copenhagen 1871, <country country="DK">Denmark</country></aff>
        <aff><institution>Abzu ApS</institution>, Copenhagen 2150, <country country="DK">Denmark</country></aff>
        <xref rid="btac405-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7352-3994</contrib-id>
        <name>
          <surname>Demharter</surname>
          <given-names>Samuel</given-names>
        </name>
        <xref rid="btac405-cor1" ref-type="corresp"/>
        <aff><institution>Abzu ApS</institution>, Copenhagen 2150, <country country="DK">Denmark</country></aff>
        <xref rid="btac405-FM1" ref-type="author-notes"/>
        <!--sam.demharter@abzu.ai-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Machado</surname>
          <given-names>Meera</given-names>
        </name>
        <aff><institution>Abzu ApS</institution>, Copenhagen 2150, <country country="DK">Denmark</country></aff>
        <xref rid="btac405-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pedersen</surname>
          <given-names>Lykke</given-names>
        </name>
        <aff><institution>Abzu ApS</institution>, Copenhagen 2150, <country country="DK">Denmark</country></aff>
        <xref rid="btac405-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Salvatore</surname>
          <given-names>Marco</given-names>
        </name>
        <aff><institution>Abzu ApS</institution>, Copenhagen 2150, <country country="DK">Denmark</country></aff>
        <xref rid="btac405-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Stentoft-Hansen</surname>
          <given-names>Valdemar</given-names>
        </name>
        <aff><institution>Abzu ApS</institution>, Copenhagen 2150, <country country="DK">Denmark</country></aff>
        <xref rid="btac405-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Iglesias</surname>
          <given-names>Miquel Triana</given-names>
        </name>
        <aff><institution>Abzu ApS</institution>, Copenhagen 2150, <country country="DK">Denmark</country></aff>
        <xref rid="btac405-FM1" ref-type="author-notes"/>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btac405-cor1">To whom correspondence should be addressed. <email>sam.demharter@abzu.ai</email></corresp>
      <fn id="btac405-FM1">
        <label>†</label>
        <p>All authors contributed equally.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-06-22">
      <day>22</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>22</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <volume>38</volume>
    <issue>15</issue>
    <fpage>3749</fpage>
    <lpage>3758</lpage>
    <history>
      <date date-type="received">
        <day>09</day>
        <month>3</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>22</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>11</day>
        <month>6</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>17</day>
        <month>6</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>06</day>
        <month>7</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac405.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>The identification of predictive biomarker signatures from omics and multi-omics data for clinical applications is an active area of research. Recent developments in assay technologies and machine learning (ML) methods have led to significant improvements in predictive performance. However, most high-performing ML methods suffer from complex architectures and lack interpretability.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We present the application of a novel symbolic-regression-based algorithm, the QLattice, on a selection of clinical omics datasets. This approach generates parsimonious high-performing models that can both predict disease outcomes and reveal putative disease mechanisms, demonstrating the importance of selecting maximally relevant and minimally redundant features in omics-based machine-learning applications. The simplicity and high-predictive power of these biomarker signatures make them attractive tools for high-stakes applications in areas such as primary care, clinical decision-making and patient stratification.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The QLattice is available as part of a python package (feyn), which is available at the Python Package Index (<ext-link xlink:href="https://pypi.org/project/feyn/" ext-link-type="uri">https://pypi.org/project/feyn/</ext-link>) and can be installed via pip. The documentation provides guides, tutorials and the API reference (<ext-link xlink:href="https://docs.abzu.ai/" ext-link-type="uri">https://docs.abzu.ai/</ext-link>). All code and data used to generate the models and plots discussed in this work can be found in <ext-link xlink:href="https://github.com/abzu-ai/QLattice-clinical-omics" ext-link-type="uri">https://github.com/abzu-ai/QLattice-clinical-omics</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary material</xref> is available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <sec>
      <title>1.1 Background</title>
      <p>The rapid increase in biological data obtained through high-throughput technologies offers new opportunities to unravel the networks of molecular interactions that underlie health and disease (<xref rid="btac405-B29" ref-type="bibr">Perkel, 2021</xref>). An important contribution to this is made by genomics, transcriptomics, proteomics, lipidomics and metabolomics studies, which generate thousands of measurements per sample and offer the unique opportunity to uncover molecular signatures associated with a particular condition or phenotype. These signatures have the potential to act as biomarkers, i.e. a biological characteristic used in the evaluation of normal, abnormal or pathogenic conditions. Biomarker profiles have been found to be particularly useful for medical decision making, where use cases such as surrogate endpoints, exposure, diagnosis and disease management have been identified (<xref rid="btac405-B15" ref-type="bibr">Ghosh and Poisson, 2009</xref>). Although the large amount of omics data contains extensive information, it is not always trivial to extract actionable insights from it. Challenges include the high dimensionality of datasets where the number of variables far exceeds the number of samples, unbalanced measured outcomes (target variables), heterogeneous molecular profiles with multiple subtypes of patients and diseases, and instrumental and experimental biases (<xref rid="btac405-B23" ref-type="bibr">Libbrecht and Noble, 2015</xref>; <xref rid="btac405-B31" ref-type="bibr">Podgórski, 2021</xref>; <xref rid="btac405-B44" ref-type="bibr">Whalen <italic toggle="yes">et al.</italic>, 2021</xref>).</p>
      <p>Classical statistical modelling has long been the gold standard for the analysis of genomics and transcriptomics data analysis. As a result, a significant amount of post-processing is required to condense information into meaningful results, e.g. through manual searching, enrichment or pathway analysis. An inherent challenge in the wide data matrices typical of omics is the existence of dependencies between features. This phenomenon is called ‘multicollinearity’ or ‘concurvity’ when linear and non-linear dependencies are involved, respectively (<xref rid="btac405-B7" ref-type="bibr">Buja <italic toggle="yes">et al.</italic>, 1989</xref>). The increasing availability of affordable computing power and high-throughput omics data has led to the increasing use of machine learning (ML) in the life sciences and pharmaceutical industries. In addition, ML methods have been used for biomarker discovery based on omics data, where they are beginning to outperform state-of-the-art assays (<xref rid="btac405-B27" ref-type="bibr">Mann <italic toggle="yes">et al.</italic>, 2021</xref>). Feature selection methods such as minimum redundancy maximum relevance have also shown great utility in identifying parsimonious sets of features that act as simple, predictive and robust signatures (<xref rid="btac405-B0230403" ref-type="bibr">Radovic, 2017</xref>).</p>
      <p>Due to the inherent noise of biological data and the ‘curse of dimensionality’ (<xref rid="btac405-B1" ref-type="bibr">Altman and Krzywinski, 2018</xref>; <xref rid="btac405-B17" ref-type="bibr">Hastie <italic toggle="yes">et al.</italic>, 2001</xref>) (more features than observations), it is a non-trivial task to perform traditional ML without misleading or overfitting the model during training, such that it is unable to robustly predict outcomes on unseen samples (<xref rid="btac405-B14" ref-type="bibr">Domingos, 2012</xref>). In addition, most state-of-the-art ML models are difficult to interpret and are therefore often considered complex ‘black boxes’ (<xref rid="btac405-B26" ref-type="bibr">Lundberg and Lee, 2017</xref>). Applying black-box ML models such as random forests and neural networks to omics data has proven effective in identifying predictive biomarkers (<xref rid="btac405-B11" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2020</xref>), but the underlying relationships between features remain hidden, and especially for decisions where the stakes are high, it has been argued that interpretable methods should be used wherever possible (<xref rid="btac405-B35" ref-type="bibr">Rudin, 2019</xref>).</p>
    </sec>
    <sec>
      <title>1.2 Symbolic regression and parsimonious models</title>
      <p>Recently, the QLattice, a new ML method based on symbolic regression (SR), has shown promising results in terms of performance and interpretability (<ext-link xlink:href="https://doi.org/10.48550/arXiv.2103.15147" ext-link-type="uri">https://doi.org/10.48550/arXiv.2103.15147</ext-link>). The goal of any implementation of SR is to model a relationship between one or more independent variables <italic toggle="yes">X</italic> and a dependent variable <italic toggle="yes">y</italic> by finding a suitable combination of mathematical operators and parameters. Even when considering only expressions with finite length, the search space is usually too large for any kind of brute force strategy, and thus, alternative methods are required. All SR algorithms can be thought of as methods of searching this combinatorial space effectively. SR is an active field of research and there are multiple examples of recent implementations (<xref rid="btac405-B8" ref-type="bibr">Burlacu <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac405-B37" ref-type="bibr">Udrescu <italic toggle="yes">et al.</italic>, 2020</xref>) (<ext-link xlink:href="https://gplearn.readthedocs.io/en/stable/" ext-link-type="uri">https://gplearn.readthedocs.io/en/stable/</ext-link>).</p>
      <p>SR is particularly suitable for scenarios where the number of features in the model should be small and their interpretation and interactions are of primary interest. Furthermore, it seeks to solve problems where the mathematical form of the data generating process cannot be assumed, or approximated, <italic toggle="yes">a priori</italic>. This is in contrast to the typical regression problem where parameters are fitted to a presupposed model, like linear models or polynomials. Thanks to its unconstrained nature, SR can usually attain higher performances while keeping the number of explicit parameters as low as possible.</p>
      <p>It is well known that most functions can be approximated by using an arbitrarily large number of coefficients and functions belonging to a complete set (e.g. Fourier series, Chebyshev polynomials, etc.). Analogously, one can theoretically build a model that explains <italic toggle="yes">y</italic> in terms of <italic toggle="yes">X</italic> with arbitrarily low train error, even if the approximated mathematical model is ostensibly different from the data-generating process. This does not necessarily pose a problem to types of research where the primary objective is to produce a working model that fits well the data, but vital information may be lost along with interpretability as model complexity grows. The most well-known example of this is deep neural networks, where e.g. modern language models contain billions of parameters, inevitably trading off interpretability for performance.</p>
      <p>In contrast, the aspiration of SR is that domain knowledge can be applied and extracted more efficiently by seeking simpler mathematical models to preserve explainability from a human perspective. In principle, this increases the likelihood of discovering driving mechanisms in data, and inclines SR methods towards maximum information gathering, which is vital in (e.g. life) sciences where both performance and interpretability is important. In practice, SR methods achieve this by using parsimonious models that explain the data with a minimal number of parameters. Additionally, one can use complexity measures such as Bayesian information criterion (BIC) and Akaike information criterion (AIC) to ensure that the resulting models generalise well from train to test set.</p>
      <p>Here, we applied the QLattice to four different omics problems to identify biomarker signatures that predict clinical outcomes while also revealing new interactions in the data. We demonstrate how highly complex problems can quickly be condensed into a set of simple models that can be reasoned and used as hypotheses for potential mechanisms underlying the problem at hand.</p>
    </sec>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 The QLattice</title>
      <p>The QLattice is a SR engine that aims to solve the optimisation problem of finding the functions that best fit the data. It applies an evolutionary algorithm framework to find the combinations of inputs, operators and parameters that minimise the fitting error in a supervised learning problem (see <xref rid="btac405-B20" ref-type="bibr">Koza (1992)</xref> for seminal work on genetic programming, and a practical guide in <xref rid="btac405-B32" ref-type="bibr">Poli <italic toggle="yes">et al.</italic> (2008)</xref>).</p>
      <p>The QLattice algorithm works as follows: first it generates an initial sample of functions, fits them with gradient descent, and evaluates them for fitness. This initial sample is formed using a set of estimated priors assigned to each input based on its mutual information with the output. Then, the best performing functions are used to create a new generation of functions consisting of three groups: (i) the best performers from the previous generation, (ii) mutated versions of the best performers from the previous generation and (iii) a completely new set of sampled functions. Instead of sampling mutations and new functions from a uniform distribution of inputs and operators, the QLattice draws from a probability distribution that is learned thanks to a mapping between the functional space and a lattice. Thus, with each generation the QLattice improves the probability distribution estimation. As this iterative process continues, the QLattice expands the search for the best fitting functions. The result of a training run is a list of functions sorted by a user-defined quality metric. These functions serve as hypotheses that each serve as their own solution to the problem. A more extensive description of the methodology can be found in <xref rid="btac405-B21" ref-type="bibr">Larsen (2021)</xref>.</p>
      <p>The QLattice can be used in both regression and classification tasks for supervised learning problems. In the case of classification, the algorithm is designed to work with binary problems, although it can be easily extended to multi-class targets using a one-versus-rest approach (see <xref rid="btac405-B4" ref-type="bibr">Bishop (2006)</xref> for detailed description of the method). All the QLattice models discussed in this manuscript are trained to perform binary classification tasks. The target variables are encoded as 0 or 1, and the output of the models is to be interpreted as a probability. In order to keep the outputs between 0 and 1, all the mathematical expressions are wrapped with the logistic regression function <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext>exp</mml:mtext><mml:mo> </mml:mo><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, expressed throughout the text as logreg.</p>
      <p>The Feyn Python library (<ext-link xlink:href="https://doi.org/10.48550/arXiv.2104.05417" ext-link-type="uri">https://doi.org/10.48550/arXiv.2104.05417</ext-link>) is the interface between the user and the QLattice, and it is used to train and analyse new models. Its high-level train function returns a list of ten models sorted by a criterion of choice (see documentation at <ext-link xlink:href="https://docs.abzu.ai" ext-link-type="uri">https://docs.abzu.ai</ext-link>). The default sorting option is the BIC, which amounts to the training loss plus a complexity penalty, and allows selection of the most generalisable models without compromising training speed (<xref rid="btac405-B17" ref-type="bibr">Hastie <italic toggle="yes">et al.</italic>, 2001</xref>).</p>
      <p>A majority of the plots in this article were created using the Feyn (<ext-link xlink:href="https://doi.org/10.48550/arXiv.2104.05417" ext-link-type="uri">https://doi.org/10.48550/arXiv.2104.05417</ext-link>) (which uses Matplotlib <xref rid="btac405-B18" ref-type="bibr">Hunter (2007)</xref> extensively), and the Seaborn <xref rid="btac405-B42" ref-type="bibr">Waskom (2021)</xref> libraries.</p>
    </sec>
    <sec>
      <title>2.2 Cross-validation</title>
      <p>Overfitting and spurious correlations are major concerns when applying ML to the wide datasets typical of many areas of computational biology such as genetics, transcriptomics and proteomics (i.e. when the number of features is much larger than the number of observations). For these kinds of datasets, simple models with complexity penalties tend to offer competitive performances (<xref rid="btac405-B17" ref-type="bibr">Hastie <italic toggle="yes">et al.</italic>, 2001</xref>). This is the case of the models selected by the QLattice when the BIC criterion is enabled.</p>
      <p>The BIC criterion used for model selection, however, does not provide an unbiased estimate of the test performance. Therefore, we use a standard k-fold cross-validation scheme to estimate the performance of the QLattice and determine what one can expect from the models selected by it. We use a scheme with five folds: four folds as a train set and one as a test set. In each of the five training loops, we reset the QLattice and call the train function to avoid “data leakage” in the feature selection. Individual models’ performances are estimated using single train/test splits.</p>
      <p>Finally, in the <xref rid="sup1" ref-type="supplementary-material">Supplementary material</xref>, we present a comprehensive benchmark of the QLattice along with other ML algorithms in combination with different feature selection techniques on all four datasets discussed in the manuscript.</p>
    </sec>
    <sec>
      <title>2.3 Selection of models for further analysis</title>
      <p>In ML, the emphasis is usually put on test-set performance. In most instances, model selection is done with the sole goal of finding the models that will generalise best on new data. BIC is a good example of such a model selection tool, and the QLattice uses it to explore and find the models with strongest signal—both in the train and test sets. In the cases where the user is only interested in prediction performance, one should select the model with the lowest BIC score. This is the selection criterion we followed in the benchmarking section.</p>
      <p>However, interpretable algorithms like the QLattice have more goals than performance. They are also used to generate hypotheses about the features involved in a process, and their specific relations. When using BIC as a criterion, all the models returned by the QLattice can be expected to highlight robust patterns in the data. Although the performance of the models might differ, one should consider all of them valid. The list of models returned by the QLattice might highlight a combination of patterns: different mechanisms, the same one represented by multicollinear features, already known biomarkers, or completely new candidates. The evaluation of the user (<italic toggle="yes">human in the loop</italic>) is then necessary to extract the relevant learnings from the models and put them in the context of the question at hand.</p>
      <p>For the sake of clarity, we only discuss one model in each of the first three cases. We selected the models according to performance and interpretability: when models had very similar performances, we chose the simplest models first. In the insulin response case we used evidence from previous studies to choose a model, where the gene features could be easily interpreted.</p>
      <p>Note, that the biomarker candidates selected by the models on the different cases analysed in this article should be further investigated—both in relation to the disease mechanism and with regards to confounding factors (e.g. cohort dependencies).</p>
    </sec>
    <sec>
      <title>2.4 Data preparation</title>
      <sec>
        <title> </title>
        <sec>
          <title> </title>
          <sec>
            <title>Proteomics: Alzheimer’s disease</title>
            <p>The data were taken from <xref rid="btac405-B3" ref-type="bibr">Bader <italic toggle="yes">et al.</italic> (2020)</xref> and consist of 1166 protein expression of the cerebrospinal fluid of 137 subjects, collected in three sample groups (we address the possible confounding factors in Section 3). We used the QLattice to predict whether a patient would develop Alzheimer (dependent variable = 1) or not (dependent variable = 0).</p>
          </sec>
          <sec>
            <title>Gene expression: relevant genes for insulin response in obese and never-obese women</title>
            <p>The data were retrieved from <xref rid="btac405-B28" ref-type="bibr">Mileti et al. (2021)</xref>. The dataset consists of gene expression from a total of 23 never obese and 23 obese women sequenced before and 2 years after bariatric surgery (post-obese) using RNA sequencing (CAGE) (<xref rid="btac405-B28" ref-type="bibr">Mileti et al., 2021</xref>). The only pre-processing done was to normalise the data from raw counts to (tag-per-million normalisation, the gold standard for CAGE data; <xref rid="btac405-B28" ref-type="bibr">Mileti et al., 2021</xref>). The data are balanced for MValue, body mass index and age across sample groups. We used to QLattice to model the response to insulin based on gene-expression measurements and predicted whether an individual is in a fasting (target variable = 0) or hyperinsulinemic (target variable = 1) state.</p>
          </sec>
          <sec>
            <title>Epigenomics: hepatocellular carcinoma</title>
            <p>The data were processed to contain only the 1712 most important features, filtered for variance. The curated dataset contained 1712 CpG island (CGI) features with a binary target of 55 cancer-free (target variable = 0) and 36 cancer (target variable = 1) individuals coming from a single sample group (plasma samples) <xref rid="btac405-B43" ref-type="bibr">Wen (2015)</xref>. The CGI features cover the methylated alleles per million mapped reads.</p>
          </sec>
          <sec>
            <title>Multi-omics: breast cancer</title>
            <p>The dataset was obtained from <xref rid="btac405-B12" ref-type="bibr">Ciriello <italic toggle="yes">et al.</italic> (2015)</xref> and contains multi-omics data from 705 breast tumour samples of different patients. We use the QLattice to predict outcomes; a survival outcome is encoded with target variable = 0 (611 patients) and a fatal outcome with target variable = 1 (94 patients). The data was extracted from The Cancer Genome Atlas through the R-package ‘curatedTCGAData’ (<xref rid="btac405-B33" ref-type="bibr">Ramos <italic toggle="yes">et al.</italic>, 2020</xref>) and included four data types: somatic mutations, copy number variations, gene expressions and protein expressions. The raw data were pre-processed with a variance threshold limiting each type of input to the highest variance features. The data were stratified for lobular and ductal subtypes in each train/test split and the models were assessed for potential confounding influences from factors such as age, stage and treatment regimen.</p>
          </sec>
        </sec>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <p>In the following cases, we showcase different aspects of the QLattice using four different omics data types:
</p>
    <list list-type="bullet">
      <list-item>
        <p><bold>Interpretability:</bold> In the proteomics case, we show how the QLattice finds high-performing models that can be easily interpreted.</p>
      </list-item>
      <list-item>
        <p><bold>Feature combinations:</bold> In the gene-expression case, we demonstrate how the QLattice finds biomarker signatures that together explain the data better than any single feature on its own.</p>
      </list-item>
      <list-item>
        <p><bold>Multicollinearity:</bold> In the epigenomics case, we show how the QLattice deals with multicollinearity typical of omics data by choosing the combination of features that best explains the target while minimising complexity of the model.</p>
      </list-item>
      <list-item>
        <p><bold>Multi-omics and non-linear interactions:</bold> In the multiomics case, we highlight how the QLattice can find non-linear interactions within and across omics data types that help to stratify patient populations.</p>
      </list-item>
    </list>
    <sec>
      <title>3.1 Proteomics: Alzheimer’s disease</title>
      <sec>
        <title>Background</title>
        <p>Despite many decades of research, neurodegenerative diseases remain a major threat to human health and are a substantial cause of mortality. Alzheimer’s disease (AD) is the most common type of dementia, and currently no therapeutics can halt or significantly slow its fatal progression (<xref rid="btac405-B38" ref-type="bibr">van der Schaar <italic toggle="yes">et al.</italic>, 2021</xref>). Furthermore, short of an autopsy, there is no definitive way to diagnose AD, and it is in general impossible to predict who will develop the disease.</p>
        <p>Here, we demonstrate how the QLattice can be used to discover protein biomarkers for AD working with the data from <xref rid="btac405-B3" ref-type="bibr">Bader <italic toggle="yes">et al.</italic> (2020)</xref>. We will use this example as an introduction to the QLattice functionality and capabilities.</p>
      </sec>
      <sec>
        <title>Model analysis</title>
        <p>After splitting the dataset into 80% train and 20% test partitions, we ran the QLattice on the train partition to obtain 10 best unique models from the QLattice (<xref rid="btac405-T1" ref-type="table">Table 1</xref>). Each model points to a relation that serves as a data-derived hypothesis. Thus, all 10 models potentially hold insights into the mechanisms involved in AD.</p>
        <table-wrap position="float" id="btac405-T1">
          <label>Table 1.</label>
          <caption>
            <p>The lowest BIC-scoring models returned by the QLattice for the AD dataset</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Functional form (logreg())</th>
                <th align="center" rowspan="1" colspan="1">BIC</th>
                <th align="center" rowspan="1" colspan="1">AUC train</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">LILRA2 + MAPT + age at CSF collection</td>
                <td rowspan="1" colspan="1">46.11</td>
                <td rowspan="1" colspan="1">0.98</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">IGKV2D-29 + LILRA2 + MAPT</td>
                <td rowspan="1" colspan="1">49.11</td>
                <td rowspan="1" colspan="1">0.98</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">FAM174A + IGLV4-69 + MAPT</td>
                <td rowspan="1" colspan="1">49.28</td>
                <td rowspan="1" colspan="1">0.97</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">MAPT*(AJAP1 + SERPINE2.1)</td>
                <td rowspan="1" colspan="1">49.45</td>
                <td rowspan="1" colspan="1">0.97</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">ENOPH1 + GPC1 + MAPT</td>
                <td rowspan="1" colspan="1">51.42</td>
                <td rowspan="1" colspan="1">0.97</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">GPC1 + MAPT + age at CSF collection</td>
                <td rowspan="1" colspan="1">52.27</td>
                <td rowspan="1" colspan="1">0.98</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">ENDOD1 + MAPT + PPIA</td>
                <td rowspan="1" colspan="1">54.08</td>
                <td rowspan="1" colspan="1">0.97</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">GPC1 + MAPT + SERPINE2.1</td>
                <td rowspan="1" colspan="1">54.86</td>
                <td rowspan="1" colspan="1">0.97</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">IGLV4-69 + MAPT</td>
                <td rowspan="1" colspan="1">54.95</td>
                <td rowspan="1" colspan="1">0.97</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">MAPT + NXPH3 + SPINT2</td>
                <td rowspan="1" colspan="1">57.0</td>
                <td rowspan="1" colspan="1">0.97</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <p><italic toggle="yes">Note</italic>: The majority are linear and contain three features. Training set AUC performances are comparable.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>We chose the model with the lowest BIC-score for thorough analysis. This model uses MAPT, age at CSF collection and LILRA2 as inputs combined with additions to predict the probability of AD for a given patient. As a ML model, it can be analysed in terms of test prediction metrics (<xref rid="btac405-F1" ref-type="fig">Fig. 1</xref>) to verify that the relations found are not spurious (see <xref rid="btac405-B41" ref-type="bibr">Walsh (2021)</xref> for a review on the matter).</p>
        <fig position="float" id="btac405-F1">
          <label>Fig. 1.</label>
          <caption>
            <p>Metrics of the best model (ranked by BIC criterion) for predicting Alzheimer’s disease. The model is robust as shown by the relatively small drop in performance from the training set (AUC 0.98) to the test set (AUC 0.92). Receiver operator characteristic (ROC) curves (top) and confusion matrices for training set (bottom left) and test set (bottom right)</p>
          </caption>
          <graphic xlink:href="btac405f1" position="float"/>
        </fig>
        <p>We ran the cross validation scheme outlined in Section 2. The estimated test performance of the QLattice top models was AUC = 0.94 (mean of the five folds, with a standard deviation of 0.05). We note that the predictive power might be overestimated due to the presence of confounders in the data.</p>
      </sec>
      <sec>
        <title>Model interpretation</title>
        <p>The known AD biomarker MAPT (tau protein) was consistently found in the highest scoring QLattice models, while the additional features varied between models. <xref rid="btac405-F2" ref-type="fig">Figure 2</xref> shows how MAPT contributes prominently to the signal of the chosen model. The plot shows the signal flow in the model, and the colour represents the strength of the association of each node to the clinical outcome. The association measure used is mutual information (<xref rid="btac405-B13" ref-type="bibr">Cover and Thomas, 2006</xref>). Thus, the features age at CSF collection and LILRA2 are both secondary to MAPT but both improve the model as made clear by the rising mutual information numbers displayed on top of the nodes. MAPT on its own has a mutual information score of 0.37, but this number rises to 0.56 when applying the additional features and the right mathematical operators—in this case additions.</p>
        <fig position="float" id="btac405-F2">
          <label>Fig. 2.</label>
          <caption>
            <p>Model signal path for AD. A prominent signal contribution from MAPT was found in all 10 models (green). The signal is expressed in terms of mutual information and displayed above the nodes in the model (see <xref rid="btac405-B13" ref-type="bibr">Cover and Thomas (2006)</xref>) (A color version of this figure appears in the online version of this article.)</p>
          </caption>
          <graphic xlink:href="btac405f2" position="float"/>
        </fig>
        <p>The partial dependence plot (<xref rid="btac405-F3" ref-type="fig">Fig. 3</xref>) shows that at fixed LILRA2, higher levels of MAPT leads to positive AD prediction. When the MAPT level reaches around 25 000 the model starts to predict AD-positive. In addition, the effect of age is displayed in the plot. Unsurprisingly, at a higher age comparably lower MAPT levels trigger the model to predict AD-positive (when the predicted probability rises above 0.5), as displayed by the coloured curves.</p>
        <fig position="float" id="btac405-F3">
          <label>Fig. 3.</label>
          <caption>
            <p>Partial dependence plot for the AD model: marginal effect of MAPT on AD-risk</p>
          </caption>
          <graphic xlink:href="btac405f3" position="float"/>
        </fig>
        <p>It should be mentioned that the protein levels of LILRA2 only present a significant difference between AD and non-AD patients for one of the cohorts depicted in <xref rid="btac405-B3" ref-type="bibr">Bader <italic toggle="yes">et al.</italic> (2020)</xref> (<italic toggle="yes">P</italic>-value of 0.008 with a Student’s <italic toggle="yes">t</italic>-test). Since we fix LILRA2 in <xref rid="btac405-F3" ref-type="fig">Figure 3</xref>, the model response to MAPT is cohort-independent. Moreover, the three age values depicted in <xref rid="btac405-F3" ref-type="fig">Figure 3</xref> are all between 62 and 72 years old. This ensures that the observed model response is free from any bias arising from the younger control group present in one of the cohorts (<xref rid="btac405-B3" ref-type="bibr">Bader <italic toggle="yes">et al.</italic>, 2020</xref>). Including suspected confounding factors in the model is a standard practice to statistically control for confounders when using linear and logistic regression (see <xref rid="btac405-B2" ref-type="bibr">Angrist and Pischke (2008)</xref> for an extensive review on the topic).</p>
        <p>The QLattice models provide data-derived hypotheses that can quickly provide an overview of possible explanations to a given question. For instance, the first model in <xref rid="btac405-T1" ref-type="table">Table 1</xref> may be translated into the following hypothesis: ‘MAPT is a main driver of AD since it is positively correlated with AD status’ and ‘MAPT interacts both with the age of the patient and with the protein LILRA2’. Thus, the mathematical simplicity of the QLattice models allows direct translation into hypotheses that can be readily understood and tested. This marks a significant departure from black-box ML models, where the inner working of the models is usually more opaque.</p>
      </sec>
    </sec>
    <sec>
      <title>3.2 Gene expression: relevant genes for insulin response in obese and never obese women</title>
      <sec>
        <title>Background</title>
        <p>Obesity is a major public health problem, and obese people are at higher risk of heart disease, stroke and type 2 diabetes. Obesity is considered a medical condition caused by eating more calories than necessary, but it can also be caused by a decreased response to insulin.</p>
        <p>To shed light on this, a recent publication (<xref rid="btac405-B28" ref-type="bibr">Mileti et al., 2021</xref>) focused on white adipose tissue, which is one of the main insulin-responsive tissues. In this study, obese subjects underwent gastric bypass surgery and lost weight. Weight loss can support the subsequent restoration of the insulin response. In <xref rid="btac405-B28" ref-type="bibr">Mileti et al. (2021)</xref>, insulin sensitivity was determined using the hyperinsulinaemic euglycemic clamp, while the insulin response was measured using cap analysis of gene expression (CAGE) from 23 obese women before and 2 years after bariatric surgery. To control for the effects of surgery, 23 never obese women were also included.</p>
        <p>The experiment was designed to understand the effects of insulin on the expression of different genes. In traditional differential gene expression (DGE) analysis, the individual genes with the strongest and most consistent changes between conditions are highlighted. Here, we propose a complementary approach to DGE analysis that uses the QLattice to identify sets of genes and their interactions that best separate two groups of samples.</p>
        <p>Specifically, we modelled the response to insulin based on gene-expression measurements and predicted whether an individual is in a fasting or hyperinsulinemic state. As well as being a predictive algorithm, the QLattice looks for different interactions between genes that describe the insulin response in two classes of individuals.</p>
      </sec>
      <sec>
        <title>Model analysis</title>
        <p>We inspect the 10 models returned by the QLattice in <xref rid="btac405-T2" ref-type="table">Table 2</xref> after we ran it on the training set (80–20% split). We select the second model for further analysis because it contains PDK4, an established insulin target (<xref rid="btac405-B28" ref-type="bibr">Mileti et al., 2021</xref>); C2CD2L, a positive regulator of insulin secretion during glucose stimulus; and PHF23 a negative regulator of autophagy. To our best knowledge, defects in autophagy homeostasis are also implicated in metabolic disorders such as obesity and insulin resistance as discussed in <xref rid="btac405-B47" ref-type="bibr">Zhang et al. (2018)</xref>. The high performance of this model is summarised in <xref rid="btac405-F4" ref-type="fig">Figure 4</xref> for both the training and test sets. In addition, the QLattice identified other genes known to be insulin targets or found in the article such as C19orf80 and LDLR (<xref rid="btac405-B28" ref-type="bibr">Mileti et al., 2021</xref>).</p>
        <fig position="float" id="btac405-F4">
          <label>Fig. 4.</label>
          <caption>
            <p>ROC AUC scores (top) for the selected three feature model for insulin response. Confusion matrices (bottom left: train, bottom right: test)</p>
          </caption>
          <graphic xlink:href="btac405f4" position="float"/>
        </fig>
        <table-wrap position="float" id="btac405-T2">
          <label>Table 2.</label>
          <caption>
            <p>Lowest BIC-scoring models returned by The QLattice for the insulin response</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Functional form (logreg())</th>
                <th align="center" rowspan="1" colspan="1">BIC</th>
                <th align="center" rowspan="1" colspan="1">AUC train</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">PHF23 + PPP1R35 + RNU6ATAC</td>
                <td rowspan="1" colspan="1">19.58</td>
                <td rowspan="1" colspan="1">1.0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">C2CD2L + PDK4 + PHF23</td>
                <td rowspan="1" colspan="1">20.79</td>
                <td rowspan="1" colspan="1">1.0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CATG000000438721*CDADC1 + SPRY4</td>
                <td rowspan="1" colspan="1">20.81</td>
                <td rowspan="1" colspan="1">1.0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">AC0271191 + CATG000000327481 + PHF23</td>
                <td rowspan="1" colspan="1">28.02</td>
                <td rowspan="1" colspan="1">1.0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CATG000000004671 + MARCH8 + PHF23</td>
                <td rowspan="1" colspan="1">34.91</td>
                <td rowspan="1" colspan="1">0.99</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">SPRY4 + 1/EEF2K</td>
                <td rowspan="1" colspan="1">36.47</td>
                <td rowspan="1" colspan="1">0.99</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">ERVK131 + PHF23 + SPRY4</td>
                <td rowspan="1" colspan="1">36.51</td>
                <td rowspan="1" colspan="1">0.99</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">C19orf80 + CEBPD + DDX6</td>
                <td rowspan="1" colspan="1">37.29</td>
                <td rowspan="1" colspan="1">0.99</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CBX4 + ESAM + LDLR</td>
                <td rowspan="1" colspan="1">38.09</td>
                <td rowspan="1" colspan="1">0.99</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CDKN1A + CTB55O610 + ID2</td>
                <td rowspan="1" colspan="1">38.27</td>
                <td rowspan="1" colspan="1">0.99</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec>
        <title>Qlattice as complementary approach to differential gene expression</title>
        <p>Differential gene expression analysis (DGE) is generally used to detect quantitative changes in expression levels between experimental groups based on normalized read-count data. There are several methods for differential expression analysis based on negative binomial distributions (<xref rid="btac405-B25" ref-type="bibr">Love et al., 2014</xref><underline>;</underline>  <xref rid="btac405-B34" ref-type="bibr">Robinson et al., 2010</xref>) or based on a negative binomial model (Bayesian approaches) (<xref rid="btac405-B16" ref-type="bibr">Hardcastle, 2021</xref>; <xref rid="btac405-B22" ref-type="bibr">Leng and Kendziorski, 2021</xref>; <xref rid="btac405-B36" ref-type="bibr">Smyth, 2004</xref>). Differential expression tools can perform pairwise comparisons or multiple comparisons.</p>
        <p>Alternatively, DGE can be used to identify candidate biomarkers, as it provides a robust method for selecting genes that offer the greatest biological insight into the processes influenced by the condition(s) under investigation. However, this robustness can sometimes translate into rigidity. Signatures expressed in linear combinations, interactions or through non-linear relationships may be overlooked when using DGE.</p>
        <p>SR-based ML models offer a complementary view on the data and highlight predictive signatures. The advantage of this approach is that even simple feature combinations can lead to a high predictive performance. As we can see in the model decision boundaries of <xref rid="btac405-F5" ref-type="fig">Figure 5</xref>, a linear combination of the features PDK4, PHF23 and C2CD2L can characterise the insulin response for almost all individuals in the sample. The strength of the signal is found as well in the test set (see <xref rid="btac405-F4" ref-type="fig">Fig. 4</xref>).</p>
        <fig position="float" id="btac405-F5">
          <label>Fig. 5.</label>
          <caption>
            <p>Decision boundaries of the selected model. We keep the feature C2CD2L fixed at the values corresponding to the 0.25, 0.50 and 0.75 quantiles</p>
          </caption>
          <graphic xlink:href="btac405f5" position="float"/>
        </fig>
        <p>Although PDK4 and PHF23 are reported as significant in the DGE analysis (according to FDR), they do not appear at the top of the list ordered by log-fold change (the one used in <xref rid="btac405-B28" ref-type="bibr">Mileti et al. (2021)</xref>). This apparent discrepancy between the DGE and the QLattice choice can be explained by the fact that the DGE only considers the univariate distributions. From the density plots in <xref rid="btac405-F6" ref-type="fig">Figure 6</xref>, we can indeed see a considerable overlap between the two classes when we look at the univariate distributions of PDK4 and PHF23, which is smaller for the distributions of the linear combination of genes. The effect can also be seen in the mutual information between the variables or their combinations, and the target variable.</p>
        <fig position="float" id="btac405-F6">
          <label>Fig. 6.</label>
          <caption>
            <p>Distributions of the two classes for the variables PDK4 (top), PHF23 (bottom left) and the linear combination found in the second model of <xref rid="btac405-T2" ref-type="table">Table 2</xref> (bottom right)</p>
          </caption>
          <graphic xlink:href="btac405f6" position="float"/>
        </fig>
        <p>In summary, we find that the QLattice can be used as a complementary method to DGE, as it is very good at finding feature combinations that carry strong signals, and as it efficiently explores the feature space without requiring an exhaustive exploration of all features. There have been efforts in this direction using mutual information and partial information decomposition (<xref rid="btac405-B10" ref-type="bibr">Chan <italic toggle="yes">et al.</italic>, 2017</xref>). Consequently, the QLattice can suggest specific operations for the proposed combinations and help to better understand biologically relevant interactions that were previously hidden.</p>
        <sec>
          <title>Epigenomics: hepatocellular carcinoma</title>
          <sec>
            <title>Background</title>
            <p>Primary liver cancer is a major health burden worldwide and develops in response to chronic inflammation of the liver. This can be caused by a number of insults such as viral infections as well as both alcoholic steatohepatitis and non-alcoholic steatohepatitis. The most common form of liver cancer is hepatocellular carcinoma (HCC), which accounts for 90% of liver cancers and is the third leading cause of cancer mortality worldwide (<xref rid="btac405-B24" ref-type="bibr">Llovet <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac405-B46" ref-type="bibr">Yang and Roberts, 2010</xref>).</p>
            <p>In this HCC diagnosis example, we explore how the QLattice performs on highly multicollinear data. The dataset was taken from a study by <xref rid="btac405-B43" ref-type="bibr">Wen <italic toggle="yes">et al.</italic> (2015)</xref> and contains data generated by methylated CpG tandems amplification and sequencing, a method that can detect thousands of hypermethylated CpG islands (CGIs) simultaneously in circulating cell-free DNA (ccfDNA). The aim is to explain liver cancer occurrence using methylation biomarkers as features. After pre-processing (see Section 2) the curated dataset contained nearly 2000 features. As demonstrated below, the QLattice gave highly predictive models using only a few key interactions.</p>
          </sec>
          <sec>
            <title>Model analysis</title>
            <p>As in the previous case, we split the dataset into train and test partitions (80–20%) and ran the QLattice with default settings on the training set. We inspected the ten models returned in <xref rid="btac405-T3" ref-type="table">Table 3</xref> balancing simplicity and performance. The 10 models all perform equally well, and we therefore chose the model with the least features for further examination (n. 5). The models is shown in <xref rid="btac405-F7" ref-type="fig">Figure 7</xref> and its performance metrics are summarised in <xref rid="btac405-F8" ref-type="fig">Figure 8</xref>.</p>
            <fig position="float" id="btac405-F7">
              <label>Fig. 7.</label>
              <caption>
                <p>A representative model for predicting Hepatocellular Carcinoma. A prominent signal contribution from chr17_59473060_59483266 is found in all 10 models. The signal is expressed in terms of mutual information and displayed above the nodes in the model (<xref rid="btac405-B13" ref-type="bibr">Cover and Thomas, 2006</xref>)</p>
              </caption>
              <graphic xlink:href="btac405f7" position="float"/>
            </fig>
            <fig position="float" id="btac405-F8">
              <label>Fig. 8.</label>
              <caption>
                <p>Metrics of the best model (ranked by BIC criterion) for predicting Hepatocellular Carcinoma. The model is robust as shown by the performance of the training set (AUC 1.0) compared to the test set (AUC 1.0). ROC curves (top) and confusion matrices for training set (bottom left) and test set (bottom right)</p>
              </caption>
              <graphic xlink:href="btac405f8" position="float"/>
            </fig>
            <table-wrap position="float" id="btac405-T3">
              <label>Table 3.</label>
              <caption>
                <p>The lowest BIC-scoring models returned by the QLattice for the HCC dataset</p>
              </caption>
              <table frame="hsides" rules="groups">
                <colgroup span="1">
                  <col valign="top" align="left" span="1"/>
                  <col valign="top" align="char" char="." span="1"/>
                  <col valign="top" align="char" char="." span="1"/>
                </colgroup>
                <thead>
                  <tr>
                    <th rowspan="1" colspan="1">Functional form (logreg())</th>
                    <th align="center" rowspan="1" colspan="1">BIC</th>
                    <th align="center" rowspan="1" colspan="1">AUC train</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1" colspan="1">chr16_6 + chr17_5 + chr6_87</td>
                    <td rowspan="1" colspan="1">11.67</td>
                    <td rowspan="1" colspan="1">1.0</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">chr10_1 * chr17_5 + chrX_37</td>
                    <td rowspan="1" colspan="1">13.56</td>
                    <td rowspan="1" colspan="1">1.0</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">chr16_8 + chr17_5 + chr6_15</td>
                    <td rowspan="1" colspan="1">13.62</td>
                    <td rowspan="1" colspan="1">1.0</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">chr10_1 * chr17_5 + chr1_10</td>
                    <td rowspan="1" colspan="1">14.19</td>
                    <td rowspan="1" colspan="1">1.0</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">chr11_1 + chr17_5 + chr5_18</td>
                    <td rowspan="1" colspan="1">14.68</td>
                    <td rowspan="1" colspan="1">1.0</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">chr17_5 + chr3_99</td>
                    <td rowspan="1" colspan="1">14.72</td>
                    <td rowspan="1" colspan="1">1.0</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">chr10_1 + chr17_5 + chr7_23</td>
                    <td rowspan="1" colspan="1">14.75</td>
                    <td rowspan="1" colspan="1">1.0</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">chr17_5 + chr6_87</td>
                    <td rowspan="1" colspan="1">17.81</td>
                    <td rowspan="1" colspan="1">0.99</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">chr17_5 + chr3_11 + chr3_99</td>
                    <td rowspan="1" colspan="1">19.82</td>
                    <td rowspan="1" colspan="1">1.0</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">chr17_5 + chr19_4 + chr6_15</td>
                    <td rowspan="1" colspan="1">19.88</td>
                    <td rowspan="1" colspan="1">1.0</td>
                  </tr>
                </tbody>
              </table>
            </table-wrap>
            <p>Using 5-fold cross-validation, the QLattice top models yielded an average performance of AUC = 0.93 (mean of the five folds, with a standard deviation of 0.01).</p>
          </sec>
          <sec>
            <title>Model interpretation</title>
            <p>As can be seen in <xref rid="btac405-F9" ref-type="fig">Figure 9</xref>, the primary separator of the two features in the selected model is chr17_59473060_59483266. Individuals who do not have cancer have stable, low levels of methylated alleles, while individuals with cancer generally have higher, more variable levels of this trait. In addition, we find that some cancer individuals have low levels of chr17_59473060_59483266. Furthermore, from the 2d plot of partial dependence in <xref rid="btac405-F9" ref-type="fig">Figure 9</xref> we can also see that low values of both chr17_59473060_59483266 and chr3_9987895_9989619 can be used to identify cancer individuals. This dynamic is captured well in the 2d partial dependence plot of <xref rid="btac405-F9" ref-type="fig">Figure 9</xref>. This is an easily understood model, two genes interacting, generating a top performing model. The model's AUC and confusion matrices on the train and test set are shown in <xref rid="btac405-F10" ref-type="fig">Figure 10</xref>.</p>
            <fig position="float" id="btac405-F9">
              <label>Fig. 9.</label>
              <caption>
                <p>Left: HCC. Pairplot for features in the selected model. Right: 2d response of the model predictions, with train data overlaid. The decision boundary separates the two outcome areas</p>
              </caption>
              <graphic xlink:href="btac405f9" position="float"/>
            </fig>
            <fig position="float" id="btac405-F10">
              <label>Fig. 10.</label>
              <caption>
                <p>Metrics of the best model of the first fold (ranked by BIC criterion) for predicting Breast Cancer outcomes. The model is not overfitted as shown by the performance of the training set (AUC 0.66) compared to the test set (AUC 0.66). ROC curves (top) and confusion matrices for training set (bottom left) and test set (bottom right)</p>
              </caption>
              <graphic xlink:href="btac405f10" position="float"/>
            </fig>
            <p>The models that were generated (<xref rid="btac405-T3" ref-type="table">Table 3</xref>) perform equally well. Aside from chr17_59473060_59483266 all models contain different secondary features and thus there could be molecular substitutes among the other features. To show whether there is multicollinearity, an overview of other correlated features is given in the correlation heatmap, <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref>. The figure shows whether the selected model feature belong to a group of highly correlated features. If this is the case, we can most likely replace this one feature with another from the same group and achieve similar model performance. In this case, the QLattice achieves high performance by selecting one feature from each main variance group in the dataset.</p>
            <p>Instead of using dimensionality reduction such as PCA to group features with similar variance into single features, the QLattice selects representatives from each variance group. The representative that performs best in combination with the other features in the training dataset is selected.</p>
          </sec>
        </sec>
      </sec>
    </sec>
    <sec>
      <title>3.3 Multi-omics: breast cancer</title>
      <sec>
        <title>Background</title>
        <p>Breast cancer is the most common cancer in women, worldwide. There are two main types of breast cancer, ductal and lobular carcinoma. The cancers can be classified as invasive or non-invasive. The non-invasive forms are often referred to as ductal carcinoma <italic toggle="yes">in situ</italic> and lobular carcinoma <italic toggle="yes">in situ</italic>. Even though there are significantly different risks between patients, currently all lesions are treated. This can lead to excessive treatment of the condition in many patients. To complicate matters, breast cancer patients at similar stages of progression can have significantly different treatment responses and survival outcomes (<xref rid="btac405-B19" ref-type="bibr">Katz and Morrow, 2013</xref>; <xref rid="btac405-B39" ref-type="bibr">van Seijen <italic toggle="yes">et al.</italic>, 2019</xref>).</p>
        <p>In this case study, we explore a multi-omics dataset and identify potential regulatory interactions across omics-types [copy numbers (cn), somatic mutations (mu), gene expression (rs) and protein expression (pp)] that could explain and predict survival outcomes of breast-cancer patients. We benchmark the QLattice models with a random forest and show that in addition to revealing interactions the QLattice performs as well as complex ‘black-box’ models. The dataset was obtained from <xref rid="btac405-B12" ref-type="bibr">Ciriello <italic toggle="yes">et al.</italic> (2015)</xref> and contains multi-omics data from 705 breast tumour samples.</p>
        <sec>
          <title> </title>
          <sec>
            <title>Two-feature model analysis</title>
            <p>Upon running the QLattice on different partitions of the data, one can expect different models being selected. These models bring similar albeit complementary insights, as they are able to see different sub-samples of the data. In this case, we obtained diverse models by keeping the lowest BIC-scoring ones from each partition of our cross-validation scheme.</p>
            <p>To maximise interpretability, we started by exploring simple models that allowed for a maximum of two features. The mean test AUC for the best models of all folds was 0.635, with a standard deviation of 0.070. Equations (1) contain the best model (ranked by BIC) for each of the five folds.
<disp-formula id="E1"><label>(1a)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mtext>logreg</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>CHST</mml:mtext><mml:mn>9</mml:mn><mml:mo>×</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>PCK</mml:mtext><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E2"><label>(1b)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:mtext>logreg</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>APOB</mml:mtext><mml:mo>×</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>GPM</mml:mtext><mml:mn>6</mml:mn><mml:mi mathvariant="normal">A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E3"><label>(1c)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mtext>logreg</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>exp</mml:mtext><mml:mo> </mml:mo><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:msup><mml:mrow><mml:mtext>LOC</mml:mtext><mml:mn>283392</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:msup><mml:mrow><mml:mtext>OXTR</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E4"><label>(1d)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mtext>logreg</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>exp</mml:mtext><mml:mo> </mml:mo><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:msup><mml:mrow><mml:mtext>MRAP</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:msup><mml:mrow><mml:mtext>OXTR</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E5"><label>(1e)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mtext>logreg</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>ACVR</mml:mtext><mml:mn>1</mml:mn><mml:mi mathvariant="normal">C</mml:mi><mml:mo>×</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>HEPACAM</mml:mtext><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p>
            <p>Two of the expressions correspond to a bivariate normal distribution, while the others have a multiplicative interaction as shown in equations (1). All the chosen features in the models above are measurements of gene expression.</p>
            <p>From the Pearson correlation heatmap in <xref rid="btac405-F11" ref-type="fig">Figure 11</xref>, we observe that all five models contain a gene-expression feature from the group with highest pairwise Pearson correlation: <italic toggle="yes">rs_PCK1</italic>, <italic toggle="yes">rs_MRAP</italic>, <italic toggle="yes">rs_LOC283392</italic>, <italic toggle="yes">rs_APOB</italic> and <italic toggle="yes">rs_ACVR1C</italic>; their correlation values range from 0.774 to 0.835. Then these features are each combined in a non-linear interaction with the remaining gene expression variables.</p>
            <fig position="float" id="btac405-F11">
              <label>Fig. 11.</label>
              <caption>
                <p>Pairwise Pearson correlation (absolute value) heatmap of the gene expression features in the models shown in equation (1)</p>
              </caption>
              <graphic xlink:href="btac405f11" position="float"/>
            </fig>
            <p>Pairwise correlation gives a measure of the similarity between the input features. In addition, one can calculate the correlation between input features and the output variable, as shown in <xref rid="btac405-T4" ref-type="table">Table 4</xref>. The latter gives a measure of the relevancy of the input features relative to the output. Note in <xref rid="btac405-T4" ref-type="table">Table 4</xref> that <italic toggle="yes">rs_PCK1</italic>, <italic toggle="yes">rs_MRAP</italic>, <italic toggle="yes">rs_LOC283392</italic>, <italic toggle="yes">rs_APOB</italic> and <italic toggle="yes">rs_ACVR1C</italic> are the features with highest relevance in this group. Therefore, akin to the HCC case, the models yielded by the QLattice combine a gene expression variable with high relevance with another gene expression with low similarity score.</p>
            <table-wrap position="float" id="btac405-T4">
              <label>Table 4.</label>
              <caption>
                <p>Pearson correlation between gene expression features and the output <italic toggle="yes">vital.status</italic>, the associated <italic toggle="yes">P</italic>-values and the <italic toggle="yes">P</italic>-values adjusted for multiple hypothesis testing using the Bonferroni correction</p>
              </caption>
              <table frame="hsides" rules="groups">
                <colgroup span="1">
                  <col valign="top" align="left" span="1"/>
                  <col valign="top" align="char" char="." span="1"/>
                  <col valign="top" align="char" char="." span="1"/>
                  <col valign="top" align="char" char="." span="1"/>
                </colgroup>
                <thead>
                  <tr>
                    <th rowspan="1" colspan="1"/>
                    <th align="center" rowspan="1" colspan="1">Pearson corr.</th>
                    <th align="center" rowspan="1" colspan="1">p_value</th>
                    <th align="center" rowspan="1" colspan="1">p_value adj.</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1" colspan="1">rs_APOB</td>
                    <td rowspan="1" colspan="1">0.270</td>
                    <td rowspan="1" colspan="1">3.0e−13</td>
                    <td rowspan="1" colspan="1">5.9e−10</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">rs_LOC283392</td>
                    <td rowspan="1" colspan="1">0.230</td>
                    <td rowspan="1" colspan="1">6.3e−10</td>
                    <td rowspan="1" colspan="1">1.2e−06</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">rs_PCK1</td>
                    <td rowspan="1" colspan="1">0.225</td>
                    <td rowspan="1" colspan="1">1.6e−09</td>
                    <td rowspan="1" colspan="1">3.2e−06</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">rs_MRAP</td>
                    <td rowspan="1" colspan="1">0.214</td>
                    <td rowspan="1" colspan="1">1.0e−09</td>
                    <td rowspan="1" colspan="1">2.0e−05</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">rs_ACVR1C</td>
                    <td rowspan="1" colspan="1">0.206</td>
                    <td rowspan="1" colspan="1">3.1e−08</td>
                    <td rowspan="1" colspan="1">6.1e−05</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">rs_OXTR</td>
                    <td rowspan="1" colspan="1">0.194</td>
                    <td rowspan="1" colspan="1">2.0e−07</td>
                    <td rowspan="1" colspan="1">3.8e−04</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">rs_CHST9</td>
                    <td rowspan="1" colspan="1">0.139</td>
                    <td rowspan="1" colspan="1">2.2e−04</td>
                    <td rowspan="1" colspan="1">4.3e−01</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">rs_GPM6A</td>
                    <td rowspan="1" colspan="1">0.116</td>
                    <td rowspan="1" colspan="1">2.0e−03</td>
                    <td rowspan="1" colspan="1">1.0e + 00</td>
                  </tr>
                  <tr>
                    <td rowspan="1" colspan="1">rs_HEPACAM2</td>
                    <td rowspan="1" colspan="1">0.051</td>
                    <td rowspan="1" colspan="1">1.8 − 01</td>
                    <td rowspan="1" colspan="1">1.0e + 00</td>
                  </tr>
                </tbody>
              </table>
              <table-wrap-foot>
                <fn id="tblfn2">
                  <p><italic toggle="yes">Note</italic>: Values computed using SciPy (<xref rid="btac405-B40" ref-type="bibr">Virtanen <italic toggle="yes">et al.</italic>, 2020</xref>).</p>
                </fn>
              </table-wrap-foot>
            </table-wrap>
            <p>The models’ decisions boundaries are depicted in <xref rid="btac405-F12" ref-type="fig">Figure 12</xref>. The bivariate Gaussian function and the product between the gene expression features identify a ‘hotspot’, i.e. there is a particular range for these gene expressions that indicate whether a breast-cancer patient died or survived. Strikingly, these patients were predominantly suffering from ductal breast cancers. There seems to be a putative molecular interaction that is an important biomarker for ductal breast-cancer survival. The model's AUC and confusion matrices on the train and test sets are shown in <xref rid="btac405-F13" ref-type="fig">Figure 13</xref>.</p>
            <fig position="float" id="btac405-F12">
              <label>Fig. 12.</label>
              <caption>
                <p>Decision boundary for three of the models at the head of each k-fold. The top right aread (green) indicate a higher probability of death, compared to the remaining area (purple) (A color version of this figure appears in the online version of this article.)</p>
              </caption>
              <graphic xlink:href="btac405f12" position="float"/>
            </fig>
            <fig position="float" id="btac405-F13">
              <label>Fig. 13.</label>
              <caption>
                <p>Metrics of the best model of the first fold (ranked by BIC criterion) for predicting Breast Cancer outcomes. The model shows some degree of overfitting as shown by the performance of the training set (AUC 0.75) compared to the test set (AUC 0.67). ROC curves (top) and confusion matrices for training set (bottom left) and test set (bottom right)</p>
              </caption>
              <graphic xlink:href="btac405f13" position="float"/>
            </fig>
            <p>The genes in the models depicted in equations (1) were found to have no relation to the age of the patients. The Pearson correlation coefficient between gene expression and age was computed and the highest absolute Pearson correlation coefficient value between gene expression and age was 0.153 (<italic toggle="yes">P</italic>-value of <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mn>4</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>).</p>
          </sec>
        </sec>
      </sec>
      <sec>
        <title>Comparison with multi-omics models</title>
        <p>Allowing models with higher complexity—more features and operations—can potentially unlock better performing models that mix different <italic toggle="yes">omics</italic>. To this end, we ran the same 5-fold cross-validation scheme allowing a maximum of five features. This should allow for any signal beyond the gene expression ‘hotspot’ to be captured by the QLattice. The resulting average test AUC score on the best models is 0.671 with standard deviation of 0.040. This average result is certainly larger than test AUC of the two feature models, although both scores could be considered statistically compatible.
<disp-formula id="E6"><label>(2a)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>logreg</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>cn</mml:mtext><mml:mo>_</mml:mo><mml:mtext>GBP</mml:mtext><mml:mn>5</mml:mn><mml:mo>+</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>PIK</mml:mtext><mml:mn>3</mml:mn><mml:mi mathvariant="normal">C</mml:mi><mml:mn>2</mml:mn><mml:mi mathvariant="normal">G</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>HS</mml:mtext><mml:mn>3</mml:mn><mml:mtext>ST</mml:mtext><mml:mn>4</mml:mn><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>cn</mml:mtext><mml:mo>_</mml:mo><mml:mtext>PEG</mml:mtext><mml:mn>3</mml:mn><mml:mo>+</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>APOB</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E7"><label>(2b)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>logreg</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>tanh</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>cn</mml:mtext><mml:mo>_</mml:mo><mml:mtext>PRSS</mml:mtext><mml:mn>33</mml:mn><mml:mo>+</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>CYP</mml:mtext><mml:mn>4</mml:mn><mml:mi mathvariant="normal">Z</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>APOB</mml:mtext><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>cn</mml:mtext><mml:mo>_</mml:mo><mml:mtext>PEG</mml:mtext><mml:mn>3</mml:mn><mml:mo>+</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>SLC</mml:mtext><mml:mn>28</mml:mn><mml:mi mathvariant="normal">A</mml:mi><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E8"><label>(2c)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>logreg</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>LGALS</mml:mtext><mml:mn>12</mml:mn><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>mu</mml:mtext><mml:mo>_</mml:mo><mml:mtext>VPS</mml:mtext><mml:mn>13</mml:mn><mml:mi mathvariant="normal">D</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>SLC</mml:mtext><mml:mn>6</mml:mn><mml:mi mathvariant="normal">A</mml:mi><mml:mn>14</mml:mn><mml:mo>+</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>CLCA</mml:mtext><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>SBSN</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E9"><label>(2d)</label><mml:math id="M9" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>logreg</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>tanh</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>cn</mml:mtext><mml:mo>_</mml:mo><mml:mtext>BRDT</mml:mtext><mml:mo>+</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>APOB</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>cn</mml:mtext><mml:mo>_</mml:mo><mml:mtext>ANKRD</mml:mtext><mml:mn>30</mml:mn><mml:mi mathvariant="normal">B</mml:mi><mml:mo>+</mml:mo><mml:mtext>cn</mml:mtext><mml:mo>_</mml:mo><mml:mtext>TNFRSF</mml:mtext><mml:mn>11</mml:mn><mml:mi mathvariant="normal">B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>DPYSL</mml:mtext><mml:mn>5</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E10"><label>(2e)</label><mml:math id="M10" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>logreg</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>FOSB</mml:mtext><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>cn</mml:mtext><mml:mo>_</mml:mo><mml:mtext>ACSM</mml:mtext><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>APOB</mml:mtext><mml:mo>+</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>rs</mml:mtext><mml:mo>_</mml:mo><mml:mtext>TRPV</mml:mtext><mml:mn>6</mml:mn><mml:mo>+</mml:mo><mml:mtext>pp</mml:mtext><mml:mo>_</mml:mo><mml:mtext>FASN</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
        <p>The average train AUC of the models on <xref rid="E6" ref-type="disp-formula">Eqs. 2</xref> is 0.743 (<inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mo>σ</mml:mo><mml:mo>=</mml:mo><mml:mn>0.020</mml:mn></mml:mrow></mml:math></inline-formula>), which is significantly higher than the average train AUC of the two-features models, 0.683 (<inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mo>σ</mml:mo><mml:mo>=</mml:mo><mml:mn>0.043</mml:mn></mml:mrow></mml:math></inline-formula>). Since their mean test AUC scores are on par, the discrepancy in the training set implies that the more complex models depicted above tend to overfit when compared to the simpler gene expression models presented before. When it comes to the functional form of the models on <xref rid="E6" ref-type="disp-formula">Eqs. 2</xref>, it is interesting to note that they all possess a non-linear interaction between gene expression features (prefix <italic toggle="yes">rs</italic>). For most, this interaction is multiplicative, while for the model from Fold 3, the non-linear boundary is set by the <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:mi>tanh</mml:mi><mml:mo>⁡</mml:mo></mml:mrow></mml:math></inline-formula> function of <italic toggle="yes">rs_APOB</italic>.</p>
      </sec>
      <sec>
        <title>Comparison with random forest</title>
        <p>In order to get a better sense of the performance of the QLattice, we compare it with a widely used ‘black-box’ model: the random forest. We use the implementation by <monospace>scikit-learn</monospace>, and tune its hyperparameters and estimate its performance using a ‘nested’ cross-validation scheme (<xref rid="btac405-B9" ref-type="bibr">Cawley and Talbot, 2010</xref>). The best parameters lay around <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="monospace">n</mml:mi><mml:mo>_</mml:mo><mml:mi mathvariant="monospace">estimators</mml:mi><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="monospace">max</mml:mi><mml:mo>_</mml:mo><mml:mi mathvariant="monospace">depth</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> for the different folds, and the average performance is an AUC of 0.604 with standard deviation of 0.106, on par with the QLattice. This is a very remarkable result, considering that the QLattice is only using two features while the random forest uses potentially all of them. A benchmark with other algorithms and feature selection techniques can be found in the <xref rid="sup1" ref-type="supplementary-material">Supplementary material</xref>.</p>
        <p>Taking into consideration how the multi-omics models in <xref rid="E6" ref-type="disp-formula">Eqs 2</xref> tend to overfit and the random forest result in comparison to the QLattice, we can conclude that the models in Eq. (1) reveal the core patterns in the data. In summary, the interaction of two gene expression variables allows for the identification of a ‘hotspot’ where the probability of a poor outcome of the disease is high. One of the genes in the model belongs to a group of genes with pairwise Pearson correlation above 0.7, while the other is taken from the remaining pool of variables. A possible next step in the study of this data is to pinpoint the combinations of gene expression variables that best predict <italic toggle="yes">vital.status</italic>.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>Given the large amounts of data being generated and a need for more efficient treatment regimens, predictive analytics in the clinic is gaining traction. A range of methods exist that can predict a certain outcome based on omics data; however, there is a scarcity of interpretable alternatives. Here, we showed that we can identify simple yet highly predictive and explainable biomarker signatures by combining sophisticated feature selection with a powerful model search algorithm. Due to the small number of features, the models are robust and can be readily interpreted. This makes them a valuable starting point for researchers and clinicians who are looking to find new and biomarker signatures while learning about the underlying interactions in the data.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btac405_Supplementary_Data</label>
      <media xlink:href="btac405_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We would like to acknowledge Casper Wilstrup, Jaan Kasak, Jonas Elsborg and Caroline Linnea Elin Lennartsson for their contributions to the manuscript.</p>
    <sec>
      <title>Author contributions</title>
      <p>V.S.H, M.M., M.T.I., M.S., S.D. and N.J.C. analysed the data and wrote the manuscript. V.S.H. and M.T.I. performed the cross validation of the results. All authors reviewed the manuscript.</p>
      <p><italic toggle="yes">Conflict of Interest</italic>: The authors are employed at Abzu, developers of the QLattice. The QLattice is freely available for non-commercial use.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac405-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Altman</surname><given-names>N.</given-names></string-name>, <string-name><surname>Krzywinski</surname><given-names>M.</given-names></string-name></person-group> (<year>2018</year>) <article-title>The curse(s) of dimensionality</article-title>. <source>Nat. Methods</source>, <volume>15</volume>, <fpage>399</fpage>–<lpage>400</lpage>.<pub-id pub-id-type="pmid">29855577</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B2">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Angrist</surname><given-names>J.D.</given-names></string-name>, <string-name><surname>Pischke</surname><given-names>J.-S.</given-names></string-name></person-group> (<year>2008</year>). <source>Mostly Harmless Econometrics: An Empiricist’s Companion</source>. <publisher-name>Princeton University Press, Princeton, NJ</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btac405-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bader</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Proteome profiling in cerebrospinal fluid reveals novel biomarkers of Alzheimer’s disease</article-title>. <source>Mol. Syst. Biol</source>., <bold>16</bold>, p.e9356.</mixed-citation>
    </ref>
    <ref id="btac405-B4">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bishop</surname><given-names>C.M.</given-names></string-name></person-group> (<year>2006</year>). <source>Pattern Recognition and Machine Learning (Information Science and Statistics)</source>. <publisher-loc>Berlin, Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btac405-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buja</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1989</year>) <article-title>Linear smoothers and additive models</article-title>. <source>Ann. Statist</source>., <volume>17</volume>, <fpage>453</fpage>–<lpage>510</lpage>.</mixed-citation>
    </ref>
    <ref id="btac405-B8">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Burlacu</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>). <source>Operon C++: An Efficient Genetic Programming Framework for Symbolic Regression</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Association for Computing Machinery</publisher-name>, pp. <fpage>1562</fpage>–<lpage>1570</lpage>.</mixed-citation>
    </ref>
    <ref id="btac405-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cawley</surname><given-names>G.C.</given-names></string-name>, <string-name><surname>Talbot</surname><given-names>N.L.C.</given-names></string-name></person-group> (<year>2010</year>) <article-title>On over-fitting in model selection and subsequent selection bias in performance evaluation</article-title>. <source>J. Mach. Learn. Res</source>., <volume>11</volume>, <fpage>2079</fpage>–<lpage>2107</lpage>.</mixed-citation>
    </ref>
    <ref id="btac405-B10">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Chan</surname><given-names>T.E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>). Gene regulatory network inference from single-cell data using multivariate information measures. <italic toggle="yes">Cell Syst</italic>., <bold>5</bold>, 251–267</mixed-citation>
    </ref>
    <ref id="btac405-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Harnessing big ‘omics’ data and AI for drug discovery in hepatocellular carcinoma</article-title>. <source>Nat. Rev. Gastroenterol. Hepatol</source>., <volume>17</volume>, <fpage>238</fpage>–<lpage>251</lpage>.<pub-id pub-id-type="pmid">31900465</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ciriello</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal>; TCGA Research Network. (<year>2015</year>) <article-title>Comprehensive molecular portraits of invasive lobular breast cancer</article-title>. <source>Cell</source>, <volume>163</volume>, <fpage>506</fpage>–<lpage>519</lpage>.<pub-id pub-id-type="pmid">26451490</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B13">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Cover</surname><given-names>T.M.</given-names></string-name>, <string-name><surname>Thomas</surname><given-names>J.A.</given-names></string-name></person-group> (<year>2006</year>). <source>Elements of Information Theory 2nd Edition (Wiley Series in Telecommunications and Signal Processing), New York, NY.</source></mixed-citation>
    </ref>
    <ref id="btac405-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Domingos</surname><given-names>P.</given-names></string-name></person-group> (<year>2012</year>) <article-title>A few useful things to know about machine learning</article-title>. <source>Commun. ACM</source>, <volume>55</volume>, <fpage>78</fpage>–<lpage>87</lpage>.</mixed-citation>
    </ref>
    <ref id="btac405-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ghosh</surname><given-names>D.</given-names></string-name>, <string-name><surname>Poisson</surname><given-names>L.M.</given-names></string-name></person-group> (<year>2009</year>) <article-title>“Omics” data and levels of evidence for biomarker discovery</article-title>. <source>Genomics</source>, <volume>93</volume>, <fpage>13</fpage>–<lpage>16</lpage>.<pub-id pub-id-type="pmid">18723089</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B16">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Hardcastle</surname><given-names>T.</given-names></string-name></person-group> (<year>2010</year>). <italic toggle="yes">bayseq: Empirical Bayesian Analysis of Patterns of Differential Expression in Count Data</italic>. <italic toggle="yes">BMC Bioinformatics</italic>, <bold>11</bold>, 422.</mixed-citation>
    </ref>
    <ref id="btac405-B17">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Hastie</surname><given-names>T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2001</year>). <source>The Elements of Statistical Learning</source>. Springer Series in Statistics. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer New York Inc</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btac405-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hunter</surname><given-names>J.D.</given-names></string-name></person-group> (<year>2007</year>) <article-title>Matplotlib: a 2d graphics environment</article-title>. <source>Comput. Sci. Eng</source>., <volume>9</volume>, <fpage>90</fpage>–<lpage>95</lpage>.</mixed-citation>
    </ref>
    <ref id="btac405-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Katz</surname><given-names>S.J.</given-names></string-name>, <string-name><surname>Morrow</surname><given-names>M.</given-names></string-name></person-group> (<year>2013</year>) <article-title>Addressing overtreatment in breast cancer</article-title>. <source>Cancer</source>, <volume>119</volume>, <fpage>3584</fpage>–<lpage>3588</lpage>.<pub-id pub-id-type="pmid">23913512</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B20">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Koza</surname><given-names>J.R.</given-names></string-name></person-group> (<year>1992</year>). <source>Genetic Programming: On the Programming of Computers by Means of Natural Selection</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btac405-B21">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Larsen</surname><given-names>E.L.</given-names></string-name></person-group> (<year>2021</year>). Analysing and evaluating the QLattice as an evolutionary algorithm in the symbolic regression space. Master’s thesis, DTU Department of Applied Mathematics and Computer Science.</mixed-citation>
    </ref>
    <ref id="btac405-B22">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Leng</surname><given-names>N.</given-names></string-name> et al.</person-group> (<year>2013</year>). <italic toggle="yes">EBSeq: an empirical Bayes hierarchical model for inference in RNA-seq experiments, <italic toggle="yes">Bioinformatics</italic></italic>, <bold>29</bold>, 1035–1043.</mixed-citation>
    </ref>
    <ref id="btac405-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Libbrecht</surname><given-names>M.</given-names></string-name>, <string-name><surname>Noble</surname><given-names>W.</given-names></string-name></person-group> (<year>2015</year>) <article-title>Machine learning applications in genetics and genomics</article-title>. <source>Nat. Rev. Genetics</source>, <volume>16</volume>, <fpage>321</fpage>–<lpage>332</lpage>.<pub-id pub-id-type="pmid">25948244</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Llovet</surname><given-names>J.M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Hepatocellular carcinoma</article-title>. <source>Nat. Rev. Dis. Primers</source>, <volume>7</volume>, <fpage>6</fpage>.<pub-id pub-id-type="pmid">33479224</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Love</surname><given-names>M.I.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Moderated estimation of fold change and dispersion for RNA-seq data with deseq2</article-title>. <source>Genome Biol</source>., <volume>15</volume>, <fpage>550</fpage>.<pub-id pub-id-type="pmid">25516281</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B26">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lundberg</surname><given-names>S.M.</given-names></string-name>, <string-name><surname>Lee</surname><given-names>S.-I.</given-names></string-name></person-group> (<year>2017</year>). <part-title>A unified approach to interpreting model predictions</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Guyon</surname><given-names>I.</given-names></string-name></person-group>  <etal>et al</etal> (eds) <source>Advances in Neural Information Processing Systems</source>, Vol. <volume>30</volume>. <publisher-name>Curran Associates, Inc, Red Hook, NY</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btac405-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mann</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Artificial intelligence for proteomics and biomarker discovery</article-title>. <source>Cell Syst</source>., <volume>12</volume>, <fpage>759</fpage>–<lpage>770</lpage>.<pub-id pub-id-type="pmid">34411543</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mileti</surname><given-names>E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Human white adipose tissue displays selective insulin resistance in the obese state</article-title>. <source>Diabetes</source>, <volume>70</volume>, <fpage>1486</fpage>–<lpage>1497</lpage>.<pub-id pub-id-type="pmid">33863803</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Perkel</surname><given-names>J.M.</given-names></string-name></person-group> (<year>2021</year>) <article-title>Single-cell analysis enters the multiomics age</article-title>. <source>Nature</source>, <volume>595</volume>, <fpage>614</fpage>–<lpage>616</lpage>.</mixed-citation>
    </ref>
    <ref id="btac405-B31">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Podgórski</surname><given-names>K.</given-names></string-name></person-group> (<year>2021</year>). <source>Computational Genomics with R</source>. <publisher-name>Wiley Online Library, New York, NY</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btac405-B32">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Poli</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2008</year>). <italic toggle="yes">A Field Guide to Genetic Programming.</italic> (With contributions by J. R. Koza), Lulu Press, Morrisville, NC.</mixed-citation>
    </ref>
    <ref id="btac405-B0230403">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Radovic</surname>,<given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Minimum redundancy maximum relevance feature selection approach for temporal gene expression data</article-title>. <source>BMC Bioinformatics</source>, <volume>18</volume>. <pub-id pub-id-type="doi">10.1186/s12859-016-1423-9</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ramos</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Multiomic integration of public oncology databases in bioconductor</article-title>. <source>JCO Clin. Cancer Inform</source>., <volume>4</volume>, <fpage>958</fpage>–<lpage>971</lpage>.<pub-id pub-id-type="pmid">33119407</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Robinson</surname><given-names>M.D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2010</year>) <article-title>Edger: a bioconductor package for differential expression analysis of digital gene expression data</article-title>. <source>Bioinformatics</source>, <volume>26</volume>, <fpage>139</fpage>–<lpage>140</lpage>.<pub-id pub-id-type="pmid">19910308</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rudin</surname><given-names>C.</given-names></string-name></person-group> (<year>2019</year>) <article-title>Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead</article-title>. <source>Nat. Mach. Intell</source>., <volume>1</volume>, <fpage>206</fpage>–<lpage>215</lpage>.<pub-id pub-id-type="pmid">35603010</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Smyth</surname><given-names>G.K.</given-names></string-name></person-group> (<year>2004</year>) <article-title>Linear models and empirical Bayes methods for assessing differential expression in microarray experiments</article-title>. <source>Stat. Appl. Genetics Mol. Biol</source>., <volume>3</volume>, <fpage>1</fpage>.</mixed-citation>
    </ref>
    <ref id="btac405-B37">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Udrescu</surname><given-names>S.-M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity. <italic toggle="yes">Advances in Neural Information Processing Systems</italic>, <bold>33</bold>, <fpage>4860</fpage>–<lpage>4871</lpage>.</mixed-citation>
    </ref>
    <ref id="btac405-B38">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>van der Schaar</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2022</year>) Considerations regarding a diagnosis of Alzheimer’s disease before dementia: a systematic review. <italic toggle="yes">Alz Res Therapy</italic>, <bold>14</bold>, 31.</mixed-citation>
    </ref>
    <ref id="btac405-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van Seijen</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal>; on behalf of the PRECISION team. (<year>2019</year>) <article-title>Ductal carcinoma in situ: to treat or not to treat, that is the question</article-title>. <source>Br. J. Cancer</source>, <volume>121</volume>, <fpage>285</fpage>–<lpage>292</lpage>.<pub-id pub-id-type="pmid">31285590</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Virtanen</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal>; SciPy 1.0 Contributors. (<year>2020</year>) <article-title>SciPy 1.0: fundamental algorithms for scientific computing in python</article-title>. <source>Nat. Methods</source>., <volume>17</volume>, <fpage>261</fpage>–<lpage>272</lpage>.<pub-id pub-id-type="pmid">32015543</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walsh</surname><given-names>I.</given-names></string-name></person-group>  <etal>et al</etal>; ELIXIR Machine Learning Focus Group. (<year>2021</year>) <article-title>DOME: recommendations for supervised machine learning validation in biology</article-title>. <source>Nat. Methods</source>, <volume>18</volume>, <fpage>1122</fpage>–<lpage>1127</lpage>.<pub-id pub-id-type="pmid">34316068</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Waskom</surname><given-names>M.L.</given-names></string-name></person-group> (<year>2021</year>) <article-title>Seaborn: statistical data visualization</article-title>. <source>J. Open Source Softw</source>., <volume>6</volume>, <fpage>3021</fpage>.</mixed-citation>
    </ref>
    <ref id="btac405-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wen</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>Genome-scale detection of hypermethylated CPG islands in circulating cell-free DNA of hepatocellular carcinoma patients</article-title>. <source>Cell Res</source>., <volume>25</volume>, <fpage>1376</fpage>.<pub-id pub-id-type="pmid">26620315</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Whalen</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Navigating the pitfalls of applying machine learning in genomics</article-title>. <source>Nat. Rev. Genetics</source>, <volume>23</volume>, <fpage>169</fpage>–<lpage>181</lpage>.<pub-id pub-id-type="pmid">34837041</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>J.D.</given-names></string-name>, <string-name><surname>Roberts</surname><given-names>L.R.</given-names></string-name></person-group> (<year>2010</year>) <article-title>Epidemiology and management of hepatocellular carcinoma</article-title>. <source>Infect. Dis. Clin. North Am</source>., <volume>24</volume>, <fpage>899</fpage>–<lpage>919</lpage>.<pub-id pub-id-type="pmid">20937457</pub-id></mixed-citation>
    </ref>
    <ref id="btac405-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Targeting autophagy in obesity: from pathophysiology to management</article-title>. <source>Nat. Rev. Endocrinol</source>., <volume>14</volume>, <fpage>356</fpage>–<lpage>376</lpage>.<pub-id pub-id-type="pmid">29686432</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
