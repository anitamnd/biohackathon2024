<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PeerJ</journal-id>
    <journal-id journal-id-type="iso-abbrev">PeerJ</journal-id>
    <journal-id journal-id-type="publisher-id">peerj</journal-id>
    <journal-id journal-id-type="pmc">peerj</journal-id>
    <journal-title-group>
      <journal-title>PeerJ</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2167-8359</issn>
    <publisher>
      <publisher-name>PeerJ Inc.</publisher-name>
      <publisher-loc>San Diego, USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7879945</article-id>
    <article-id pub-id-type="publisher-id">10849</article-id>
    <article-id pub-id-type="doi">10.7717/peerj.10849</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Bioinformatics</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Computational Biology</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Translational Medicine</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Data Mining and Machine Learning</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Data Science</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>modelBuildR: an R package for model building and feature selection with erroneous classifications</article-title>
    </title-group>
    <contrib-group>
      <contrib id="author-1" contrib-type="author" corresp="yes">
        <name>
          <surname>Knoll</surname>
          <given-names>Maximilian</given-names>
        </name>
        <email>m.knoll@dkfz.de</email>
        <xref ref-type="aff" rid="aff-1"/>
        <xref ref-type="aff" rid="aff-2"/>
        <xref ref-type="aff" rid="aff-3"/>
      </contrib>
      <contrib id="author-2" contrib-type="author">
        <name>
          <surname>Furkel</surname>
          <given-names>Jennifer</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1"/>
        <xref ref-type="aff" rid="aff-2"/>
        <xref ref-type="aff" rid="aff-3"/>
      </contrib>
      <contrib id="author-3" contrib-type="author">
        <name>
          <surname>Debus</surname>
          <given-names>Juergen</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1"/>
        <xref ref-type="aff" rid="aff-2"/>
        <xref ref-type="aff" rid="aff-3"/>
      </contrib>
      <contrib id="author-4" contrib-type="author">
        <name>
          <surname>Abdollahi</surname>
          <given-names>Amir</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1"/>
        <xref ref-type="aff" rid="aff-2"/>
        <xref ref-type="aff" rid="aff-3"/>
      </contrib>
      <aff id="aff-1"><label>1</label><institution>Department of Radiation Oncology, Heidelberg University Hospital</institution>, <city>Heidelberg</city>, <country>Deutschland</country></aff>
      <aff id="aff-2"><label>2</label><institution>National Center for Tumor Disease (NCT), UKHD and German Cancer Research Center (DKFZ)</institution>, <city> Heidelberg</city>, <country>Germany</country></aff>
      <aff id="aff-3"><label>3</label><institution>German Cancer Consortium (DKTK), Core Center Heidelberg, DKFZ</institution>, <city>Heidelberg</city>, <country>Germany</country></aff>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Wang</surname>
          <given-names>Dapeng</given-names>
        </name>
      </contrib>
    </contrib-group>
    <pub-date pub-type="epub" date-type="pub" iso-8601-date="2021-02-09">
      <day>9</day>
      <month>2</month>
      <year iso-8601-date="2021">2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>9</volume>
    <elocation-id>e10849</elocation-id>
    <history>
      <date date-type="received" iso-8601-date="2020-07-31">
        <day>31</day>
        <month>7</month>
        <year iso-8601-date="2020">2020</year>
      </date>
      <date date-type="accepted" iso-8601-date="2021-01-06">
        <day>6</day>
        <month>1</month>
        <year iso-8601-date="2021">2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>©2021 Knoll et al.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Knoll et al.</copyright-holder>
      <license xlink:href="https://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, reproduction and adaptation in any medium and for any purpose provided that it is properly attributed. For attribution, the original author(s), title, publication source (PeerJ) and either DOI or URL of the article must be cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="https://peerj.com/articles/10849"/>
    <abstract>
      <sec>
        <title>Background</title>
        <p>Model building is a crucial part of omics based biomedical research to transfer classifications and obtain insights into underlying mechanisms. Feature selection is often based on minimizing error between model predictions and given classification (maximizing accuracy). Human ratings/classifications, however, might be error prone, with discordance rates between experts of 5–15%. We therefore evaluate if a feature pre-filtering step might improve identification of features associated with true underlying groups.</p>
      </sec>
      <sec>
        <title>Methods</title>
        <p>Data was simulated for up to 100 samples and up to 10,000 features, 10% of which were associated with the ground truth comprising 2–10 normally distributed populations. Binary and semi-quantitative ratings with varying error probabilities were used as classification. For feature preselection standard cross-validation (V2) was compared to a novel heuristic (V1) applying univariate testing, multiplicity adjustment and cross-validation on switched dependent (classification) and independent (features) variables. Preselected features were used to train logistic regression/linear models (backward selection, AIC). Predictions were compared against the ground truth (ROC, multiclass-ROC). As use case, multiple feature selection/classification methods were benchmarked against the novel heuristic to identify prognostically different G-CIMP negative glioblastoma tumors from the TCGA-GBM 450 k methylation array data cohort, starting from a fuzzy umap based rough and erroneous separation.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>V1 yielded higher median AUC ranks for two true groups (ground truth), with smaller differences for true graduated differences (3–10 groups). Lower fractions of models were successfully fit with V1. Median AUCs for binary classification and two true groups were 0.91 (range: 0.54–1.00) for V1 (Benjamini-Hochberg) and 0.70 (0.28–1.00) for V2, 13% (<italic>n</italic> = 616) of V2 models showed AUCs &lt; = 50% for 25 samples and 100 features. For larger numbers of features and samples, median AUCs were 0.75 (range 0.59–1.00) for V1 and 0.54 (range 0.32–0.75) for V2. In the TCGA-GBM data, modelBuildR allowed best prognostic separation of patients with highest median overall survival difference (7.51 months) followed a difference of 6.04 months for a random forest based method.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p>The proposed heuristic is beneficial for the retrieval of features associated with two true groups classified with errors. We provide the R package modelBuildR to simplify (comparative) evaluation/application of the proposed heuristic (<ext-link ext-link-type="uri" xlink:href="http://github.com/mknoll/modelBuildR">http://github.com/mknoll/modelBuildR</ext-link>).</p>
      </sec>
    </abstract>
    <kwd-group kwd-group-type="author">
      <kwd>Feature selection</kwd>
      <kwd>Misclassification</kwd>
      <kwd>Model building</kwd>
      <kwd>Ground truth</kwd>
      <kwd>High dimensional data</kwd>
      <kwd>Glioblastoma multiforme</kwd>
      <kwd>Prognosis</kwd>
      <kwd>Long term/short term survivor</kwd>
      <kwd>Illumina humanmethylation array data</kwd>
      <kwd>G-CIMP negative GBM</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="fund-1">
        <funding-source>National Center for Tumor diseases</funding-source>
        <award-id>NCT PRO-2015.21</award-id>
      </award-group>
      <award-group id="fund-2">
        <funding-source>Deutsche Forschungsgemeinschaft</funding-source>
        <award-id>UNITE SFB13-89</award-id>
      </award-group>
      <award-group id="fund-3">
        <funding-source>German Cancer Research Center</funding-source>
        <award-id>iMED</award-id>
      </award-group>
      <award-group id="fund-4">
        <funding-source>Heidelberg Medical Faculty of Heidelberg University within the scope of the MD/PhD program</funding-source>
      </award-group>
      <funding-statement>This work was supported by the National Center for Tumor diseases (NCT PRO-2015.21), Deutsche Forschungsgemeinschaft (UNITE SFB13-89) and the German Cancer Research Center (iMED). Maximilian Knoll and Jennifer Furkel received financial support from the Heidelberg Medical Faculty of Heidelberg University within the scope of the MD/PhD program. There was no additional external funding received for this study. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
  </article-meta>
</front>
<body>
  <sec sec-type="intro">
    <title>Introduction</title>
    <p>Model training is an important task in biomedical research for the evaluation of omics data, e.g., for classification tasks. The features included in the model and used for classification might hint towards underlying (biological) processes or mechanisms.</p>
    <p>Such classifications in biomedical research are often encoded by a human rater as binary, e.g., a given immune-histochemistry staining can be classified as positive/negative (1/0), or as semi-quantitative score (e.g., 0–5) for graduated evaluation (<xref rid="ref-2" ref-type="bibr">Balermpas et al., 2017</xref>; <xref rid="ref-13" ref-type="bibr">Knoll et al., 2016</xref>). Often, associated changes on molecular level are of interest, measured e.g., by analysis of expression or methylation data with arrays/sequencing yielding a high number of features.</p>
    <p>Binary outcome data can be modeled using a logistic regression, a generalized linear model (GLM) with logit link function (<xref rid="ref-9" ref-type="bibr">Hastie &amp; Tibshirani, 1986</xref>; <xref rid="ref-18" ref-type="bibr">McCullagh &amp; Nelder, 1989</xref>). Semi-quantitative data might be evaluated using linear models.</p>
    <p>For model training, a full evaluation of all feature combinations is usually not feasible (high number of features), and standard GLMs cannot be trained for numbers of features &gt;numbers of observations, requiring the usage of heuristics for pre-filtering of features. A set of remaining features can then be used to train a model, e.g., using backward selection in combination with an information criterion (<xref rid="ref-1" ref-type="bibr">Akaike, 1973</xref>).</p>
    <p>Model fits are usually evaluated for their ability to predict the observed data (“goodness-of-fit”). The latter might, however, contain erroneous assignments, arising e.g., from multiple sources (technical difficulties, sampling or human error). Thus, forcing the model to fit the observed rather than the true underlying groups might lead to the selection of inappropriate features.</p>
    <p>We therefore propose to use a heuristic for feature pre-filtering prior to model building which reverses the role of dependent (classification)/independent (features) variables, perform tests for difference and cross validate data with reverted roles of dependent/independent variables, and use only retained features for subsequent model building.</p>
    <p>Its performance is compared to a standard cross validation approach (non-reverted roles of variables) in simulated data. Binary and semi-quantitative encodings (with added errors) in features sampled from two or more populations are evaluated, and the ability of both approaches to select meaningful features (high overlap with known ground truth).</p>
    <p>We provide an R package to simplify (comparative) analyses with the proposed heuristic, available on github (<ext-link ext-link-type="uri" xlink:href="http://github.com/mknoll/modelBuildR">http://github.com/mknoll/modelBuildR</ext-link>).</p>
  </sec>
  <sec sec-type="methods">
    <title>Methods</title>
    <sec>
      <title>Feature selection methods</title>
      <p>The two evaluated feature selection methods are outlined in <xref ref-type="fig" rid="fig-1">Figs. 1B</xref> and <xref ref-type="fig" rid="fig-2">2</xref>. Variant 2 (V2) uses cross validation to obtain an order on single features (univariate test), using the (erroneous) classification as dependent variable. For binary outcomes, cv.binary() from the DAAG package (<xref rid="ref-17" ref-type="bibr">Maindonald &amp; Braun, 2020</xref>) and for semi-quantitative outcomes, cv.lm() was used (default parameters, <xref ref-type="fig" rid="fig-3">Fig. 3</xref>). The first n features with lowest cross-validation errors or highest accuracy were selected for model selection, with <italic>n</italic> being the number of evaluated samples (here: 50). Further processing was similar between both evaluated methods. Variant 1 inverts the role of dependent (classification)/independent (features) variables for the initial feature filtering step. First, a significant influence of the observed classification on each measured feature is tested using a linear model and calculating model <italic>p</italic>-values (null- vs full models, likelihood ratio test, LRT). <italic>P</italic>-values are then adjusted for multiplicity, Benjamini–Hochberg and Bonferroni adjustment was evaluated, all features with adjusted <italic>p</italic>-values below 0.05 (<italic>p</italic>∗ = 0.05, <xref ref-type="fig" rid="fig-1">Fig. 1B</xref>) were retained. Next, a cross validation step was performed, keeping the inverted roles of independent/dependent variables. Finally, the first n features with lowest cross-validation errors were used for further analysis, with n being the minimum of the number of remaining features and numbers of samples. For the next step, which is similar to variant 2, the original roles of the dependent and independent variables were assumed (classification: dependent variable). Model building was performed by backward model selection using AIC, with a logistic regression for binary outcomes and a linear model for semi-quantitative classification. Predictions were then compared to known underlying group truth by calculation AUCs with pROC::roc() (<xref rid="ref-21" ref-type="bibr">Robin et al., 2011</xref>) for binary and pROC::multiclass.roc() for semi-quantitative classifications (<xref ref-type="fig" rid="fig-2">Fig. 2</xref>). AUCs and AUC ranks (tie methods: average, random) were evaluated.</p>
      <fig id="fig-1" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.10849/fig-1</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Model building for a given classification using high dimensional data.</title>
          <p>(A) Major steps in model building and outline of the subsequently addressed issue of potential erroneous classification. (B) Comparatively evaluated strategies for feature pre-filtering/ordering of features prior to model building and outline of how model performance is evaluated.</p>
        </caption>
        <graphic xlink:href="peerj-09-10849-g001"/>
      </fig>
      <fig id="fig-2" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.10849/fig-2</object-id>
        <label>Figure 2</label>
        <caption>
          <title>Simulated data for binary (A) and semi-quantitative classification (B) and the introduction of errors used for evaluation of feature selection/model building approaches.</title>
          <p>Observed classification was sampled from a binomial distribution for varying probabilities per group, for semi-quantitative data, equidistance between classes was assumed, and errors were added based on data sampled from binomial distributions.</p>
        </caption>
        <graphic xlink:href="peerj-09-10849-g002"/>
      </fig>
      <fig id="fig-3" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.10849/fig-3</object-id>
        <label>Figure 3</label>
        <caption>
          <title>Overview of the functions implemented in the modelBuildR package and required parameters.</title>
          <p>(A) Instantiation of a fitModel object for analysis. (B) Prefiltering of features. (C) Cross-validation approaches. (D) Final model fitting.</p>
        </caption>
        <graphic xlink:href="peerj-09-10849-g003"/>
      </fig>
    </sec>
    <sec>
      <title>Evaluated data</title>
      <p>An overview of simulated data gives <xref ref-type="fig" rid="fig-2">Fig. 2</xref>. Two common cases were tested, a binary classification and a semi-quantitative graduated classification together with high-dimensional data. To keep calculation time reasonable, a total number of 100 features was evaluated in 50 samples. Only a fraction of features (∼10%, sampled with runif()) were assumed to show differences between groups. For two group analyses, they were sampled from two normal distributions with varying differences in means and standard deviations. For more than two classes, differences between means of subsequent classes/distributions were constant, as were their standard deviations. Group sizes were balanced, if this was not possible, the sample number of the highest ranked group was expanded. To assure reproducibility, a fixed seed was used. Errors on the classifications were introduced as follows: for a binary classification, the respective group assignment was retrieved from a binomial distribution yielding 0,1 with probabilities prob1 and prob2. For larger numbers of classes, a vector of 0,1 values was obtained similarly for a probability prob1, and was subtracted from the true classification. Absolute values were used as erroneous classification. Reproducible code and analyses are available as CodeOcean capsule: <ext-link ext-link-type="uri" xlink:href="https://codeocean.com/capsule/3333162/tree/v1">https://codeocean.com/capsule/3333162/tree/v1</ext-link>.</p>
    </sec>
    <sec>
      <title>modelBuildR package</title>
      <p>The presented analyses were performed with the modelBuildR package. An overview of its functionality is shown in <xref ref-type="fig" rid="fig-3">Fig. 3</xref>, additional functionality is outlined in the package vignette.</p>
      <p>The constructor for a new fitModel instance requires a feature data.frame data with features in rows and samples in colums, a metadata data.frame meta with samples in rows and covariates in columns, specification of the classification (dependent) variable var and the type of model to train (type, lr for logistic regression and lm for linear model). The evaluation of an association of the classification variable on feature measurements is performed with testSign(), expecting a multiplicity adjustment parameter (pAdj, all allowed methods from stats::p.adjust()) and a <italic>p</italic>-value cutoff (pCut). Different cross-validation methods are implemented, cv() performs the cross validation on inverted roles of dependent/independent variables as described above (<xref ref-type="fig" rid="fig-1">Figs. 1B</xref> and <xref ref-type="fig" rid="fig-2">2</xref>). cvB() and cvL() perform cross-validation on non-inverted roles of variables. fitM() finally performs the model training using R’s stats::step() function with default parameters (using AIC or BIC) or using a cross-validation approach (see <xref ref-type="supplementary-material" rid="supplemental-information">Suppl. Methods</xref> for details).</p>
      <p>In addition to previously outlined analyses, the feature preselection step can also be performed while including additional covariates (both for the model evaluation and cross validation step, refer to the package vignette for details: vignette(“modelBuildR”)).</p>
    </sec>
    <sec>
      <title>Omics data and alternative feature selection methods</title>
      <p>450k Illumina human methylation array data and clinical information of the TCGA-GBM cohort was retrieved through the GDC data portal on 2019-11-07. Logit transformed methylation data was used for analysis if not stated otherwise (<italic>M</italic> values). G-CIMP classification was performed as follows: <italic>L</italic> = 282.7+114.2*cg06903384, <italic>p</italic> = exp (<italic>L</italic>)/(1 + exp (<italic>L</italic>)). Samples with <italic>p</italic> &lt; 0.5 were classified as CIMP- and CIMP+ otherwise. The glmnet package (<xref rid="ref-8" ref-type="bibr">Friedman, Hastie &amp; Tibshirani, 2010</xref>) was used for lasso regression, utilizing cross validation to select an appropriate lambda value, and randomForest (<xref rid="ref-16" ref-type="bibr">Liaw &amp; Wiener, 2002</xref>) for random forest analysis. Student’s <italic>t</italic>-tests were used. Optimal cutoffs of prognostic separation (minimal <italic>p</italic>-value) were calculated with dataAnalysisMisc::findOptCutoff() (<xref rid="ref-6" ref-type="bibr">dataAnalysisMisc, 2020</xref>). The pvclust package (<xref rid="ref-20" ref-type="bibr">pvclust, 2019</xref>) was used for consensus clustering, the umap R package in combination with umap-learn for dimensionality reduction (<xref rid="ref-14" ref-type="bibr">Konopka, 2020</xref>; <xref rid="ref-19" ref-type="bibr">McInnes &amp; Healy, 2018</xref>). Significance level alpha was fixed at 0.05 (two-sided).</p>
    </sec>
  </sec>
  <sec sec-type="results">
    <title>Results</title>
    <sec>
      <title>Semi-quantitative classification and true graduated differences in underlying data</title>
      <p>Model fitting (&gt;0 as significantly different identified features, <italic>pAdj</italic> &lt; 0.05, Benjamini–Hochberg adjustment) was successful more frequently when using V2. V1 showed lower fractions for fewer categories (successful model fits, reference V2: median: 88%, range: 70–97%, <xref ref-type="fig" rid="fig-4">Fig. 4A</xref>). Observed median AUCs were similar between V1 and V2 (<xref ref-type="fig" rid="fig-4">Fig. 4B</xref>) and did not differ between <italic>p</italic>-value adjustment methods (V1, <xref ref-type="fig" rid="fig-4">Fig. 4B</xref>). AUCs stratified by numbers of true underlying groups and mean difference for BH and Bonferroni adjustments are shown in <xref ref-type="supplementary-material" rid="supp-2">Figs. S2</xref> + <xref ref-type="supplementary-material" rid="supp-3">S3</xref>. Differences between V1/V2 of observed AUCs decreased for increasing numbers of categories, single outliers were observed mostly for V1. Higher uncertainty in classification (prob1 0.3/0.6) showed lower AUCs especially for fewer groups (<xref ref-type="supplementary-material" rid="supp-2">Figs. S2</xref> + <xref ref-type="supplementary-material" rid="supp-3">S3</xref>). Larger standard deviations with smaller mean differences decreased AUCs for V1, more prominent for Bonferroni than for Benjamini–Hochberg adjustment (<xref ref-type="supplementary-material" rid="supp-2">Figs. S2</xref> + <xref ref-type="supplementary-material" rid="supp-3">S3</xref>). Median model fitting time requirements were lower for V1 (<xref ref-type="supplementary-material" rid="supp-1">Fig. S1</xref>).</p>
      <fig id="fig-4" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.10849/fig-4</object-id>
        <label>Figure 4</label>
        <caption>
          <title>Comparison of feature preselection methods for semi-quantitative classification with true underlying equidistant differences between groups.</title>
          <p>(A) Number of successfully trained models (V1, Benjamini-Hochberg multiplicity adjustment). (B) AUCs of model predictions tested against ground truths for varying classification errors and different multiplicity adjustment methods. AUCs (C–D) and AUC ranks (E–F) of V1 and V2, rank-ties methods: avg, average, rnd, random.</p>
        </caption>
        <graphic xlink:href="peerj-09-10849-g004"/>
      </fig>
    </sec>
    <sec>
      <title>Binary classification and two true underlying groups</title>
      <p>The number of successful model fits ranged between 139 and 144 for V2 and 0 and 144 for V1 (Benjamini–Hochberg adjustment, <xref ref-type="fig" rid="fig-5">Fig. 5A</xref>). Processing times were lower for V1 (&lt;5 vs &gt;20 s, <xref ref-type="fig" rid="fig-5">Fig. 5B</xref>, <xref ref-type="supplementary-material" rid="supp-1">Fig. S1</xref>). Minimum observed AUCs were &gt;0.5 for all combinations evaluated with V1, 13% of models lead to an AUC &lt; = 0.5 for V2 (<xref ref-type="supplementary-material" rid="supp-5">Fig. S5</xref>). Separate analysis for combinations of prob1/prob2 showed that 0.1/0.1; 0.3/0.1; 0.1/0.3; 0.3/0.3; 0.6/06; 0.6/0.9; 0.9/0.9 did not yield any models for V1 (<xref ref-type="fig" rid="fig-5">Fig. 5A</xref>), V2 identified models with low AUCs in these cases (<xref ref-type="supplementary-material" rid="supp-4">Figs. S4</xref> + <xref ref-type="supplementary-material" rid="supp-5">S5</xref>). No general difference in AUCs between Bonferroni and Benjamini–Hochberg adjustment could be detected when separating results by probability (<xref ref-type="supplementary-material" rid="supp-4">Figs. S4</xref> + <xref ref-type="supplementary-material" rid="supp-5">S5</xref>). Increasing mean differences allowed model fitting for larger standard deviations with V1, with higher median AUCs for Bonferroni adjustment for most evaluated combinations (<xref ref-type="supplementary-material" rid="supp-4">Figs. S4</xref> + <xref ref-type="supplementary-material" rid="supp-5">S5</xref>, <xref ref-type="fig" rid="fig-5">Fig. 5C</xref>). Higher median AUC ranks were observed for V1 (<xref ref-type="fig" rid="fig-5">Fig. 5D</xref>), as well as higher median AUCs (<xref ref-type="fig" rid="fig-5">Fig. 5C</xref>).</p>
      <fig id="fig-5" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.10849/fig-5</object-id>
        <label>Figure 5</label>
        <caption>
          <title>Comparison of feature preselection methods for binary outcomes with underlying true dichotomous groups.</title>
          <p>(A–D) Number of successfully trained models (Benjamini-Hochberg multiplicity adjustment). (E–H) Time requirements for model fitting. (I, J, K) AUCs of model predictions tested against ground truths for varying classification probabilities. (L–M) AUC ranks for V1 and V2, rank-ties methods: avg, average, rnd, random.</p>
        </caption>
        <graphic xlink:href="peerj-09-10849-g005"/>
      </fig>
      <p>Performance of both approaches were additionally tested for larger numbers of features (up to 10,000) and higher number of samples per group (same size, up to 100) and with probabilities 0.1 and 0.3 with Bonferroni <italic>p</italic>-value adjustment. Results are shown in <xref ref-type="supplementary-material" rid="supp-7">Fig. S7</xref>. For <italic>n</italic> = 25 samples per group, no models could be fitted with V1. Both AUCs and AUC ranks were higher for V1, up to AUCs of 1 where the corresponding models from V2 reached AUCs not above 0.8. Minimum observed AUCs for V1 were 0.6. V2 did not show a clear influence of distribution parameters from which the data was sampled on AUCs as opposed to V1. In summary, V1 outperforms V2 also in larger datasets.</p>
    </sec>
    <sec>
      <title>Semi-quantitative classification and two true underlying groups</title>
      <p>An intermediate between the two previously analyzed conditions was evaluated next. Classification was allowed to be graduated (semi-quantitative), but the underlying grouping was assumed to be dichotomous. V1 lead to model fits of median 35% (range: 16–48%, Benjamini–Hochberg <italic>p</italic>-value adjustment) of successful model fits using V2 (<xref ref-type="fig" rid="fig-6">Fig. 6A</xref>). Processing time was lower for V1 (<xref ref-type="supplementary-material" rid="supp-1">Fig. S1</xref>). V1 yielded higher AUC ranks as compared to V2 (<xref ref-type="fig" rid="fig-6">Fig. 6B</xref>). Minimum observed AUCs were 0.64 for V1 and 0.44 for V2. V2 yielded 5 models with AUCs &lt; = 0.5. Stratification by numbers of categories showed higher median AUC ranks for V1 and increasing median ranks for V2 (<xref ref-type="fig" rid="fig-6">Fig. 6C</xref>), as well as increases in AUCs for &gt; = 4 categories for V2 (<xref ref-type="fig" rid="fig-6">Fig. 6C</xref>). Stratification of AUCs by error probability (prob1) and number of categories showed decreases of AUCs for increasing error probabilities especially for V2 (<xref ref-type="supplementary-material" rid="supp-6">Fig. S6</xref>). Dependency of AUCs on numbers of categories, mean difference and standard deviations between the two underlying groups showed higher AUCs for lower standard deviations especially for 4 groups for V1 (<xref ref-type="supplementary-material" rid="supp-6">Fig. S6</xref>).</p>
      <fig id="fig-6" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.10849/fig-6</object-id>
        <label>Figure 6</label>
        <caption>
          <title>Comparison of feature preselection methods for semi-quantitative equidistant classification with true dichotomous underlying groups.</title>
          <p>(A) Number of successfully trained models (Benjamini-Hochberg multiplicity adjustment). AUCs (B–C) and AUC ranks (F–G) ranks of V1 and V2, rank-ties methods: avg, average, rnd, random. (D) AUCs and ranks (E) split by numbers of semi quantitative categories.</p>
        </caption>
        <graphic xlink:href="peerj-09-10849-g006"/>
      </fig>
    </sec>
    <sec>
      <title>Use case: methylation based identification of prognostically different CIMP-glioblastomas</title>
      <p>To comparatively evaluate the proposed heuristic, we assessed a number of methods for their ability to identify/retrieve two assumedly true groups of prognostically different G-CIMP- GBM tumors present in the TCGA-GBM 450k methylation array data cohort (<xref ref-type="fig" rid="fig-7">Fig. 7</xref>). Two prognostically different groups (long-term survivors, LTS and short-term survivors, STS) were defined as outlined in <xref ref-type="supplementary-material" rid="supp-7">Fig. S7</xref> and <xref ref-type="supplementary-material" rid="supplemental-information">Suppl. Methods</xref>. An umap representation was calculated from methylation array data, distribution of LTS/STS samples is shown in <xref ref-type="fig" rid="fig-7">Fig. 7A</xref>. LTS tumors are rather located in the lower right part, STS tumor in the upper part of the graph. Data-driven separation of samples, based on the umap representation, was performed manually with a straight line (<xref ref-type="fig" rid="fig-7">Fig. 7B</xref>). The resulting grouping of samples (above, below the line, grp1 and grp2) was used to train a random forest classifier, a lasso regression and a logistic regression with the proposed heuristic. For the random forest classifier, an additional analysis was performed by selecting the highest ranked CpG probes (importance, mean decrease Gini, <xref ref-type="fig" rid="fig-7">Fig. 7E</xref>, 2nd to 4th column) for subsequent hierarchical cluster analysis. Additional methods for feature selection are shown in <xref ref-type="fig" rid="fig-7">Figs. 7F</xref>–<xref ref-type="fig" rid="fig-7">7H</xref>. Predictions from the random forest classifier, two main clusters for approaches involving hierarchical [consensus] clustering and optimal prognostic separation of continuous values (predictions from lasso and the novel heuristic, minimum <italic>p</italic>-values) were compared w.r.t. their ability for prognostic separation (<xref ref-type="fig" rid="fig-7">Figs. 7D</xref>–<xref ref-type="fig" rid="fig-7">7H</xref> and <xref rid="table-1" ref-type="table">Table 1</xref>). Best separation was achieved with the novel heuristic (median survival difference of 7.51 months), followed by random forest classifier with hierarchical cluster analysis of most important CpGs (6.04 months). Selection of BIC, AIC or CV approach in fitM() yielded the same model (<xref ref-type="supplementary-material" rid="supp-9">Table S1</xref>).</p>
      <fig id="fig-7" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.10849/fig-7</object-id>
        <label>Figure 7</label>
        <caption>
          <title>Comparative evaluation of the novel proposed heuristic to identify prognostically different G-CIMP-tumors from methylation array data.</title>
          <p>(A) Evaluated data. (B) Umap representation of M-values with LTS/STS classification (see <xref ref-type="supplementary-material" rid="supp-7">Fig. S7</xref> and <xref ref-type="supplementary-material" rid="supplemental-information">Suppl.-Methods</xref>) and corresponding survival curves (C). Manual separation of prognostically different tumors, umap (D) and survival curves (E). (F) Evaluated approaches to detect groups of prognostically different tumors. hcl: hierarchical cluster analysis. (G–I) modelBuildR heuristic, (G) color-coded model scores in umap representation of methylation data and separated by prognostic group (high/low, see H). (H) Survival curves correspond to best achievable separation (minimal <italic>p</italic>-value, vertical line, I). Random forest predictions (J), random forest derived ranking of CpG probes (K, importance, mean decrease Gini), hierarchical cluster analysis of selected probes (L, blue, ward.D2, Euclidean distance), survival curves of two main clusters (M). (F) Hierarchical cluster analysis (ward.D2, Euclidean distance) of 1% of most variant probes (median absolute deviation) and corresponding survival curves of two main clusters (O). (P) Survival curves for lasso regression model predictions, analogously to I. (Q) Volcano plot of differentially regulated probes (<italic>t</italic>-test, Bonferroni adjustment), selected probes were used for consensus clustering (R, hcl, ward.D2, Euclidean), prognostic separation of two main clusters (S). Kaplan-Meier survival curves, likelihood ratio test p-values (Cox-PH models).</p>
        </caption>
        <graphic xlink:href="peerj-09-10849-g007"/>
      </fig>
    </sec>
  </sec>
  <sec sec-type="discussion">
    <title>Discussion</title>
    <p>Omics-data, e.g., expression or methylation data is often used to gain insights the underlying biology (<xref rid="ref-4" ref-type="bibr">Capper et al., 2018</xref>). In translational research, molecular data from patients is often compared against a given binary classification (e.g., tumor subtype A vs B) or a graduated semi-quantitative rating, e.g., of an immune-histochemical straining of intensity classes 1 to 5 (<xref rid="ref-2" ref-type="bibr">Balermpas et al., 2017</xref>; <xref rid="ref-13" ref-type="bibr">Knoll et al., 2016</xref>). However, prospectively measured inter-rater agreement for classification of grade and histotype of ovarian cancer by specialists (pathologists) has been reported with only 85–95% (<xref rid="ref-3" ref-type="bibr">Barnard et al., 2018</xref>). Thus, a fraction of misclassifications of 5–15% might be considered a conservative estimation even for trained raters.</p>
    <table-wrap id="table-1" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.7717/peerj.10849/table-1</object-id>
      <label>Table 1</label>
      <caption>
        <title>Comparison of different methods for prognostic separation of G-CIMP negative glioblastoma tumors based on methylation array data.</title>
      </caption>
      <alternatives>
        <graphic xlink:href="peerj-09-10849-g008"/>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col span="1"/>
            <col span="1"/>
            <col span="1"/>
            <col span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Method</th>
              <th rowspan="1" colspan="1">Median survival difference [months]</th>
              <th rowspan="1" colspan="1">HR, 95% CI</th>
              <th rowspan="1" colspan="1"><italic>p</italic>-value</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Random Forest</td>
              <td rowspan="1" colspan="1">3.2</td>
              <td rowspan="1" colspan="1">1.3 [0.86–2.03]</td>
              <td rowspan="1" colspan="1">0.2</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Random Forest + hcl</td>
              <td rowspan="1" colspan="1">6.04</td>
              <td rowspan="1" colspan="1">0.5 [0.41–0.96]</td>
              <td rowspan="1" colspan="1">0.03</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Most variant + hcl</td>
              <td rowspan="1" colspan="1">4.5</td>
              <td rowspan="1" colspan="1">0.8 [0.54–1.30]</td>
              <td rowspan="1" colspan="1">0.4</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"><italic>t</italic>-test + hcl*</td>
              <td rowspan="1" colspan="1">3.0</td>
              <td rowspan="1" colspan="1">0.6 [0.39–0.98]</td>
              <td rowspan="1" colspan="1">0.04</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Lasso</td>
              <td rowspan="1" colspan="1">3.7</td>
              <td rowspan="1" colspan="1">0.6 [0.42–0.99]</td>
              <td rowspan="1" colspan="1">0.04</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">modelBuildR</td>
              <td rowspan="1" colspan="1">7.51</td>
              <td rowspan="1" colspan="1">0.5 [0.33–0.81]</td>
              <td rowspan="1" colspan="1">0.004</td>
            </tr>
          </tbody>
        </table>
      </alternatives>
      <table-wrap-foot>
        <fn id="table-1fn">
          <p>
            <bold>Notes.</bold>
          </p>
        </fn>
        <fn id="table-1fn1" fn-type="other">
          <p>
            <def-list id="dl1">
              <def-item>
                <term> Hcl</term>
                <def>
                  <p>hierarchical cluster analysis</p>
                </def>
              </def-item>
              <def-item>
                <term> *</term>
                <def>
                  <p>consensus clustering</p>
                </def>
              </def-item>
              <def-item>
                <term> HR</term>
                <def>
                  <p>hazard ratio, Cox-PH models</p>
                </def>
              </def-item>
            </def-list>
          </p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <p>Model training for classification might hint towards underlying biological mechanisms as the model training step is assumed to select features which robustly allow to infer groups. Evaluation of all possible combinations of features for model training is not feasible for typical datasets and for standard modelling approaches also often not possible (numbers of features &gt; &gt; numbers of samples), ridge regression and lasso (<xref rid="ref-22" ref-type="bibr">Santosa &amp; Symes, 1986</xref>; <xref rid="ref-23" ref-type="bibr">Tibshirani, 1996</xref>) allow to deal with such data. Alternatively, features can be pre filtered with a wide variety of methods (<xref rid="ref-15" ref-type="bibr">Lazar et al., 2012</xref>). Binary outcomes can be modeled with logistic regressions and graduated, equidistant classifications with linear models. For a discussion of currently applied methods for the analysis of real-world clinical data—starting from simple ROC based analyses to complex models and feature selection approaches—see <xref rid="ref-5" ref-type="bibr">Chen et al. (2019)</xref> and <xref rid="ref-7" ref-type="bibr">Deo (2015)</xref>. Even though deep-learning models might show extraordinary high performance for specific tasks in biomedical research, their application if often limited by sparsity of data or low quality (<xref rid="ref-5" ref-type="bibr">Chen et al., 2019</xref>) and might be vulnerable to small adversarial perturbations (<xref rid="ref-24" ref-type="bibr">Yuan et al., 2019</xref>). Therefore, novel methods are needed with specifically enable analysis using poorer quality data. Furthermore, highly complex and powerful deep-learning methods lack transparency (<xref rid="ref-10" ref-type="bibr">Holzinger et al., 2019</xref>), but explainability and interpretability often is a crucial point needed to gain a more mechanistic understanding of underlying processes.</p>
    <p>Methods often aim to explain the observed data (classification) as good as possible, e.g., by using goodness of fit tests or sufficient differences in information criteria, while addressing overfitting e.g., by incorporating cross-validation. However, selection of features is still based on (probable) erroneous classification.</p>
    <p>We aimed to evaluate if a heuristic which inverts the roles of dependent (classification) and independent (features) variables in a pre-filtering step might help to retrieve features associated with the true underlying structure/grouping (testing for significant differences, cross validation). Therefore, we simulated data for two or more distinct classes, added an error on the classification and tried to retrieve the original classification as quantified by (multiclass) ROC analyses.</p>
    <p>Evaluation of true different populations encoded semi-quantitatively showed no global preference for V1 or V2 except for lower time requirements for V1. AUC ranks were still higher for V1, thus making V1 a reasonable analysis approach. The presence of only small differences between populations, however, might impair performance in this setting.</p>
    <p>The presence of two true groups can be encoded binary by a (human) rater or, e.g., for immune histochemical stainings, graduated even though only two groups are present. Both combinations were evaluated, showing a clear overall benefit of the proposed heuristic for binary encodings. This was not only true for systematic analyses with few numbers of features (<italic>n</italic> = 100) and 25 samples per group, but also for larger datasets with up to 10,000 features and 100 samples per group. For semi-quantitative encodings, a better performance was seen for lower numbers of semi-quantitative categories. Thus the heuristic can be recommended for binary classified data, and if only few categories (∼4) are used for classification if a binary ground truth might be present. Due to large time requirements, only the combination yielding a clear benefit (two groups, binary classification), was tested with larger numbers of features and samples.</p>
    <p>The proposed heuristic for feature pre-filtering leads to a number of combinations where no model could be fit. These combinations, however, would have led to models with low AUCs (compared to the ground truth) using the cross validation only feature selection strategy (V2). More liberal <italic>p</italic>-value adjustment strategies were not always beneficial, thus performance of different multiplicity adjustment procedures with varying <italic>p</italic>-value cutoffs while considering their respective power should be evaluated in future work. Lower time-requirements of the heuristic might prove useful especially for larger datasets.</p>
    <p>We utilized the TCGA-GBM 450k methylation array data cohort of G-CIMP negative tumors to demonstrate the ability of the proposed heuristic to retrieve features able to separate probable true different underlying groups of tumors. Direct comparison with additional methods, even for only a small number of approaches, showed a superior performance of the novel heuristic. Without interpreting too much into the potential biological meaning (no independent validation), it is worth noting that methylation array data is used to detect and classify separate subgroups of glioma and G-CIMP- glioblastoma, which also show differences in prognosis (<xref rid="ref-4" ref-type="bibr">Capper et al., 2018</xref>; <xref rid="ref-12" ref-type="bibr">Knoll et al., 2019</xref>; <xref rid="ref-11" ref-type="bibr">Hwang et al., 2019</xref>).</p>
    <p>In summary, the proposed heuristic proved most beneficial for the identification of two groups encoded in two or few categories. Identified features were then more probable to represent true associated characteristics. However, future work is needed to validate these findings in more complex/real-world data with e.g., unbalanced groups, larger sample sizes and multiple (non-)correlated true effects in underlying data. For an easy application of such benchmarks, our modelBuildR package can be used and is made publicly available on github.</p>
  </sec>
  <sec sec-type="conclusions">
    <title>Conclusions</title>
    <p>In biomedical research, misclassification is not negligible with reported error rates up to 15%. Classical feature selection methods, however, assume that a provided labeling is correct and select features best explaining potentially erroneous data, even though interest lies in true underlying groups. We propose a novel feature selection heuristic which inverts roles of dependent and independent variables in an initial feature selection step and proceeds with standard methods. Its superior performance in identifying features associated with the ground truth even for wrongly labeled samples is demonstrated in synthetic data arising from two true groups and binary manual encoding. A use case with methylation array omics data shows promising results. Further work is needed to better characterize applications for which the proposed heuristic might be beneficial.</p>
  </sec>
  <sec sec-type="supplementary-material" id="supplemental-information">
    <title> Supplemental Information</title>
    <supplementary-material content-type="local-data" id="supp-1">
      <object-id pub-id-type="doi">10.7717/peerj.10849/supp-1</object-id>
      <label>Figure S1</label>
      <caption>
        <title>Time requirements for different evaluated datasets</title>
      </caption>
      <media xlink:href="peerj-09-10849-s001.png">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="supp-2">
      <object-id pub-id-type="doi">10.7717/peerj.10849/supp-2</object-id>
      <label>Figure S2</label>
      <caption>
        <title>AUC stratified by parameters used for simulation of data with semi-quantitative classification and graduated ground truth</title>
        <p>BH <italic>p</italic>-value adjustment in prefiltering step.</p>
      </caption>
      <media xlink:href="peerj-09-10849-s002.png">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="supp-3">
      <object-id pub-id-type="doi">10.7717/peerj.10849/supp-3</object-id>
      <label>Figure S3</label>
      <caption>
        <title>AUC stratified by parameters used for simulation of data with semi-quantitative classification and graduated ground truth</title>
        <p>Bonferroni <italic>p</italic>-value adjustment in prefiltering step.</p>
      </caption>
      <media xlink:href="peerj-09-10849-s003.png">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="supp-4">
      <object-id pub-id-type="doi">10.7717/peerj.10849/supp-4</object-id>
      <label>Figure S4</label>
      <caption>
        <title>AUC stratified by parameters used for simulation of data for binary classification and dichotomous ground truth</title>
        <p>BH <italic>p</italic>-value adjustment in prefiltering step.</p>
      </caption>
      <media xlink:href="peerj-09-10849-s004.png">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="supp-5">
      <object-id pub-id-type="doi">10.7717/peerj.10849/supp-5</object-id>
      <label>Figure S5</label>
      <caption>
        <title>AUC stratified by parameters used for simulation of data for binary classification and dichotomous ground truth</title>
        <p>Bonferroni <italic>p</italic>-value adjustment inprefiltering step and numbers of models with AUC &lt; = 0.5.</p>
      </caption>
      <media xlink:href="peerj-09-10849-s005.png">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="supp-6">
      <object-id pub-id-type="doi">10.7717/peerj.10849/supp-6</object-id>
      <label>Figure S6</label>
      <caption>
        <title>AUC stratified by parameters used for simulation of data with semi-quantitative classification and dichotomous ground truth</title>
        <p>BH <italic>p</italic>-value adjustment in prefiltering step, data shown for 3,4 and 5 groups.</p>
      </caption>
      <media xlink:href="peerj-09-10849-s006.png">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="supp-7">
      <object-id pub-id-type="doi">10.7717/peerj.10849/supp-7</object-id>
      <label>Figure S7</label>
      <caption>
        <title>Comparison of feature presentation methods for binary outcomes with underlying true dichotomous groups and for larger number of features and samples</title>
        <p>(A) AUCs of model predictions tested against group truth for varying classification probabilities, numbers of samples and features. (B) AUC ranks for V1 and V2, rank-ties methods: avg average, rnd: random. (C) AUCs stratified by parameters used for simulation of data. Bonferroni p-value adjustment.</p>
      </caption>
      <media xlink:href="peerj-09-10849-s007.png">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="supp-8">
      <object-id pub-id-type="doi">10.7717/peerj.10849/supp-8</object-id>
      <label>Figure S8</label>
      <caption>
        <title>Identification of prognostically different tumors and associated differentially methylated probes from the TCGA-GBM 450k methylation array dataset</title>
        <p>Kaplan–Meier survival curves, Likelihood Ratio Test (Cox-PH) <italic>p</italic>-values. See Suppl-Methods for details.</p>
      </caption>
      <media xlink:href="peerj-09-10849-s008.png">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="supp-9">
      <object-id pub-id-type="doi">10.7717/peerj.10849/supp-9</object-id>
      <label>Table S1</label>
      <caption>
        <title>modelBuildR dervied model for prognostic separation of G-CIMP- tumors from the TCGA-GBM cohort</title>
        <p>M-values were used for model training, binary outcome (grp1 vs grp2, <xref ref-type="fig" rid="fig-7">Fig. 7B</xref>), default parameters.</p>
      </caption>
      <media xlink:href="peerj-09-10849-s009.csv">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="supp-10">
      <object-id pub-id-type="doi">10.7717/peerj.10849/supp-10</object-id>
      <label>Supplemental Information 1</label>
      <caption>
        <title>Supplemental Methods</title>
      </caption>
      <media xlink:href="peerj-09-10849-s010.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>We thank the Heidelberg Medical Faculty at Heidelberg University for their financial support within the scope of the MD/PhD program to MK and JF.</p>
  </ack>
  <sec sec-type="additional-information">
    <title>Additional Information and Declarations</title>
    <fn-group content-type="competing-interests">
      <title>Competing Interests</title>
      <fn id="conflict-1" fn-type="COI-statement">
        <p>The authors declare there are no competing interests.</p>
      </fn>
    </fn-group>
    <fn-group content-type="author-contributions">
      <title>Author Contributions</title>
      <fn id="contribution-1" fn-type="con">
        <p><xref ref-type="contrib" rid="author-1">Maximilian Knoll</xref> conceived and designed the experiments, performed the experiments, analyzed the data, prepared figures and/or tables, authored or reviewed drafts of the paper, and approved the final draft.</p>
      </fn>
      <fn id="contribution-2" fn-type="con">
        <p><xref ref-type="contrib" rid="author-2">Jennifer Furkel</xref>, <xref ref-type="contrib" rid="author-3">Juergen Debus</xref> and <xref ref-type="contrib" rid="author-4">Amir Abdollahi</xref> conceived and designed the experiments, authored or reviewed drafts of the paper, and approved the final draft.</p>
      </fn>
    </fn-group>
    <fn-group content-type="other">
      <title>Data Availability</title>
      <fn id="addinfo-1">
        <p>The following information was supplied regarding data availability:</p>
        <p>The R package is available at Github: <ext-link ext-link-type="uri" xlink:href="http://github.com/mknoll/modelBuildR">http://github.com/mknoll/modelBuildR</ext-link>.</p>
        <p>Code for the simulation study are accessible at CodeOcean:</p>
        <p>Maximilian Knoll (2020) modelBuildR: An R package for model building and feature selection with erroneous classifications. [Source Code]. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.24433/CO.3805663.v1">https://doi.org/10.24433/CO.3805663.v1</ext-link>.</p>
      </fn>
    </fn-group>
  </sec>
  <ref-list content-type="authoryear">
    <title>References</title>
    <ref id="ref-1">
      <label>Akaike (1973)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="editor">
          <name>
            <surname>Akaike</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <year>1973</year>
        <source>Information theory and an extension of the maximum likelihood principle</source>
        <publisher-name>Akadémiai Kiadó</publisher-name>
        <publisher-loc>Budapest</publisher-loc>
      </element-citation>
    </ref>
    <ref id="ref-2">
      <label>Balermpas et al. (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Balermpas</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Rodel</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Krause</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Linge</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lohaus</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Baumann</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Tinhofer</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Budach</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Sak</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Stuschke</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Gkika</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Grosu</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Abdollahi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Debus</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Stangl</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ganswindt</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Belka</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Pigorsch</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Multhoff</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Combs</surname>
            <given-names>SE</given-names>
          </name>
          <name>
            <surname>Welz</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zips</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Lim</surname>
            <given-names>SY</given-names>
          </name>
          <name>
            <surname>Rodel</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Fokas</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Dktk</surname>
            <given-names>ROG</given-names>
          </name>
        </person-group>
        <year>2017</year>
        <article-title>The PD-1/PD-L1 axis and human papilloma virus in patients with head and neck cancer after adjuvant chemoradiotherapy: a multicentre study of the German Cancer Consortium Radiation Oncology Group (DKTK-ROG)</article-title>
        <source>International Journal of Cancer</source>
        <volume>141</volume>
        <issue>3</issue>
        <fpage>594</fpage>
        <lpage>603</lpage>
        <pub-id pub-id-type="doi">10.1002/ijc.30770</pub-id>
        <pub-id pub-id-type="pmid">28480996</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-3">
      <label>Barnard et al. (2018)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Barnard</surname>
            <given-names>ME</given-names>
          </name>
          <name>
            <surname>Pyden</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Rice</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Linares</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Tworoger</surname>
            <given-names>SS</given-names>
          </name>
          <name>
            <surname>Howitt</surname>
            <given-names>BE</given-names>
          </name>
          <name>
            <surname>Meserve</surname>
            <given-names>EE</given-names>
          </name>
          <name>
            <surname>Hecht</surname>
            <given-names>JL</given-names>
          </name>
        </person-group>
        <year>2018</year>
        <article-title>Inter-pathologist and pathology report agreement for ovarian tumor characteristics in the Nurses’ Health Studies</article-title>
        <source>Gynecologic Oncology</source>
        <volume>150</volume>
        <issue>3</issue>
        <fpage>521</fpage>
        <lpage>526</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ygyno.2018.07.003</pub-id>
        <pub-id pub-id-type="pmid">30001835</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-4">
      <label>Capper et al. (2018)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Capper</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>DTW</given-names>
          </name>
          <name>
            <surname>Sill</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hovestadt</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Schrimpf</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Sturm</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Koelsche</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Sahm</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Chavez</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Reuss</surname>
            <given-names>DE</given-names>
          </name>
          <name>
            <surname>Kratz</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wefers</surname>
            <given-names>AK</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Pajtler</surname>
            <given-names>KW</given-names>
          </name>
          <name>
            <surname>Schweizer</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Stichel</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Olar</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Engel</surname>
            <given-names>NW</given-names>
          </name>
          <name>
            <surname>Lindenberg</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Harter</surname>
            <given-names>PN</given-names>
          </name>
          <name>
            <surname>Braczynski</surname>
            <given-names>AK</given-names>
          </name>
          <name>
            <surname>Plate</surname>
            <given-names>KH</given-names>
          </name>
          <name>
            <surname>Dohmen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Garvalov</surname>
            <given-names>BK</given-names>
          </name>
          <name>
            <surname>Coras</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Holsken</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hewer</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Bewerunge-Hudler</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Schick</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Fischer</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Beschorner</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Schittenhelm</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Staszewski</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Wani</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Varlet</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Pages</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Temming</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Lohmann</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Selt</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Witt</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Milde</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Witt</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Aronica</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Giangaspero</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Rushing</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Scheurlen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Geisenberger</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Rodriguez</surname>
            <given-names>FJ</given-names>
          </name>
          <name>
            <surname>Becker</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Preusser</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Haberler</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Bjerkvig</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Cryan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Farrell</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Deckert</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hench</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Frank</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Serrano</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Kannan</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Tsirigos</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bruck</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Hofer</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Brehmer</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Seiz-Rosenhagen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hanggi</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hans</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Rozsnoki</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Hansford</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Kohlhof</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Kristensen</surname>
            <given-names>BW</given-names>
          </name>
          <name>
            <surname>Lechner</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lopes</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Mawrin</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ketter</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Kulozik</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Khatib</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Heppner</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Koch</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Jouvet</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Keohane</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Muhleisen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Mueller</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Pohl</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Prinz</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Benner</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Zapatka</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Gottardo</surname>
            <given-names>NG</given-names>
          </name>
          <name>
            <surname>Driever</surname>
            <given-names>PH</given-names>
          </name>
          <name>
            <surname>Kramm</surname>
            <given-names>CM</given-names>
          </name>
          <name>
            <surname>Muller</surname>
            <given-names>HL</given-names>
          </name>
          <name>
            <surname>Rutkowski</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Hoff</surname>
            <given-names>Kvon</given-names>
          </name>
          <name>
            <surname>Fruhwald</surname>
            <given-names>MC</given-names>
          </name>
          <name>
            <surname>Gnekow</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Fleischhack</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Tippelt</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Calaminus</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Monoranu</surname>
            <given-names>CM</given-names>
          </name>
          <name>
            <surname>Perry</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Jacques</surname>
            <given-names>TS</given-names>
          </name>
          <name>
            <surname>Radlwimmer</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Gessi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Pietsch</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Schramm</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Schackert</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Westphal</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Reifenberger</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Wesseling</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Weller</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Collins</surname>
            <given-names>VP</given-names>
          </name>
          <name>
            <surname>Blumcke</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Bendszus</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Debus</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Jabado</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Northcott</surname>
            <given-names>PA</given-names>
          </name>
          <name>
            <surname>Paulus</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Gajjar</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Robinson</surname>
            <given-names>GW</given-names>
          </name>
          <name>
            <surname>Taylor</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Jaunmuktane</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Ryzhova</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Platten</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Unterberg</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wick</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Karajannis</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Mittelbronn</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Acker</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Hartmann</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Aldape</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Schuller</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Buslei</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Lichter</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Kool</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Herold-Mende</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ellison</surname>
            <given-names>DW</given-names>
          </name>
          <name>
            <surname>Hasselblatt</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Snuderl</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Brandner</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Korshunov</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Deimling</surname>
            <given-names>Avon</given-names>
          </name>
          <name>
            <surname>Pfister</surname>
            <given-names>SM</given-names>
          </name>
        </person-group>
        <year>2018</year>
        <article-title>DNA methylation-based classification of central nervous system tumours</article-title>
        <source>Nature</source>
        <volume>555</volume>
        <issue>7697</issue>
        <fpage>469</fpage>
        <lpage>474</lpage>
        <pub-id pub-id-type="doi">10.1038/nature26000</pub-id>
        <pub-id pub-id-type="pmid">29539639</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-5">
      <label>Chen et al. (2019)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kingsbury</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Sohn</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Storlie</surname>
            <given-names>CB</given-names>
          </name>
          <name>
            <surname>Habermann</surname>
            <given-names>EB</given-names>
          </name>
          <name>
            <surname>Naessens</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Larson</surname>
            <given-names>DW</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <year>2019</year>
        <article-title>Deep learning and alternative learning strategies for retrospective real-world clinical data</article-title>
        <source>NPJ Digital Medicine</source>
        <volume>2</volume>
        <comment>Article 43</comment>
        <pub-id pub-id-type="doi">10.1038/s41746-019-0122-0</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-6">
      <label>dataAnalysisMisc (2020)</label>
      <element-citation publication-type="software">
        <person-group person-group-type="author">
          <collab>dataAnalysisMisc</collab>
        </person-group>
        <year>2020</year>
        <data-title>Collection of functions for daily tasks</data-title>
        <version designator="0.99.11">R package version 0.99.11</version>
        <uri xlink:href="http://github.com/mknoll/dataAnalysisMisc">http://github.com/mknoll/dataAnalysisMisc</uri>
      </element-citation>
    </ref>
    <ref id="ref-7">
      <label>Deo (2015)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deo</surname>
            <given-names>RC</given-names>
          </name>
        </person-group>
        <year>2015</year>
        <article-title>Machine learning in medicine</article-title>
        <source>Circulation</source>
        <volume>132</volume>
        <issue>20</issue>
        <fpage>1920</fpage>
        <lpage>1930</lpage>
        <pub-id pub-id-type="doi">10.1161/CIRCULATIONAHA.115.001593</pub-id>
        <pub-id pub-id-type="pmid">26572668</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-8">
      <label>Friedman, Hastie &amp; Tibshirani (2010)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Friedman</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hastie</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Tibshirani</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <year>2010</year>
        <article-title>Regularization paths for generalized linear models via coordinate descent</article-title>
        <source>Journal of Statistical Software</source>
        <volume>33</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>22</lpage>
        <pub-id pub-id-type="pmid">20808728</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-9">
      <label>Hastie &amp; Tibshirani (1986)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hastie</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Tibshirani</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <year>1986</year>
        <article-title>Generalized additive models</article-title>
        <source>Statistical Science</source>
        <volume>1</volume>
        <issue>3</issue>
        <fpage>297</fpage>
        <lpage>310</lpage>
        <pub-id pub-id-type="doi">10.1214/ss/1177013604</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-10">
      <label>Holzinger et al. (2019)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Holzinger</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Langs</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Denk</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zatloukal</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Muller</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <year>2019</year>
        <article-title>Causability and explainability of artificial intelligence in medicine</article-title>
        <source>Wiley Interdisciplinary Reviews</source>
        <volume>9</volume>
        <issue>4</issue>
        <elocation-id>e1312</elocation-id>
        <pub-id pub-id-type="pmid">32089788</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-11">
      <label>Hwang et al. (2019)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hwang</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Mathios</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>McDonald</surname>
            <given-names>KL</given-names>
          </name>
          <name>
            <surname>Daris</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>SH</given-names>
          </name>
          <name>
            <surname>Burger</surname>
            <given-names>PC</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Dho</surname>
            <given-names>YS</given-names>
          </name>
          <name>
            <surname>Carolyn</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Bettegowda</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Shin</surname>
            <given-names>JH</given-names>
          </name>
          <name>
            <surname>Lim</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>CK</given-names>
          </name>
        </person-group>
        <year>2019</year>
        <article-title>Integrative analysis of DNA methylation suggests down-regulation of oncogenic pathways and reduced somatic mutation rates in survival outliers of glioblastoma</article-title>
        <source>Acta Neuropathologica Communications</source>
        <volume>7</volume>
        <issue>1</issue>
        <comment>Article 88</comment>
        <pub-id pub-id-type="doi">10.1186/s40478-019-0744-0</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-12">
      <label>Knoll et al. (2019)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Knoll</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Debus</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Furkel</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Warta</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Bougatf</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Rapp</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Brors</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Wick</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Unterberg</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Herold-Mende</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Abdollahi</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <year>2019</year>
        <article-title>Glioblastoma evolution pattern under surgery and radio(chemo)therapy (RCHT) to identify novel methylome based glioma subtypes</article-title>
        <source>Journal of Clinical Oncology</source>
        <volume>37</volume>
        <issue>suppl 15</issue>
        <fpage>2012</fpage>
        <lpage>2012</lpage>
        <pub-id pub-id-type="doi">10.1200/JCO.2019.37.15_suppl.2012</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-13">
      <label>Knoll et al. (2016)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Knoll</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Macher-Goeppinger</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kopitz</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Duensing</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Pahernik</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Hohenfellner</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Schirmacher</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Roth</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <year>2016</year>
        <article-title>The ribosomal protein S6 in renal cell carcinoma: functional relevance and potential as biomarker</article-title>
        <source>Oncotarget</source>
        <volume>7</volume>
        <issue>1</issue>
        <fpage>418</fpage>
        <lpage>432</lpage>
        <pub-id pub-id-type="doi">10.18632/oncotarget.6225</pub-id>
        <pub-id pub-id-type="pmid">26506236</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-14">
      <label>Konopka (2020)</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Konopka</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <year>2020</year>
        <article-title>unap: Uniform manifold approximation and projection</article-title>
        <uri xlink:href="https://CRAN.R-project.org/package=umap">https://CRAN.R-project.org/package=umap</uri>
      </element-citation>
    </ref>
    <ref id="ref-15">
      <label>Lazar et al. (2012)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lazar</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Taminau</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Meganck</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Steenhoff</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Coletta</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Molter</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Schaetzen</surname>
            <given-names>VD</given-names>
          </name>
          <name>
            <surname>Duque</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Bersini</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Nowe</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <year>2012</year>
        <article-title>A survey on filter techniques for feature selection in gene expression microarray analysis</article-title>
        <source>IEEE/ACM Transactions on Computational Biology and Bioinformatics</source>
        <volume>9</volume>
        <issue>4</issue>
        <fpage>1106</fpage>
        <lpage>1119</lpage>
        <pub-id pub-id-type="doi">10.1109/TCBB.2012.33</pub-id>
        <pub-id pub-id-type="pmid">22350210</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-16">
      <label>Liaw &amp; Wiener (2002)</label>
      <element-citation publication-type="journal">
        <year>2002</year>
        <person-group person-group-type="author">
          <name>
            <surname>Liaw</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wiener</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Classification and regression by randomForest</article-title>
        <source>R News</source>
        <volume>2</volume>
        <issue>3</issue>
        <fpage>18</fpage>
        <lpage>22</lpage>
      </element-citation>
    </ref>
    <ref id="ref-17">
      <label>Maindonald &amp; Braun (2020)</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Maindonald</surname>
            <given-names>JH</given-names>
          </name>
          <name>
            <surname>Braun</surname>
            <given-names>WJ</given-names>
          </name>
        </person-group>
        <year>2020</year>
        <article-title>DAAG: Data analysis and graphics data and functions</article-title>
        <uri xlink:href="https://CRAN.R-project.org/package=DAAG">https://CRAN.R-project.org/package=DAAG</uri>
      </element-citation>
    </ref>
    <ref id="ref-18">
      <label>McCullagh &amp; Nelder (1989)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>McCullagh</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Nelder</surname>
            <given-names>JA</given-names>
          </name>
        </person-group>
        <year>1989</year>
        <source>Generalized linear models</source>
        <publisher-name>Chapman &amp; Hall/CRC</publisher-name>
        <publisher-loc>New York</publisher-loc>
        <edition designator="2">Second Edition</edition>
      </element-citation>
    </ref>
    <ref id="ref-19">
      <label>McInnes &amp; Healy (2018)</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>McInnes</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Healy</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>UMAP: uniform manifold approximation and projection for dimension reduction</article-title>
        <comment>ArXiv 2018</comment>
      </element-citation>
    </ref>
    <ref id="ref-20">
      <label>pvclust (2019)</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <collab>pvclust</collab>
        </person-group>
        <year>2019</year>
        <article-title>Hierarchical clustering with <italic>P</italic>-values via multiscale bootstrap resampling</article-title>
        <uri xlink:href="https://CRAN.R-project.org/package=pvclust">https://CRAN.R-project.org/package=pvclust</uri>
      </element-citation>
    </ref>
    <ref id="ref-21">
      <label>Robin et al. (2011)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Robin</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Turck</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hainard</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tiberti</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Lisacek</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Sanchez</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Muller</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <year>2011</year>
        <article-title>pROC: an open-source package for R and S+ to analyze and compare ROC curves</article-title>
        <source>BMC Bioinformatics</source>
        <volume>12</volume>
        <fpage>77</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-12-77</pub-id>
        <pub-id pub-id-type="pmid">21414208</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-22">
      <label>Santosa &amp; Symes (1986)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Santosa</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Symes</surname>
            <given-names>WW</given-names>
          </name>
        </person-group>
        <year>1986</year>
        <article-title>Linear inversion of band-limited reflection seismograms</article-title>
        <source>SIAM Journal on Scientific and Statistical Computing</source>
        <volume>7</volume>
        <issue>4</issue>
        <fpage>1307</fpage>
        <lpage>1330</lpage>
        <pub-id pub-id-type="doi">10.1137/0907087</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-23">
      <label>Tibshirani (1996)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tibshirani</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <year>1996</year>
        <article-title>Regression shrinkage and selection via the lasso</article-title>
        <source>Journal of the Royal Statistical Society Series B</source>
        <volume>58</volume>
        <issue>1</issue>
        <fpage>267</fpage>
        <lpage>288</lpage>
      </element-citation>
    </ref>
    <ref id="ref-24">
      <label>Yuan et al. (2019)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yuan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <year>2019</year>
        <article-title>Adversarial examples: attacks and defenses for deep learning</article-title>
        <source>IEEE Transactions on Neural Networks and Learning Systems</source>
        <volume>30</volume>
        <issue>9</issue>
        <fpage>2805</fpage>
        <lpage>2824</lpage>
        <pub-id pub-id-type="doi">10.1109/TNNLS.2018.2886017</pub-id>
        <pub-id pub-id-type="pmid">30640631</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
