<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Nat Commun</journal-id>
    <journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id>
    <journal-title-group>
      <journal-title>Nature Communications</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2041-1723</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9636371</article-id>
    <article-id pub-id-type="publisher-id">34381</article-id>
    <article-id pub-id-type="doi">10.1038/s41467-022-34381-8</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>VeChat: correcting errors in long reads using variation graphs</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Luo</surname>
          <given-names>Xiao</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kang</surname>
          <given-names>Xiongbin</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3529-0856</contrib-id>
        <name>
          <surname>Schönhuth</surname>
          <given-names>Alexander</given-names>
        </name>
        <address>
          <email>a.schoenhuth@cwi.nl</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.7491.b</institution-id><institution-id institution-id-type="ISNI">0000 0001 0944 9128</institution-id><institution>Genome Data Science, Faculty of Technology, </institution><institution>Bielefeld University, </institution></institution-wrap>Bielefeld, Germany </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.6054.7</institution-id><institution-id institution-id-type="ISNI">0000 0004 0369 4183</institution-id><institution>Life Science &amp; Health, </institution><institution>Centrum Wiskunde &amp; Informatica, </institution></institution-wrap>Amsterdam, The Netherlands </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>4</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>4</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>13</volume>
    <elocation-id>6657</elocation-id>
    <history>
      <date date-type="received">
        <day>4</day>
        <month>3</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>24</day>
        <month>10</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Error correction is the canonical first step in long-read sequencing data analysis. Current self-correction methods, however, are affected by consensus sequence induced biases that mask true variants in haplotypes of lower frequency showing in mixed samples. Unlike consensus sequence templates, graph-based reference systems are not affected by such biases, so do not mistakenly mask true variants as errors. We present VeChat, as an approach to implement this idea: VeChat is based on variation graphs, as a popular type of data structure for pangenome reference systems. Extensive benchmarking experiments demonstrate that long reads corrected by VeChat contain 4 to 15 (Pacific Biosciences) and 1 to 10 times (Oxford Nanopore Technologies) less errors than when being corrected by state of the art approaches. Further, using VeChat prior to long-read assembly significantly improves the haplotype awareness of the assemblies. VeChat is an easy-to-use open-source tool and publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/HaploKit/vechat">https://github.com/HaploKit/vechat</ext-link>.</p>
    </abstract>
    <abstract id="Abs2" abstract-type="web-summary">
      <p id="Par2">Consensus sequence-based methods for self-correction of long-read sequencing data are affected by biases that can mask true variants characterizing little-covered or low-frequency haplotypes. Here, to address this issue, the authors develop a variation graph-based method for performing haplotype-aware self-correction of long reads.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Genome assembly algorithms</kwd>
      <kwd>DNA sequencing</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100010890</institution-id>
            <institution>CSC | Chinese Government Scholarship</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Dutch Scientific Organization, through Vidi grant 639.072.309. European Union’s Horizon 2020 research and innovation programme under Marie Skłodowska-Curie grant agreements No 956229 (ALPACA) and No 872539 (PANGAIA)</institution>
        </funding-source>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par3">Third-generation sequencing (TGS) such as single-molecule real-time (Pacific Biosciences, or short PacBio) or nanopore sequencing (Oxford Nanopore Technologies or short ONT) has been emerging rapidly over the last few years. The most obvious reason is that the length of TGS reads exceeds the length of next-generation sequencing (NGS) reads by orders of magnitude. While the length of TGS reads ranges from several Kbp up to even a few Mbp<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>, NGS reads only span a few hundred base pairs. The fact that TGS is relatively inexpensive and, depending on the particular platform can even be carried out on mobile, handheld devices, greatly adds to its popularity. Last but not least, TGS does not suffer from PCR induced biases, because it circumvents polymerase chain reaction (PCR) as part of its protocol. Thanks to these advantages, TGS has been able to make decisive contributions in various areas of application. Prominent examples are haplotype phasing<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>, genome assembly<sup><xref ref-type="bibr" rid="CR3">3</xref>–<xref ref-type="bibr" rid="CR7">7</xref></sup> and (complex) variant calling<sup><xref ref-type="bibr" rid="CR8">8</xref>–<xref ref-type="bibr" rid="CR10">10</xref></sup>.</p>
    <p id="Par4">The downside of TGS, however, are the significantly elevated error rates the reads are subject to. For example, PacBio CLR and ONT reads, as the currently most representative examples of TGS reads, contain 5% to 15% errors<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. This comes in obvious contrast to NGS short reads, whose error rates usually do not exceed 1%. The fact that the majority of errors affecting long reads consists of insertions and deletions adds to the difficulties because it prevents the application of principles and straightforward adaptation of tools for correcting errors in short reads. This implies that direct usage of raw TGS reads or successful application of existing error correction tools is hardly possible in the majority of relevant applications. Novel methods and tools are required for correcting errors in TGS reads.</p>
    <p id="Par5">Because correcting errors in TGS reads is imperative for sound analyses, various TGS read error correction methods have been presented in the meantime. The corresponding range of methods can be divided into two major categories: hybrid correction and self-correction. While hybrid correction addresses to integrate short reads into the error correction process, self-correction seeks to correct errors without auxiliary data.</p>
    <p id="Par6">Hybrid correction reflects a sound and reasonable approach in general (see<sup><xref ref-type="bibr" rid="CR11">11</xref>–<xref ref-type="bibr" rid="CR14">14</xref></sup> for prominent approaches). However, hybrid correction suffers from certain pragmatic issues. First, while long reads can span repetitive regions, short reads cannot; this introduces ambiguities in the process of assigning short to long reads (or vice versa), and as a consequence biases in the quality of the correction, depending on the uniqueness of the region in the genome the reads stem from. Second, short reads re-introduce PCR induced biases. For example, certain areas of genomes are not sufficiently covered by short reads because of sequence content (e.g. GC content). This hampers error correction in these areas. Last but not least, employing several different sequencing protocols can be impossible for equipment related or financial reasons, which prevents the application of hybrid error correction in the first place.</p>
    <p id="Par7">Self-correction, as the second class of methods, does not suffer from any of these issues. However, because of the lack of external (e.g. short read based) assistance, self-correction faces other methodically principled challenges. It is key to overcome these challenges before one can profit from the great practical advantages of self-error correction. In terms of prior, related work, self-correction can be further divided into three sub-categories, each of which is characterized by particular algorithmic strategies and methodical foundations.</p>
    <p id="Par8">The first, and most common of the three categories is based on multiple sequence alignments (MSAs). For prior approaches and tools that crucially rely on computing MSAs, see Racon<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, the error correction module of the assembler Canu<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>, and FLAS<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>. The second principled class of approaches relies on de Bruijn graphs (DBGs). Corresponding tools employ DBGs at some point crucial for the correction process. The prevalent tool to consider is Daccord<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>, which is based on raising local DBGs, where local refers to reads, from which DBGs are constructed, stemming from relatively small segments of the genome. The third class of self-correction methods collects approaches that make combined use of both MSAs and DBGs. Such methodically combined approaches seek to balance the advantages and disadvantages of the two concepts, MSAs on the one hand, and DBGs on the other hand. Prominent tools that make successful, combined use of MSAs with DBGs are LoRMA<sup><xref ref-type="bibr" rid="CR19">19</xref></sup> and CONSENT<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>.</p>
    <p id="Par9">The common denominator that unifies all of these self-correction approaches is to raise consensus sequence as a summary of the reads observed. This consensus sequence then serves as a template during error correction, by indicating default variation. However, because sequence-based templates cannot capture ambiguities, one experiences biases during the correction process: the default allele provided by the template wins in case of uncertainties remaining. As a consequence, these approaches tend to mask variation that characterizes little-covered or low-frequency haplotypes/strains in mixed samples (metagenomes, cancer genomes) or polyploid genomes. Haplotypes exhibiting template masked variants virtually disappear, such that downstream analyses remain blind to them.</p>
    <p id="Par10">To address this issue, we suggest VeChat ([V]ariation graph-based [e]rror [C]orrection in [ha]plo[t]ypes), a self-correction method to perform haplotype-aware error correction for long reads. From a larger perspective, VeChat considers the full spectrum of all possible haplotypes that possibly affect the sample already during error correction, and not—as is common—only thereafter. This reflects a novelty for ploidies larger than two, because earlier approaches only deal with diploid scenarios<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>. From a methodical point of view, the novelty of VeChat is to integrate variation graphs<sup><xref ref-type="bibr" rid="CR22">22</xref></sup> as a fundamental data structure into the process of error correction. Variation graphs have been effectively used to solve various problems in computational genomics, such as improving read mapping and variant calling<sup><xref ref-type="bibr" rid="CR23">23</xref>–<xref ref-type="bibr" rid="CR25">25</xref></sup>, modeling haplotypes<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> and assembling genomes from mixed samples<sup><xref ref-type="bibr" rid="CR27">27</xref>,<xref ref-type="bibr" rid="CR28">28</xref></sup>. To the best of our knowledge, VeChat is the first approach to apply variation graphs to long-read error correction. We have tested VeChat and extensively compared it with the current state of the art on datasets reflecting various settings of current interest. Benchmarking experiments on both simulated and real data demonstrate that our approach basically achieves the best performance rates, across all categories of common sequencing errors. Moreover, using VeChat for long-read error correction prior to haplotype-aware genome assembly largely improves assemblies in terms of most relevant categories, most prominently including completeness, contiguity and accuracy.</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <p id="Par11">We have designed and implemented VeChat, an approach to haplotype aware long-read self error correction. The key concept underlying VeChat are variation graphs. Unlike single consensus sequences, which current self-correction approaches are generally centering on, variation graphs are able to represent the genetic diversity across multiple, evolutionarily or environmentally coherent genomes<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. This enables to preserve haplotype-specific variation during error correction also for samples of higher, known or unknown ploidy.</p>
    <p id="Par12">In this section, we first provide a high-level description of the workflow of VeChat. We then evaluate the performance of VeChat on both simulated and real data in comparison with the state of the art approaches. Finally, we assess the effect of integrating VeChat as a preprocessing tool in common haplotype aware genome assembly pipelines.</p>
    <sec id="Sec3">
      <title>Workflow</title>
      <p id="Par13">See Fig. <xref rid="Fig1" ref-type="fig">1</xref> for an illustration of the workflow of VeChat. See also Methods for full details in the following.<fig id="Fig1"><label>Fig. 1</label><caption><title>Workflow of VeChat.</title><p>The input and output of cycle 1 and cycle 2 are labeled with purple and blue, respectively. Both cycle 1 and cycle 2 share the steps 1-6 except some differences in step 1 and 4. The target read is highlighted with orange. Red forks indicate the sequencing errors in reads.</p></caption><graphic xlink:href="41467_2022_34381_Fig1_HTML" id="d32e355"/></fig></p>
      <p id="Par14">The basic idea of VeChat is to construct a variation graph from the all-to-all alignments of the raw reads. One then identifies nodes and edges in the resulting graph that are likely to be artifacts, and removes them. Subsequently, reads are realigned against the resulting, pruned graph. The path in the pruned graph corresponding to the optimal re-alignment points out an error-corrected sequence of the read. The procedure of spurious node and edge removal followed by re-alignment is repeated until convergence (note that the statistical evaluation of remaining nodes and edges changes upon re-alignment, which may reveal new likely spurious nodes and edges in the next iteration). The re-alignment of the original read with the final graph points out the fully error-corrected sequence of the read.</p>
      <p id="Par15">VeChat consists of two cycles. While the first cycle yields pre-corrected reads, the second cycle generates the final, corrected reads from the pre-corrected reads. Each cycle proceeds in 6 steps. While the two cycles generally agree on these 6 steps, they disagree in terms of small, but crucial details affecting steps 1 and 4.</p>
      <p id="Par16">During the first cycle, step 1 computes minimizer based all-vs-all overlaps, for which we employ Minimap2<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. Minimap2 prevents the need for computing base-level alignments. Therefore, this stage proceeds rapidly and without additional efforts.</p>
      <p id="Par17">Steps 2–6 reflect the technical core of the error correction procedure in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. In step 2, a target read is selected as the read whose errors are to be corrected. A read alignment pile that consists of all reads that overlap it is computed. Subsequently, in step 3, the read alignment pile is divided into small segments, where each of the segments gives rise to a window like part of the pile in step 3; the part of the target read in a particular window is further referred to as ’target subread’.</p>
      <p id="Par18">Subsequently, in step 4, the error correction for target subreads is performed in each window. Step 4 is methodically more involved, because it captures the novel, variation graph-based approach; see Fig. <xref rid="Fig2" ref-type="fig">2</xref> for detailed illustrations on the version of that particular step used in the first cycle. Step 4 involves the construction of a variation graph using the partial order alignment (POA) algorithm<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>, and pruning this graph in an iterative manner from nodes and edges that are spurious because they reflect errors (‘Graph pruning’ and ‘Graph re-pruning’ in Fig. <xref rid="Fig2" ref-type="fig">2</xref>). For pruning the graph, we make use of a frequent itemset model that involves read coverage, sequencing errors and co-occurrence of characters in reads. The path in the pruned variation graph that corresponds to the optimal alignment of the target subread is then taken as the pre-corrected target subread; see subsection Step 4: Error correction for target subreads in Methods for details. The first cycle concludes with concatenating the different ’target subreads’ of one target read, which results in a pre-corrected read at full, original length. These pre-corrected reads then serve as input for the second cycle.<fig id="Fig2"><label>Fig. 2</label><caption><title>Error correction for one target subread in cycle 1.</title><p>The error correction process for the target read <italic>r</italic> is illustrated assuming a diploid scenario (the orange path represents the optimal alignment path, whereas the green path represents the other true haplotype). “Graph pruning” and “Graph re-pruning” refer to the core error correction procedures. These procedures rely on a variation graph that is constructed from segments of a read alignment pile that results from a multiple alignment of the target read and the reads that overlap it, see Fig. <xref rid="Fig1" ref-type="fig">1</xref>. During graph pruning and re-pruning spurious edges (dashed arrows), induced by sequencing errors, are removed from the variation graph. The pink elements indicate that these procedures are repeated.</p></caption><graphic xlink:href="41467_2022_34381_Fig2_HTML" id="d32e399"/></fig></p>
      <p id="Par19">While the (vast) majority of errors have already been corrected during the first cycle, a few errors, to be considered statistical outliers that escape correction during iterative graph pruning during the first cycle, have resisted their correction. The second cycle is supposed to spot such outliers. The second cycle is less complex than the first cycle, because it does no longer include the statistically involved graph pruning procedure; the blue elements in Fig. <xref rid="Fig1" ref-type="fig">1</xref> point out the different routes along which the second cycle proceeds. Overall, as above-mentioned, the second cycle is identical with the first cycle in steps 2, 3, 5 and 6. In step 1, however, beyond computing all-vs-all overlaps, base-level alignments are computed, which enables haplotype aware read overlap filtration. Step 4, as shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>, then proceeds differently insofar as graph (re-)pruning is no longer part of the cycle. Instead of iterative re-pruning, which did not lead to removal of the errors that we would like to remove during this second cycle, (haplotype-aware!) consensus sequences (displayed as thick yellow arrows in Fig. <xref rid="Fig3" ref-type="fig">3</xref>) are derived from the constructed variation graphs by using a dynamic programming algorithm<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>. After concatenating these consensus sequences in step 5, joining all target reads in step 6 generates the final output of Vechat.<fig id="Fig3"><label>Fig. 3</label><caption><title>Error correction for one target subread in cycle 2.</title><p>The bold orange path indicates the consensus sequence. The false nucleotide 'G' in the pre-corrected target subread in cycle 1 (see in Fig. <xref rid="Fig2" ref-type="fig">2</xref>) is marked with red and further corrected in cycle 2.</p></caption><graphic xlink:href="41467_2022_34381_Fig3_HTML" id="d32e428"/></fig></p>
    </sec>
    <sec id="Sec4">
      <title>Benchmarking results</title>
      <p id="Par20">Table <xref rid="Tab1" ref-type="table">1</xref> shows the error correction benchmarking results for simulated PacBio CLR reads from genomes of varying ploidies, namely 2,3 and 4. VeChat achieves approximately 14–30, 9–26 and 4–11 times lower error rates on diploid, triploid and tetraploid genomes, respectively. At the same time, it maintains better or comparable performance in terms of other aspects such as number of corrected reads, completeness (haplotype coverage), number of misassemblies and length of corrected reads (as shown by N50/NGA50). In particular, VeChat outperforms other tools in terms of mismatch rate (4–69 times lower than others).<table-wrap id="Tab1"><label>Table 1</label><caption><p>Error correction benchmarking results for simulated PacBio CLR reads of various polyploid genomes (ploidy = 2, 3, 4)</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>#Reads</th><th>Error rate (%)</th><th>Mismatch (%)</th><th>Indel (%)</th><th>Haplotype coverage (%)</th><th>N50 (bp)</th><th>NGA50 (bp)</th><th>#Misassemblies</th></tr></thead><tbody><tr><td><bold>Ploidy</bold> <bold>=</bold> <bold>2</bold></td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>VeChat</td><td>31958</td><td>0.014</td><td>0.006</td><td>0.008</td><td>100.0</td><td>12,556</td><td>38,515</td><td>0</td></tr><tr><td>CONSENT</td><td>33115</td><td>0.194</td><td>0.152</td><td>0.042</td><td>99.9</td><td>12,509</td><td>38,318</td><td>38</td></tr><tr><td>Racon</td><td>32183</td><td>0.276</td><td>0.190</td><td>0.085</td><td>99.2</td><td>12,514</td><td>38,421</td><td>72</td></tr><tr><td>Canu</td><td>25924</td><td>0.308</td><td>0.183</td><td>0.124</td><td>99.9</td><td>13,280</td><td>38,517</td><td>3</td></tr><tr><td>Daccord</td><td>31403</td><td>0.423</td><td>0.412</td><td>0.011</td><td>99.2</td><td>12,604</td><td>38,598</td><td>3</td></tr><tr><td><bold>Ploidy</bold> <bold>=</bold> <bold>3</bold></td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>VeChat</td><td>48085</td><td>0.031</td><td>0.015</td><td>0.016</td><td>100.0</td><td>12,595</td><td>38,467</td><td>13</td></tr><tr><td>CONSENT</td><td>50462</td><td>0.276</td><td>0.205</td><td>0.071</td><td>100.0</td><td>12,511</td><td>38,187</td><td>105</td></tr><tr><td>Racon</td><td>48986</td><td>0.558</td><td>0.427</td><td>0.131</td><td>98.7</td><td>12,484</td><td>38,257</td><td>288</td></tr><tr><td>Canu</td><td>37210</td><td>0.612</td><td>0.405</td><td>0.207</td><td>99.9</td><td>13,675</td><td>38,360</td><td>30</td></tr><tr><td>Daccord</td><td>48189</td><td>0.807</td><td>0.752</td><td>0.055</td><td>99.7</td><td>12,485</td><td>38,357</td><td>16</td></tr><tr><td><bold>Ploidy</bold> <bold>=</bold> <bold>4</bold></td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>VeChat</td><td>62743</td><td>0.074</td><td>0.047</td><td>0.027</td><td>99.9</td><td>12,593</td><td>38,442</td><td>44</td></tr><tr><td>CONSENT</td><td>66315</td><td>0.275</td><td>0.180</td><td>0.095</td><td>100.0</td><td>12,492</td><td>38,268</td><td>111</td></tr><tr><td>Racon</td><td>64342</td><td>0.547</td><td>0.398</td><td>0.149</td><td>93.2</td><td>12,464</td><td>38,016</td><td>387</td></tr><tr><td>Canu</td><td>46698</td><td>0.549</td><td>0.335</td><td>0.214</td><td>99.5</td><td>13,956</td><td>38,255</td><td>86</td></tr><tr><td>Daccord</td><td>63440</td><td>0.833</td><td>0.790</td><td>0.043</td><td>97.5</td><td>12,463</td><td>38,335</td><td>22</td></tr></tbody></table><table-wrap-foot><p>The average sequencing coverage per haplotype is 30× and sequencing error rate is 10%. ‘#Reads’ indicates the number of corrected reads. The error rate is equal to the sum of mismatch and indel rate. The results are sorted by the error rate in ascending order.</p></table-wrap-foot></table-wrap></p>
      <p id="Par21">Table <xref rid="Tab2" ref-type="table">2</xref> shows the error correction benchmarking results for simulated Oxford Nanopore reads from genomes of varying ploidies, namely 2, 3 and 4. VeChat achieves approximately 10–20, 3–9 and 2–5 times lower error rates on diploid, triploid and tetraploid genomes, respectively, while maintaining better or comparable performance in terms of all other aspects. Just as for PacBio reads, VeChat also shows better performance in terms of mismatch rate: 2–59 times lower than other correction tools, compared with indel rate.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Error correction benchmarking results for simulated Oxford Nanopore reads of various polyploid genomes (ploidy = 2, 3, 4)</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>#Reads</th><th>Error rate (%)</th><th>Mismatch (%)</th><th>Indel (%)</th><th>Haplotype coverage (%)</th><th>N50 (bp)</th><th>NGA50 (bp)</th><th>#Misassemblies</th></tr></thead><tbody><tr><td><bold>Ploidy</bold> <bold>=</bold> <bold>2</bold></td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>VeChat</td><td>30920</td><td>0.022</td><td>0.007</td><td>0.014</td><td>99.9</td><td>13,095</td><td>40,612</td><td>5</td></tr><tr><td>CONSENT</td><td>32661</td><td>0.212</td><td>0.160</td><td>0.052</td><td>99.9</td><td>13,040</td><td>40,903</td><td>37</td></tr><tr><td>Racon</td><td>31840</td><td>0.346</td><td>0.234</td><td>0.112</td><td>99.3</td><td>13,039</td><td>40,725</td><td>120</td></tr><tr><td>Canu</td><td>25506</td><td>0.390</td><td>0.206</td><td>0.183</td><td>100.0</td><td>13,820</td><td>40,846</td><td>6</td></tr><tr><td>Daccord</td><td>31438</td><td>0.438</td><td>0.410</td><td>0.027</td><td>99.2</td><td>12,987</td><td>40,730</td><td>3</td></tr><tr><td><bold>Ploidy</bold> <bold>=</bold> <bold>3</bold></td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>VeChat</td><td>45113</td><td>0.090</td><td>0.041</td><td>0.050</td><td>100.0</td><td>13,130</td><td>40,497</td><td>90</td></tr><tr><td>CONSENT</td><td>49826</td><td>0.298</td><td>0.221</td><td>0.077</td><td>99.9</td><td>13,037</td><td>40,877</td><td>103</td></tr><tr><td>Racon</td><td>48520</td><td>0.673</td><td>0.501</td><td>0.172</td><td>98.6</td><td>13,028</td><td>39,286</td><td>631</td></tr><tr><td>Canu</td><td>36962</td><td>0.748</td><td>0.453</td><td>0.295</td><td>99.9</td><td>14,141</td><td>40,605</td><td>59</td></tr><tr><td>Daccord</td><td>49033</td><td>0.821</td><td>0.751</td><td>0.069</td><td>99.7</td><td>12,712</td><td>39,193</td><td>11</td></tr><tr><td><bold>Ploidy</bold> <bold>=</bold> <bold>4</bold></td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>VeChat</td><td>58739</td><td>0.169</td><td>0.098</td><td>0.071</td><td>99.7</td><td>13,129</td><td>40,450</td><td>177</td></tr><tr><td>CONSENT</td><td>65384</td><td>0.292</td><td>0.195</td><td>0.097</td><td>100.0</td><td>13,033</td><td>40,864</td><td>121</td></tr><tr><td>Racon</td><td>63670</td><td>0.666</td><td>0.469</td><td>0.197</td><td>94.9</td><td>13,012</td><td>40,007</td><td>668</td></tr><tr><td>Daccord</td><td>65072</td><td>0.840</td><td>0.784</td><td>0.056</td><td>96.9</td><td>12,606</td><td>39,076</td><td>22</td></tr></tbody></table><table-wrap-foot><p>The average sequencing coverage per haplotype is 30× and sequencing error rate is 10%.</p></table-wrap-foot></table-wrap></p>
      <p id="Par22">Table <xref rid="Tab3" ref-type="table">3</xref> shows the error correction benchmarking results for simulated PacBio CLR reads of metagenomic datasets with different complexity. VeChat achieves approximately 6–7 and 3–4 times lower error rates on low and high complexity metagenomes, respectively, while maintaining comparable performance in terms of other aspects. In particular, VeChat outperforms other tools in terms of mismatch rate (6–12 times lower) quite substantially on the low-complexity dataset.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Error correction benchmarking results for simulated PacBio CLR reads of metagenomic datasets with different complexity</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>#Reads</th><th>Error rate (%)</th><th>Mismatch (%)</th><th>Indel (%)</th><th>Haplotype coverage (%)</th><th>N50 (bp)</th><th>NGA50 (bp)</th><th>#Misassemblies</th></tr></thead><tbody><tr><td><bold>Low complexity (20 genomes)</bold></td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>VeChat</td><td>293466</td><td>0.036</td><td>0.020</td><td>0.015</td><td>96.9</td><td>11,866</td><td>29,555</td><td>104</td></tr><tr><td>Racon</td><td>299053</td><td>0.200</td><td>0.122</td><td>0.078</td><td>91.7</td><td>11,811</td><td>29,514</td><td>794</td></tr><tr><td>CONSENT</td><td>299333</td><td>0.214</td><td>0.149</td><td>0.065</td><td>98.4</td><td>11,841</td><td>29,556</td><td>515</td></tr><tr><td>Canu</td><td>253381</td><td>0.259</td><td>0.134</td><td>0.125</td><td>97.4</td><td>12,370</td><td>29,457</td><td>139</td></tr><tr><td>Daccord</td><td>298284</td><td>0.259</td><td>0.243</td><td>0.016</td><td>92.8</td><td>11,862</td><td>29,595</td><td>280</td></tr><tr><td><bold>High complexity (100 genomes)</bold></td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>VeChat</td><td>1441190</td><td>0.088</td><td>0.061</td><td>0.026</td><td>97.5</td><td>11,886</td><td>30,129</td><td>2774</td></tr><tr><td>CONSENT</td><td>1497216</td><td>0.274</td><td>0.163</td><td>0.112</td><td>99.4</td><td>11,839</td><td>30,204</td><td>3263</td></tr><tr><td>Canu</td><td>1185152</td><td>0.354</td><td>0.192</td><td>0.162</td><td>99.0</td><td>12,706</td><td>30,016</td><td>873</td></tr><tr><td>Racon</td><td>–</td><td>–</td><td>–</td><td>–</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td>Daccord</td><td>–</td><td>–</td><td>–</td><td>–</td><td>–</td><td>–</td><td>–</td><td>–</td></tr></tbody></table><table-wrap-foot><p>The average sequencing coverage of strains is about 30x and the sequencing error rate is 10%. Racon and Daccord failed to run for high complexity dataset.</p></table-wrap-foot></table-wrap></p>
      <p id="Par23">Table <xref rid="Tab4" ref-type="table">4</xref> shows the error correction benchmarking results for real PacBio sequencing data (mock communities). The three sections of the table show results on the yeast pseudo-diploid genome dataset (mock community) first, the NWC metagenome dataset (real) second, and the Microbial 10-plex metagenome dataset (mock community) as the third section of rows in Table <xref rid="Tab4" ref-type="table">4</xref>. VeChat achieves approximately 2–4, 1.4–7.8 and 3.3–5.6 times lower error rates on Yeast, NWC and Microbial 10-plex datasets, respectively, while maintaining comparable performance in terms of other aspects.<table-wrap id="Tab4"><label>Table 4</label><caption><p>Error correction benchmarking results for real PacBio sequencing data (mock communities)</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>#Reads</th><th>Error rate (%)</th><th>Mismatch (%)</th><th>Indel (%)</th><th>Haplotype coverage (%)</th><th>N50 (bp)</th><th>NGA50 (bp)</th><th>#Misassemblies</th></tr></thead><tbody><tr><td><bold>Yeast pseudo-diploid genome</bold></td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>VeChat</td><td>107210</td><td>0.236</td><td>0.111</td><td>0.126</td><td>99.6</td><td>5693</td><td>15,537</td><td>505</td></tr><tr><td>Daccord</td><td>149020</td><td>0.503</td><td>0.285</td><td>0.217</td><td>96.5</td><td>4762</td><td>15,161</td><td>1457</td></tr><tr><td>Racon</td><td>136199</td><td>0.758</td><td>0.282</td><td>0.476</td><td>98.3</td><td>6349</td><td>16,001</td><td>3836</td></tr><tr><td>Canu</td><td>118367</td><td>0.787</td><td>0.214</td><td>0.573</td><td>99.9</td><td>5684</td><td>15,603</td><td>743</td></tr><tr><td>CONSENT</td><td>160136</td><td>0.947</td><td>0.344</td><td>0.603</td><td>99.4</td><td>5622</td><td>16,001</td><td>7973</td></tr><tr><td><bold>NWC metagenome</bold></td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>VeChat</td><td>156426</td><td>0.101</td><td>0.031</td><td>0.070</td><td>99.3</td><td>9619</td><td>27,416</td><td>14961</td></tr><tr><td>Daccord</td><td>163313</td><td>0.140</td><td>0.079</td><td>0.061</td><td>99.5</td><td>8461</td><td>26,343</td><td>12440</td></tr><tr><td>Racon</td><td>168879</td><td>0.394</td><td>0.062</td><td>0.332</td><td>99.5</td><td>9914</td><td>28,428</td><td>10832</td></tr><tr><td>Canu</td><td>37779</td><td>0.551</td><td>0.090</td><td>0.461</td><td>99.1</td><td>13811</td><td>27,729</td><td>4066</td></tr><tr><td>CONSENT</td><td>176764</td><td>0.787</td><td>0.107</td><td>0.680</td><td>99.7</td><td>9708</td><td>27,638</td><td>9731</td></tr><tr><td><bold>Microbial 10-plex metagenome</bold></td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>VeChat</td><td>245804</td><td>0.089</td><td>0.066</td><td>0.023</td><td>99.3</td><td>7837</td><td>17,511</td><td>1533</td></tr><tr><td>Racon</td><td>253817</td><td>0.297</td><td>0.160</td><td>0.137</td><td>97.8</td><td>8019</td><td>17,760</td><td>3724</td></tr><tr><td>Canu</td><td>193810</td><td>0.328</td><td>0.121</td><td>0.206</td><td>99.8</td><td>8477</td><td>17,824</td><td>1170</td></tr><tr><td>Daccord</td><td>254003</td><td>0.336</td><td>0.298</td><td>0.038</td><td>98.2</td><td>7704</td><td>17,342</td><td>2073</td></tr><tr><td>CONSENT</td><td>256935</td><td>0.495</td><td>0.107</td><td>0.388</td><td>100.0</td><td>8017</td><td>17,729</td><td>3470</td></tr></tbody></table></table-wrap></p>
      <p id="Par24">See Supplementary Table <xref rid="MOESM1" ref-type="media">1</xref> for error correction benchmarking experiments for real ONT sequencing data (non-synthetic), which have been evaluated using Merqury<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> because of the lack of reference genomes. Before discussing results, see Supplementary Table <xref rid="MOESM1" ref-type="media">2</xref>, which puts evaluations with and without a reference genome (QUAST resp. Merqury), that is, with and without available ground truth into context. Corresponding results immediately point out that Merqury is subject to substantial biases with respect to the choice of methods. For example, on ONT sequenced diploid genomes, Merqury underestimates the true error rates (as performed by QUAST relative to the ground truth) by factors of 4.33 (CONSENT) and even 11.84(!) (Daccord), but only by factors of 2.54 (Racon), 2.05 (Canu), and 1.75 (VeChat).</p>
      <p id="Par25">The quality of the results persists on the other datasets: Merqury evidently favors CONSENT and Daccord quite substantially in comparison with Racon, Canu and VeChat. Because Merqury is k-mer based, an immediate hypothesis is that Merqury tends to favor k-mer (e.g. de Bruijn graph) based approaches (CONSENT, Daccord) over approaches that do not make use of de Bruijn graphs (Racon, Canu and VeChat), where VeChat appears to be the only tool whose error rates are not substantially underestimated, at least on the lesser complex datasets. In summary, we have experienced that Merqury is affected by considerable volatility with respect to the methodological background of error correction tools, clearly favoring certain tools over others.</p>
      <p id="Par26">Therefore, the discussion of the following results are to be taken with the corresponding caution in terms of the method-specific biases that Merqury appears to induce.</p>
      <p id="Par27">As becomes obvious from Supplementary Table <xref rid="MOESM1" ref-type="media">1</xref>, VeChat achieves approximately 1.5 times lower error rate (QV) and 1.2 times lower switch error on HG002 compared with CONSENT (the only alternative tool available to compare), while loosing more haplotype coverage. Whereas on the human gut microbiome dataset, Daccord achieves the lowest error rate (QV) while VeChat obtains comparable read accuracy. VeChat achieves about 1.4 and 1.7 times lower error rates (QV) in comparison to CONSENT and Canu, respectively, while keeping comparable performance in terms of other aspects. (We recall that Daccord was the tool whose error rate was underestimated by the by far largest factors, which points out that, potentially, VeChat virtually achieves better error rates). As we mentioned earlier in the subsection ‘Metrics for evaluation’, the error rate (QV) ignores long-range switch errors in evaluation, which is unable to represent the overall error rate of reads. In fact, in simulated datasets of which the ground truth are known, we observed that VeChat achieves much lower switch error rate compared with others, and in both metagenome datasets VeChat achieves much lower overall error rate (from QUAST), even though its error rate (QV, from Merqury) is comparable with Daccord in the metagenome dataset of low complexity (see Supplementary Table <xref rid="MOESM1" ref-type="media">2</xref>). In summary, we speculate VeChat can achieve better performance in terms of overall error rate on the real human gut microbiome data.</p>
    </sec>
    <sec id="Sec5">
      <title>Varying read coverage</title>
      <p id="Par28">In order to evaluate how sequencing coverage influences the error correction approaches, we focused on the triploid genome, consisting of three E. coli strains as described before. We simulated PacBio CLR reads at varying sequencing coverage, namely, 10×, 20×, 30×, 40×, 50× per haplotype.</p>
      <p id="Par29">Supplementary Table <xref rid="MOESM1" ref-type="media">3</xref> shows the benchmarking results of error correction. In summary, VeChat achieves approximately 2–47 times lower error rates on all datasets, while maintaining better or comparable performance in terms of other aspects such as number of corrected reads, completeness (HC) and length of corrected reads. As the sequencing coverage increases (from 10× to 50×), VeChat achieves better error correction (error rate from 0.311% to 0.017%), while keeping comparable performance in terms of other aspects.</p>
      <p id="Par30">In addition, we particularly tested VeChat in the scenario of ultra-high sequencing coverage over a small genome. To reflect this context, we simulated a 5-strain HIV mixture (genome size ≈ 10 Kbp) dataset, which has been used for benchmarking experiments in many related studies, such as refs. <xref ref-type="bibr" rid="CR27">27</xref>, <xref ref-type="bibr" rid="CR33">33</xref>–<xref ref-type="bibr" rid="CR35">35</xref>. The average sequencing coverage per strain is about 1000×. See the Supplementary Table <xref rid="MOESM1" ref-type="media">4</xref> for the details about the data descriptions and the benchmarking results. The results show that VeChat outperforms others on the PacBio data in terms of error rate, whereas it achieves the second best performance on the Nanopore data. In summary, VeChat still works for the ultra-high sequencing coverage case, but is not necessarily very effective especially for ONT reads.</p>
    </sec>
    <sec id="Sec6">
      <title>Varying sequencing error rates</title>
      <p id="Par31">In order to evaluate the effect of sequencing error rate on the different methods, we again focused on the triploid genome consisting of three E. coli strains as described above. Accordingly, we simulated PacBio CLR reads at varying sequencing error rates, namely, at 5%, 10% and 15%. The average sequencing coverage per haplotype is 30x.</p>
      <p id="Par32">Supplementary Table <xref rid="MOESM1" ref-type="media">5</xref> shows the corresponding benchmarking results of error correction. Overall, VeChat achieves approximately 10–93, 9–26 and 7–9 times lower error rates on datasets with 5%, 10% and 15% errors, respectively, while maintaining comparable performance in terms of other aspects. On decreasing sequencing error rate (from 15% down to 5%), VeChat’s error correction undoubtedly improves with error rates dropping from 0.091% to 0.009%.</p>
    </sec>
    <sec id="Sec7">
      <title>Improving genome assembly</title>
      <p id="Par33">De novo genome assembly sticks out among the many possible applications that depend on sequencing reads in two ways. First, sequencing reads are its only input. Second, genome assembly seeks to reconstruct the very sequences from which the reads stem. In other words, arguably, de novo assembly is the primary application of genome sequencing.</p>
      <p id="Par34">It is therefore also of primary interest how correcting errors in reads influences the quality of de novo genome assemblies that build on the corrected reads.</p>
      <p id="Par35">To investigate related effects, we carried out some straightforward experiments, and ran (Hi)Canu<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR36">36</xref></sup> and (meta)Flye<sup><xref ref-type="bibr" rid="CR6">6</xref>,<xref ref-type="bibr" rid="CR37">37</xref></sup>, as the predominant long-read genome assemblers, with and without correcting reads using VeChat before. We did this on the datasets described earlier.</p>
      <p id="Par36">Before discussing results, note that the construction of pipelines that are optimized in terms of combining error correction and genome assembly approaches requires further investigation, which is beyond the scope of this manuscript. Here, we report the quick application “VeChat + Assembler” on various polyploid genome and metagenome datasets.</p>
      <p id="Par37">See Supplementary Tables <xref rid="MOESM1" ref-type="media">6–9</xref> for details on the following results. We evaluated genome assemblies in terms of various relevant aspects, again using Quast.</p>
      <p id="Par38">It becomes immediately evident that (Hi)Canu and (meta)Flye profit from VeChat corrected reads considerably. On the vast majority of datasets, greater haplotype coverage, longer contigs (N50/NGA50), lower error rates (especially mismatch rates) and fewer misassemblies are reported upon prior application of VeChat.</p>
      <p id="Par39">For example, in the diploid case (Supplementary Table <xref rid="MOESM1" ref-type="media">6</xref>), VeChat+HiCanu increases haplotype coverage (HC) by 7.6% over Canu, from 92% to 99.6%, which also implies that VeChat+HiCanu supports to reconstruct both haplotypes at nearly full length. N50/NGA50 is about 10 times greater for VeChat+HiCanu. Also, VeChat+HiCanu yield fewer number of misassemblies, and error rate is more than 90 times lower. The substantial improvements of VeChat+HiCanu persist when raising the ploidy. We note particularly that VeChat+HiCanu increase the haplotype coverage by 14% in tetraploid genomes, at remarkably enhanced alternative metrics as well. Moreover, VeChat+Flye substantially improves genome assemblies for the triploid and the tetraploid case, compared with Flye alone. Overall, this points out that one can use VeChat for substantially improving on polyploid genome assembly quality when working with state-of-the-art assemblers for long reads.</p>
    </sec>
    <sec id="Sec8">
      <title>Runtime and memory usage evaluation</title>
      <p id="Par40">The runtime of VeChat is dominated by three steps: while the computation of read overlaps (without base-level alignment) is fast, subsequent edit-distance-based alignment (for segmenting windows) is time-consuming. Second, the POA algorithm that drives the construction of the variation graphs performs sequence-to-graph alignment, which comes at computational complexity of <italic>O</italic>(<italic>N</italic>(2<italic>N</italic><sub><italic>p</italic></sub> + 1)∣<italic>V</italic>∣), where <italic>N</italic> is the length of the sequence to be aligned, <italic>N</italic><sub><italic>p</italic></sub> is the average number of predecessors in the graph and ∣<italic>V</italic>∣ is the number of vertices in the graph<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>. Third, VeChat follows an iterative paradigm, such as read overlap computation (with base-level alignment) and error correction (consensus generation) steps during the second iteration; this also requires a non-negligible amount of running time.</p>
      <p id="Par41">We performed most of benchmarking analyses on x86_64 GNU/Linux machines using 48 cores. The runtime and peak memory usage evaluations for different methods are reported in Supplementary Tables <xref rid="MOESM1" ref-type="media">10–13</xref>. VeChat takes 23–81 CPU hours and 8–92 CPU hours on simulated PacBio CLR and ONT reads from datasets reflecting varying ploidy (2, 3 or 4, as usual), which is 1.1–6.2 and 0.6–6.9 times slower than other methods. At the same time, it requires higher peak memory usages (Supplementary Tables <xref rid="MOESM1" ref-type="media">10</xref> and <xref rid="MOESM1" ref-type="media">11</xref>). VeChat is 2.4–7.1 times slower than other approaches on the simulated metagenomic dataset, and reaches higher peak memory usages (Supplementary Table <xref rid="MOESM1" ref-type="media">12</xref>). Note that the high complexity metagenomic dataset is too large to be processed by Racon and Daccord, whereas our approach is able to handle it. In addition, VeChat is 0.7 ~ 32 times slower on real sequencing datasets (mock communities), while requiring higher peak memory usages (Supplementary Table <xref rid="MOESM1" ref-type="media">13</xref>).</p>
    </sec>
  </sec>
  <sec id="Sec9" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par42">We have presented VeChat, as an approach that performs haplotype-aware error correction for third-generation sequencing (TGS) reads. To the best of our knowledge, VeChat is the first approach that explicitly addresses to preserve haplotype-specific variation already during the correction process. The methodical improvement over prior approaches has been to make use of graph-based instead of sequence-based reference systems, which avoids the typical consensus sequence-induced biases.</p>
    <p id="Par43">Results have demonstrated the superiority of VeChat: in all benchmarking scenarios, VeChat suppresses error rates by at least a factor of 1–3, if not, as is the case for the majority of scenarios, suppressing error rates by one or even two orders of magnitude in comparison with the leading competitive approaches. At the same time, VeChat preserves the haplotype identity of the reads, which means that after correction with VeChat, all reads contribute to the coverage of the haplotype they stemmed from. The most obvious interpretation of these results is that capturing haplotype structure already during error correction is not just beneficial, but perhaps even imperative, when seeking to remove all errors from TGS reads.</p>
    <p id="Par44">For appropriately capturing haplotype-specific variants during the error correction step, we construct variation graphs from the noisy TGS reads directly. Note that direct construction of variation graphs from heavily erroneous reads is not standard. In fact, at first glance, it is even counterintuitive, because the seminal idea of variation graphs is to be constructed from true haplotype-specific, sufficiently long patches of sequence. Here, patches of sequence contain up to even 15% of errors.</p>
    <p id="Par45">As a consequence, upon initial construction, the graphs contain a large amount of nodes and edges that reflect sequencing errors. For identifying spurious nodes and edges, one exploits that sequencing errors are randomly distributed, whereas variants tend to re-occur across different reads. In particular, edges that link spurious nodes (with true nodes or other spurious nodes) tend to be little covered by reads, because reads do not tend to share errors, whereas they do tend to share true variation. To systematically identify spurious edges as edges that are covered by too little reads, in a sound, principled way, we adopt two metrics from frequent itemset mining. While Support measures the relative coverage of edges in the graph, Confidence measures the association between the two nodes incident to the edge they share; if basic support or the association is too little, the edge and possibly resulting isolated nodes are removed.</p>
    <p id="Par46">A particular effect of VeChat is to achieve substantial improvements in terms of mismatch rates; improvements on indel rates are also evident in all scenarios, but usually a bit less substantial. One possible explanation is that substitution events, much more than insertion and deletion events, dominate the evolutionary processes of living organisms, and thus are often characteristic of strains or haplotypes. VeChat appears to be the first approach to correctly preserve these single nucleotide polymorphisms (SNPs), because the distinction of haplotypes is just what variation graphs are made for. At any rate, VeChat appears to prevent masking of true variants as a consequence of generating consensus sequence.</p>
    <p id="Par47">Further, we have demonstrated that correcting reads using VeChat prior to performing de novo genome assembly significantly enhanced the resulting assemblies. Obviously, and unsurprisingly, not mistaking haplotype specific variation as errors, and so preserving the haplotype identity of the reads results in assemblies that are considerably enhanced in terms of haplotype awareness. Particularly notably, correcting reads with VeChat enabled the application of HiCanu thereafter, as the best strategy evaluated here, which is interesting because HiCanu crucially relies on clean reads. Nevertheless, the exploration of optimal strategies and pipelines in terms of combining preprocessing, error correction and core assembly tools, relative to particular settings such as polyploid, cancer or metagenomes, still requires further efforts, which are beyond the scope of this study.</p>
    <p id="Par48">As for future perspectives, the rapid development of long-read sequencing technologies will lead to decreasing sequencing error rates. However, because the advantages of VeChat become even more evident when sequencing error rates drop, VeChat will also be a superior tool when correcting long reads in which errors appear at a rate of 5% or lower (see Supplementary Table <xref rid="MOESM1" ref-type="media">5</xref>).</p>
    <p id="Par49">Of course, future improvements are conceivable: in particular, although not requiring excessive amounts, VeChat does not win the competition in terms of computational resources. In particular on large datasets, VeChat experiences longer runtimes and higher peak memory usage. However, there is room for improving on that point. VeChat uses off-the-shelf approaches in some places, without making use of all features these off-the-shelf approaches provide. This amounts to unnecessary overheads when running these tools, which one can avoid by disintegrating approaches into their single functionalities and running them separately. In particular, there is good hope that computations such as edit-distance-based alignments, or the sequence-to-graph alignments, can be replaced by more efficient routines in the future.</p>
  </sec>
  <sec id="Sec10">
    <title>Methods</title>
    <sec id="Sec11">
      <title>Datasets</title>
      <p id="Par50">We made use of PBSIM2<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>, as a most recent tool to simulate PacBio CLR and Oxford Nanopore reads using built-in P6C4 and R103 model-based simulation profiles, respectively. Since the main application scenario of VeChat is to correct long-read sequencing data from multiple genomes, such as polyploid genomes and metagenomes, we simulated various datasets for both cases.</p>
      <p id="Par51">We constructed pseudo diploid (ploidy = 2, ANI: 98%), triploid (ploidy = 3, ANI: 96–98%) and tetraploid (ploidy = 4, ANI: 96–99%) genomes by mixing strains of <italic>Escherichia coli</italic> (<italic>E. coli</italic>) bacteria; note that Average Nucleotide Identity (ANI) is defined to measure the genome sequence similarity, which can be reported by FastANI<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>, for example. All genome sequences of E. coli were downloaded from the NCBI database (see Supplementary Data <xref rid="MOESM4" ref-type="media">1</xref> for the details of reference genomes). Reads were simulated from the haplotypes (i.e. strains) independently and upon generation mixed together to form the corresponding polyploid genome datasets (ploidy = 2,3,4). We simulated both PacBio CLR and Nanopore reads for these datasets, at average sequencing coverage of 30x per haplotype and average sequencing error rate of 10%.</p>
      <p id="Par52">Additionally, we used CAMISIM<sup><xref ref-type="bibr" rid="CR40">40</xref></sup> to simulate two metagenomic datasets (PacBio CLR reads) of different levels of complexity. Here, we used PBSIM2 to simulate PacBio CLR reads instead of the built-in simulator in CAMISIM. The low-complexity dataset consists of 10 species (20 strains), whereas the high complexity dataset consists of 30 species (100 strains). The genomes used in both datasets are derived from<sup><xref ref-type="bibr" rid="CR41">41</xref></sup> (see Supplementary Data <xref rid="MOESM4" ref-type="media">1</xref> for the details). For both datasets, the average sequencing coverage of strains is about 30x and the average sequencing error rate is 10%. The relative abundances of strains range from 1.9% to 10.6% and from 0.28% to 3.3%, respectively. The corresponding sequencing coverages over different strains range from 12.6× to 68.0× and from 11.0× to 126.9×, respectively; see Supplementary Data <xref rid="MOESM4" ref-type="media">2</xref> for information on coverage of the individual strains.</p>
      <p id="Par53">We constructed a pseudo-diploid genome by mixing two yeast strains (N44, CBS432) of ANI 98.4%, which are derived from <ext-link ext-link-type="uri" xlink:href="https://yjx1217.github.io/Yeast_PacBio_2016/data/">Yeast Population Reference Panel</ext-link> (see Supplementary Data <xref rid="MOESM4" ref-type="media">3</xref>). The corresponding real PacBio CLR reads were downloaded from European Nucleotide Archive (ENA) under project <ext-link ext-link-type="uri" xlink:href="https://www.ebi.ac.uk/ena/browser/view/PRJEB7245">PRJEB7245</ext-link>, and we subsampled long reads to match a sequencing coverage of 30× per strain for further analyses. This dataset we refer to as “Yeast pseudo-diploid genome”.</p>
      <p id="Par54">We downloaded two real metagenomic datasets (PacBio CLR reads) derived from natural whey starter cultures (NWCs)<sup><xref ref-type="bibr" rid="CR42">42</xref></sup> and mixed both together (see Supplementary Data <xref rid="MOESM4" ref-type="media">3</xref>), and then subsampled 20% reads such that we obtained a low-complexity metagenomic dataset, which contains 3 species (6 strains). This dataset we refer to “NWC metagenome”.</p>
      <p id="Par55">We downloaded raw long-read sequencing data and the corresponding reference genomes from a 10-plex multiplexed dataset which was sequenced by PacBio Sequel System, Chemistry v3.0. Then, we randomly subsampled 10% reads such that we obtained a mock metagenomic dataset with an average sequencing coverage about 40×, which contains 7 species (9 strains in all, ANI &lt; 98.5%, see Supplementary Data <xref rid="MOESM4" ref-type="media">3</xref>). This dataset we refer to “Microbial 10-plex metagenome”.</p>
      <p id="Par56">We downloaded the real whole genome sequencing data (Nanopore PromethION) of the human individual HG002 (diploid genome). Subsequently, we performed quality control using fastp<sup><xref ref-type="bibr" rid="CR43">43</xref></sup> and randomly subsampled 50% of the reads for further error correction. The average sequencing coverage per haplotype is about 8x.</p>
      <p id="Par57">We downloaded Nanopore reads of a real human gut microbiome sample from SRA database (accession number: <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra/?term=SRR8427258">SRR8427258</ext-link>) that was presented in the previous study<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>. The corresponding Illumina reads of the same sample (accession number: SRR6807561, SRR6788327) were also provided in another study<sup><xref ref-type="bibr" rid="CR45">45</xref></sup>. Therefore, we could use Illumina reads to evaluate correction performance without knowing the reference genomes (see below).</p>
    </sec>
    <sec id="Sec12">
      <title>Step 1: Read overlap calculation</title>
      <p id="Par58">Step 1 refers to computation of all-vs-all overlaps for the input reads (first cycle: raw reads, second cycle: pre-corrected reads) using the (widely popular) minimizer based, long-read overlap computation tool Minimap2<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. During the first cycle, only a seed-chain procedure is performed, while during the second cycle a base-level alignment is added. Because this is very fast, it can manage the large amount of read pairs we need to process easily. Subsequently, bad overlaps are filtered by reasonable, additional criteria, which includes removing overlaps that do not exceed 500 bp in length, self-overlaps, or internal matches. In this, we follow Algorithm 5 in ref. <xref ref-type="bibr" rid="CR46">46</xref> and its implementation in<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>. Additionally, overlaps that have a high error rate, that is <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$|1-\min ({L}_{q},{L}_{t})/\max ({L}_{q},{L}_{t})|\ge e$$\end{document}</tex-math><mml:math id="M2"><mml:mo>∣</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>min</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>max</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∣</mml:mo><mml:mo>≥</mml:mo><mml:mi>e</mml:mi></mml:math><inline-graphic xlink:href="41467_2022_34381_Article_IEq1.gif"/></alternatives></inline-formula>, where <italic>L</italic><sub><italic>q</italic></sub> and <italic>L</italic><sub><italic>t</italic></sub> are the lengths of the mapping in the query and the target reads, respectively, and <italic>e</italic> is the maximum error-rate threshold, are also filtered out<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>.</p>
      <p id="Par59">While during the second cycle, the similar procedures(overlap computation and filtration) are also performed but for pre-corrected reads. Unlike in the first cycle, we compute pre-corrected read overlaps with base-level alignment such that the sequence identity of overlaps (overlap identity) can be determined, and then filter overlaps with one more criterion, minimum overlap identity (denoted as <italic>δ</italic>, <italic>δ</italic> = 0.99 for simulated sequencing data and <italic>δ</italic> = 0.98 for real sequencing data). Notably, because most of sequencing errors have been corrected in the first cycle, the sequence identity distribution referring to read overlaps with reads from the same haplotype clearly differs from the sequence identity distribution on read overlaps where the two reads stem from different haplotypes. Therefore, it is straightforward to filter overlaps that refer to reads from different haplotypes: we filter out read overlaps of sequence identity &lt; <italic>δ</italic>, where the threshold <italic>δ</italic> is a parameter determined based on observations for the error rate of corrected reads after the first cycle. For example, we see that the error rate of corrected reads after the first cycle is basically less than 0.5% for simulated data. Therefore, we could say the error rate of read overlaps (assume two reads are from the same haplotype) is less than 0.5% × 2 = 1%, that is the overlap identity ≥<italic>δ</italic> = 1 − 1% = 0.99.</p>
    </sec>
    <sec id="Sec13">
      <title>Step 2: Read alignment pile generation</title>
      <p id="Par60">Our workflow then selects a target read <italic>r</italic> and, based on the overlaps computed in step 1, collects reads that overlap <italic>r</italic>. The target read <italic>r</italic> serves as a backbone, and for each overlap between read <italic>r</italic> and another read, a fast edit-distance-based alignment<sup><xref ref-type="bibr" rid="CR48">48</xref>,<xref ref-type="bibr" rid="CR49">49</xref></sup> is then performed, which generates a read alignment pile. The edit-distance-based alignment is only needed to split the read alignment pile into small windows in step 3. Dangling ends of reads that overlap the target read <italic>r</italic>, indicated by horizontal dotted lines in the original read alignment pile in Fig. <xref rid="Fig1" ref-type="fig">1</xref>, are removed from further consideration in the following. See<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> for more details.</p>
    </sec>
    <sec id="Sec14">
      <title>Step 3: Window segmentation</title>
      <p id="Par61">The read alignment pile is then divided into several small non-overlapping windows of identical length, with the target read serving as a reference: each such window covers 500 bp of the target read. Obviously, segmenting the read alignment pile reflects a straightforward procedure, because of the pairwise alignments of the target read with its overlapping reads served as the basis for read alignment pile construction, see Step 2<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. The part of the target read <italic>r</italic> corresponding with one particular window is further referred to as a ‘target subread’. This implies in particular that target subreads are 500 bp in length, apart from the rightmost window, where target subreads can be shorter.</p>
      <p id="Par62">The reason for segmenting the alignment piles into windows of small length is the great reduction in terms of computational burden in the following: the next step 4, as the technical core of our approach being concerned with variation graphs, greatly profits from this segmentation, both in terms of downsizing the original problem as well as in terms of enabling parallelization.</p>
    </sec>
    <sec id="Sec15">
      <title>Step 4: Error correction for target subreads</title>
      <p id="Par63">Step 4 reflects the methodical novelty of VeChat. Step 4 differs when comparing the first with the second cycle, see Fig. <xref rid="Fig2" ref-type="fig">2</xref> for the first and Fig. <xref rid="Fig3" ref-type="fig">3</xref> for the second cycle. Step 4 of the first cycle is considerably more involved, because it reflects the crucial statistical considerations through which to identify sequencing errors. The core idea that underlies these crucial statistical considerations is that true variants are significantly likely to co-occur across different reads, whereas occurrence of errors is random. Correspondingly, the following arguments make sense.</p>
      <p id="Par64">Thanks to dividing reads into subreads, the corresponding computations, such as variation graph construction and statistical evaluation of edges relative to read coverage, can be parallelized across subreads, which speeds up computations substantially.</p>
      <sec id="Sec16">
        <title>Variation graph construction</title>
        <p id="Par65">The subsequences in a window we refer to as subreads, are subsequently used to construct a variation graph <italic>G</italic> = (<italic>V</italic>, <italic>E</italic>, <italic>P</italic>). This variation graph is a directed acyclic graph (DAG), where vertices <italic>v</italic> ∈ <italic>V</italic> represent nucleotides (A, T, C, G), edges (<italic>v</italic><sub><italic>i</italic></sub>, <italic>v</italic><sub><italic>j</italic></sub>) ∈ <italic>E</italic> indicate that the nucleotides represented by nodes <italic>v</italic><sub><italic>i</italic></sub> and <italic>v</italic><sub><italic>j</italic></sub> have appeared as a two-letter subsequence in one of the reads from which the graph was constructed, relative to that particular position with respect to the read alignment pile. So, for example, if <italic>v</italic><sub><italic>i</italic></sub> and <italic>v</italic><sub><italic>j</italic></sub> correspond to <italic>A</italic> and <italic>G</italic>, respectively, exactly the reads that relative to the coordinates implied by the target read show <italic>A</italic><italic>G</italic> at that particular position induce an edge (<italic>v</italic><sub><italic>i</italic></sub>, <italic>v</italic><sub><italic>j</italic></sub>). Correspondingly, reads can be identified as certain paths <italic>P</italic> = (<italic>v</italic><sub>1</sub>, …, <italic>v</italic><sub><italic>l</italic></sub>) in the variation graph. For variation graph construction, we use the partial order alignment (POA) algorithm<sup><xref ref-type="bibr" rid="CR30">30</xref></sup> and its faster version, enhanced by SIMD vectorization, as described in<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>.</p>
      </sec>
      <sec id="Sec17">
        <title>Pruning: Principle</title>
        <p id="Par66">In the following, we will use the notation <italic>v</italic> ∈ <italic>V</italic> to also indicate the letter from the alphabet {<italic>A</italic>, <italic>C</italic>, <italic>G</italic>, <italic>T</italic>} a particular node <italic>v</italic> refers to, recalling that each node corresponds to exactly one nucleotide in the variation graphs we work with in the following.</p>
        <p id="Par67">The high error rate affecting TGS reads and the possible bias introduced by constructing the graph (because, for example, the order relative to which reads are considered has an influence), the variation graph constructed in the first cycle contains many spurious vertices and edges. For pruning the graph from mistaken edges and/or nodes (vertices), we adopt techniques from frequent itemset mining. The basic idea is to identify edges with itemsets, and to prune edges from the graph if the corresponding itemsets do not appear to be sufficiently frequent. After removal of edges, reads are realigned against the resulting graph, such that itemset counts have to be re-computed. This may render more edges to correspond to itemsets that are not sufficiently frequent. The cycle of identifying edges as infrequent itemsets, removing them, and re-aligning reads is repeated until convergence, that is, until no further edges are identified as spurious. In practice, we determined 3 as an appropriate number of iterations for our experiments. Note that for re-aligning reads against the modified graph, we make use of the POA algorithm, without, however, re-modifying the graph anymore.</p>
        <p id="Par68">The model that underlies the mining of frequent itemsets is the “market-basket model”. Baskets correspond to sets of items, and frequent itemsets correspond to subsets of items that appear in sufficiently many baskets, or, vice versa, infrequent itemsets correspond to subsets of items that do not appear in sufficiently many baskets.</p>
        <p id="Par69">Following this model, the basic set of items agrees with the set of nodes <italic>V</italic> in the variation graph. Baskets then correspond to reads, which are modeled as paths <italic>P</italic> = (<italic>v</italic><sub>1</sub>, …, <italic>v</italic><sub><italic>l</italic></sub>), and the items they contain correspond to the nodes <italic>v</italic><sub>1</sub>, …, <italic>v</italic><sub><italic>l</italic></sub> ∈ <italic>V</italic> the reads cover. Further, the itemsets we are interested in correspond to edges <italic>e</italic> = (<italic>v</italic>, <italic>w</italic>), as pairs of items <italic>v</italic>, <italic>w</italic>. If two nodes <italic>v</italic>, <italic>w</italic> that are connected by an edge <italic>e</italic> = (<italic>v</italic>, <italic>w</italic>), as particular subsets of items, do not appear in sufficiently many baskets, that is, the corresponding edge <italic>e</italic> = (<italic>v</italic>, <italic>w</italic>) is not contained in sufficiently many read induced paths <italic>P</italic>, the corresponding edge is removed from the graph.</p>
        <p id="Par70">For appropriately quantifying “sufficiently many baskets”, we make further use of Support and Confidence as two standard definitions from frequent itemset mining. “Support” just corresponds to the number of baskets a particular subset of items is contained in. Here, Support just agrees with the number of reads by which a particular edge <italic>e</italic> = (<italic>v</italic>, <italic>w</italic>) is covered. “Confidence”, on the other hand, corresponds to measuring whether appearance of items in a basket is correlated with other items appearing in that basket. Here, Confidence corresponds to the amount of reads that cover the edge (<italic>v</italic>, <italic>w</italic>) in relation to how many reads cover <italic>v</italic>, on the one hand, and in relation to how many reads cover <italic>w</italic>, on the other hand. If neither sufficiently many reads that cover <italic>v</italic> also cover (<italic>v</italic>, <italic>w</italic>), nor sufficiently many reads that cover <italic>w</italic> also cover (<italic>v</italic>, <italic>w</italic>), we “loose confidence” in <italic>e</italic> = (<italic>v</italic>, <italic>w</italic>), because the edge (<italic>v</italic>, <italic>w</italic>) could reflect sequencing error noise.</p>
      </sec>
      <sec id="Sec18">
        <title>Pruning: definitions</title>
        <p id="Par71">To make the ideas from above explicit, let <italic>R</italic>(<italic>v</italic>) be all reads that cover node <italic>v</italic>. For <italic>r</italic> ∈ <italic>R</italic>(<italic>v</italic>), let further <italic>p</italic><sub><italic>r</italic>,<italic>v</italic></sub> reflect the probability that <italic>v</italic> reflects an error in <italic>r</italic>. When dealing with FASTQ files, the probability <italic>p</italic><sub><italic>r</italic>,<italic>v</italic></sub> is derived from the Phred profile of <italic>r</italic>. In case of FASTA files, <italic>p</italic><sub><italic>r</italic>,<italic>v</italic></sub> is taken as zero.</p>
        <p id="Par72">We now would like to determine <italic>w</italic>(<italic>v</italic>), as a weight for node <italic>v</italic> that reflects the expected number of reads that cover it. Note that for FASTA files, <italic>w</italic>(<italic>v</italic>) just agrees with the number of reads that cover <italic>v</italic>. For FASTQ files, <italic>w</italic>(<italic>v</italic>) corresponds to summing up 1 − <italic>p</italic><sub><italic>r</italic>,<italic>v</italic></sub> across all reads <italic>r</italic> ∈ <italic>R</italic>(<italic>v</italic>), as the sum of the probabilities that the reads <italic>r</italic> ∈ <italic>R</italic>(<italic>v</italic>) indeed reflect the letter associated with <italic>v</italic>. In terms of formulas, we obtain<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w(v):=\left\{\begin{array}{ll}{\sum }_{r\in R(v)}1\hfill\quad &amp;{{{{{{{\rm{for}}}}}}}}\,{{{{{{{\rm{FASTA}}}}}}}}\,{{{{{{{\rm{files}}}}}}}}\\ {\sum }_{r\in R(v)}1-{p}_{r,v}\quad &amp;{{{{{{{\rm{for}}}}}}}}\,{{{{{{{\rm{FASTQ}}}}}}}}\,{{{{{{{\rm{files}}}}}}}}\end{array}\right.$$\end{document}</tex-math><mml:math id="M4"><mml:mi>w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>∈</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mi mathvariant="normal">for</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">FASTA</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">files</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>∈</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd columnalign="left"><mml:mi mathvariant="normal">for</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">FASTQ</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">files</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="41467_2022_34381_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula></p>
        <p id="Par73">For an edge <italic>e</italic> = (<italic>v</italic><sub><italic>i</italic></sub>, <italic>v</italic><sub><italic>j</italic></sub>), let <italic>R</italic>(<italic>v</italic><sub><italic>i</italic></sub>, <italic>v</italic><sub><italic>j</italic></sub>) be all reads that cover edge <italic>e</italic>. We further determine<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w(e)=w({v}_{i},{v}_{j}):=\frac{1}{2}\mathop{\sum}\limits_{r\in R({v}_{i},{v}_{j})}w({v}_{i})+w({v}_{j})$$\end{document}</tex-math><mml:math id="M6"><mml:mi>w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>∈</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:mi>w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic xlink:href="41467_2022_34381_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>as an approximation for the expected amount of reads that cover <italic>e</italic> = (<italic>v</italic><sub><italic>i</italic></sub>, <italic>v</italic><sub><italic>j</italic></sub>). Note that <italic>w</italic>(<italic>e</italic>) corresponds to exactly the amount of reads that cover <italic>e</italic> for FASTA files. For FASTQ files, the expected amount of reads that cover (<italic>v</italic><sub><italic>i</italic></sub>, <italic>v</italic><sub><italic>j</italic></sub>) virtually corresponds to the sum of products <inline-formula id="IEq2"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(1-{p}_{r,{v}_{i}})(1-{p}_{r,{v}_{j}})=1-{p}_{r,{v}_{i}}-{p}_{r,{v}_{j}}+{p}_{r,{v}_{i}}{p}_{r,{v}_{j}}$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_34381_Article_IEq2.gif"/></alternatives></inline-formula> (*) across <italic>r</italic> ∈ <italic>R</italic>(<italic>v</italic><sub><italic>i</italic></sub>) ∩ <italic>R</italic>(<italic>v</italic><sub><italic>j</italic></sub>). Here, for speeding up computations, we opt for approximating (*) by <inline-formula id="IEq3"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1-\frac{1}{2}{p}_{r,{v}_{i}}-\frac{1}{2}{p}_{r,{v}_{j}}$$\end{document}</tex-math><mml:math id="M10"><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_34381_Article_IEq3.gif"/></alternatives></inline-formula>, which reflects (<xref rid="Equ2" ref-type="">2</xref>). Since this agrees with (*) in terms of orders of magnitude, this introduces only negligible deviations from the true values; experiments of ours confirmed that the gain in speed offset the loss in precision on that account.</p>
        <p id="Par74">Based on these weights, we now define the two metrics Support and Confidence. See also Fig. <xref rid="Fig4" ref-type="fig">4</xref> for an illustration of the relevant definitions. In formal detail, let <italic>e</italic> = (<italic>v</italic><sub><italic>i</italic></sub>, <italic>v</italic><sub><italic>j</italic></sub>) be an edge. Let then Support of <italic>e</italic> be defined as<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\mbox{Support}}}\,(e):=w(e)$$\end{document}</tex-math><mml:math id="M12"><mml:mstyle><mml:mtext>Support</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mi>w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic xlink:href="41467_2022_34381_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>that is, just as the weight of <italic>e</italic>. Further, note that Confidence is an asymmetrical measure: the probability to observe <italic>v</italic><sub><italic>j</italic></sub> in a read that contains <italic>v</italic><sub><italic>i</italic></sub> may disagree with the probability to observe <italic>v</italic><sub><italic>i</italic></sub> in a read that contains <italic>v</italic><sub><italic>j</italic></sub>. We take this into account by defining<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\mbox{Confidence}}}\,({v}_{i},{v}_{j}):=\,{{\mbox{Confidence}}}\,({v}_{i}\to \{{v}_{i},{v}_{j}\}):=\frac{w({v}_{i},{v}_{j})}{{\sum }_{{v}_{k^{\prime} }\in S({v}_{i})}w({v}_{i},{v}_{k^{\prime} })}$$\end{document}</tex-math><mml:math id="M14"><mml:mstyle><mml:mtext>Confidence</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>Confidence</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>→</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>S</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41467_2022_34381_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>on the one hand, and<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\mbox{Confidence}}}\,({v}_{j},{v}_{i}):=\,{{\mbox{Confidence}}}\,({v}_{j}\to \{{v}_{i},{v}_{j}\}):=\frac{w({v}_{i},{v}_{j})}{\mathop{\sum }\nolimits_{{v}_{k}\in P({v}_{j})}^{}w({v}_{k},{v}_{j})}$$\end{document}</tex-math><mml:math id="M16"><mml:mstyle><mml:mtext>Confidence</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>Confidence</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>→</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow/></mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41467_2022_34381_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>on the other hand, where <italic>S</italic>(<italic>v</italic><sub><italic>i</italic></sub>) and <italic>P</italic>(<italic>v</italic><sub><italic>j</italic></sub>) denote the vertices that succeed <italic>v</italic><sub><italic>i</italic></sub> and precede <italic>v</italic><sub><italic>j</italic></sub>, respectively (and where <italic>v</italic><sub><italic>i</italic></sub> → {<italic>v</italic><sub><italic>j</italic></sub>, <italic>v</italic><sub><italic>j</italic></sub>} and <italic>v</italic><sub><italic>j</italic></sub> → {<italic>v</italic><sub><italic>i</italic></sub>, <italic>v</italic><sub><italic>j</italic></sub>} agree with standard notation from association rule mining). We eventually declare<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\mbox{Confidence}}}\,(e):=\max \{{{\mbox{Confidence}}}\,({v}_{i},{v}_{j}),\,{{\mbox{Confidence}}}\,({v}_{j},{v}_{i})\}$$\end{document}</tex-math><mml:math id="M18"><mml:mstyle><mml:mtext>Confidence</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mi>max</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mstyle><mml:mtext>Confidence</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>Confidence</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math><graphic xlink:href="41467_2022_34381_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>as the overall Confidence in <italic>e</italic> = (<italic>v</italic><sub><italic>i</italic></sub>, <italic>v</italic><sub><italic>j</italic></sub>).<fig id="Fig4"><label>Fig. 4</label><caption><title>A schematic diagram for explaining the calculation of Support and Confidence for edge (<italic>v</italic><sub><italic>i</italic></sub>, <italic>v</italic><sub><italic>j</italic></sub>).</title><p><italic>w</italic>(<italic>v</italic><sub><italic>i</italic></sub>, <italic>v</italic><sub><italic>j</italic></sub>) is the approximation for the expected amount of reads that cover edge (<italic>v</italic><sub><italic>i</italic></sub>, <italic>v</italic><sub><italic>j</italic></sub>). <italic>S</italic>(<italic>v</italic><sub><italic>i</italic></sub>) and <italic>P</italic>(<italic>v</italic><sub><italic>j</italic></sub>) denote the vertices that succeed <italic>v</italic><sub><italic>i</italic></sub> and precede <italic>v</italic><sub><italic>j</italic></sub>, respectively. In this directed graph, <inline-formula id="IEq4"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{j},{v}_{k^{\prime} }$$\end{document}</tex-math><mml:math id="M20"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_34381_Article_IEq4.gif"/></alternatives></inline-formula> are the successors of <italic>v</italic><sub><italic>i</italic></sub>, whereas <italic>v</italic><sub><italic>i</italic></sub>, <italic>v</italic><sub><italic>k</italic></sub> are the predecessors of <italic>v</italic><sub><italic>i</italic></sub>.</p></caption><graphic xlink:href="41467_2022_34381_Fig4_HTML" id="d32e4466"/></fig></p>
        <p id="Par75">It remains to determine appropriate thresholds <italic>s</italic> and <italic>c</italic>, such that edges <italic>e</italic> for which either Support(<italic>e</italic>) &lt; <italic>s</italic> or Confidence(<italic>e</italic>) &lt; <italic>c</italic> are pruned from the graph. Note that by its definition, Confidence reflects the probability that a read that covers <italic>v</italic><sub><italic>i</italic></sub> also covers <italic>v</italic><sub><italic>j</italic></sub>, or vice versa. We determined <italic>c</italic> = 0.2 as an appropriate threshold in experiments; see the Supplementary Figure <xref rid="Fig1" ref-type="fig">1</xref> for the corresponding outcome.</p>
        <p id="Par76">Support, however, does not reflect a probability. Depending on the overall amount of reads in a subwindow, and the length of a subwindow—that is virtually depending on the average read coverage of a subwindow—the Support needs to be appropriately scaled. Therefore, consider that <italic>C</italic> ≔ ∑<sub><italic>v</italic>∈<italic>V</italic></sub>
<italic>w</italic>(<italic>v</italic>)/<italic>L</italic> is the average coverage of a position in the subwindow. Accordingly, we determine <italic>s</italic> ≔ 0.2 × <italic>C</italic> as a threshold that takes subwindow specific coverage into appropriate account.</p>
        <p id="Par77">Note eventually that both Support and Confidence are required for effective pruning of the graph, see Supplementary Figure <xref rid="Fig2" ref-type="fig">2</xref> for the correlation between the two quantities.</p>
      </sec>
      <sec id="Sec19">
        <title>Optimal alignment path extraction</title>
        <p id="Par78">Upon convergence of the pruning algorithm, the target subread that corresponds to a small window is realigned against the fully pruned variation graph that results from the last iteration of the pruning algorithm. The path in the graph that corresponds to the optimal alignment of the target subread is then taken as the pre-corrected target subread; see the orange elements in Fig. <xref rid="Fig2" ref-type="fig">2</xref> for an illustration.</p>
      </sec>
    </sec>
    <sec id="Sec20">
      <title>Step 5: Concatenation</title>
      <p id="Par79">In this step, pre-corrected target subreads are concatenated to a whole, pre-corrected target read, which corresponds to the obvious, straightforward idea of “patching together” pre-corrected target subreads; see “5. Concatenation” in Fig. <xref rid="Fig1" ref-type="fig">1</xref> for an illustration.</p>
    </sec>
    <sec id="Sec21">
      <title>Step 6: Merging corrected target reads</title>
      <p id="Par80">Steps 2–5 are repeated until all reads have been corrected. Step 6 then reflects a simple operation: the overall set of pre-corrected reads that result from the repeated execution of steps 2–5 steps are merged and taken as input for the second cycle.</p>
    </sec>
    <sec id="Sec22">
      <title>Second cycle: Modifications Step 1 and 4</title>
      <p id="Par81">Note that the pre-corrected reads generated by way of cycle 1 still contain a small, but yet non-negligible amount of random errors (see Supplementary Table <xref rid="MOESM1" ref-type="media">14</xref>). Cycle 2 addresses to correct these remaining errors. To do so, steps 1–6 are repeated with, however, some crucial modifications in steps 1 and 4. See the blue elements in Fig. <xref rid="Fig1" ref-type="fig">1</xref> for the workflow that reflects the procedures of cycle 2. To be specific, the modification of step 1 consists in not only computing all-vs-all overlaps based on minimizers, but also base-level alignments<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> for the pre-corrected reads. This considerably facilitates to filter reads overlaps according to which they stem from identical haplotypes, based on sequence identity related thresholds. We use <italic>δ</italic> = 0.99 for sequencing error rates of 5–10% and <italic>δ</italic> = 0.98 for a sequencing error rate of 15% in our experiments, which we also generally recommend.</p>
      <p id="Par82">The modification of step 4 then relates to generating a single sequence from each variation graph, instead of performing iterative graph pruning and sequence-to-graph re-alignment. For that, the dynamic programming algorithm referred to as “heaviest bundle algorithm” in ref. <xref ref-type="bibr" rid="CR31">31</xref>, as indicated in Fig. <xref rid="Fig3" ref-type="fig">3</xref> is used. Note that generating a single sequence from each of the local variation graphs is reasonable in the second cycle, because the overlapping reads used to correct the target read can already be assumed to stem from the same haplotype. Finally, we obtain fully error-corrected reads as the output of the second cycle; see “All final corrected reads (cycle2)” in Fig. <xref rid="Fig1" ref-type="fig">1</xref>.</p>
    </sec>
    <sec id="Sec23">
      <title>Benchmarking: alternative approaches</title>
      <p id="Par83">To enable a fair and meaningful comparison, we considered all popular state-of-the-art tools that perform TGS read self-correction. Namely, this selection includes Racon (v1.4.13)<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, CONSENT (v2.2.2)<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>, Canu (v2.1.1)<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> and Daccord (v0.0.18)<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. We ran all tools using their default parameters (command details are provided in the Supplementary Methods).</p>
      <p id="Par84">Apart from just evaluating error correction, we were also interested in the effects when using the corrected reads for genome assembly, as the prior, canonical area of application for corrected reads. Therefore, we considered Canu (v2.1.1) and (meta)Flye (v2.8.2), which can perform haplotype-aware assembly or metagenome assembly, as well-known assemblers, with or without prior error correction by VeChat. Also, because the corrected reads have error rates of less than 1%, one can run HiCanu (Canu in HiFi mode, which applies for the given error rates) on the reads, which we included into our considerations.</p>
    </sec>
    <sec id="Sec24">
      <title>Metrics for evaluation</title>
      <p id="Par85">We evaluated genome assembly performance by means of several commonly used metrics, as reported by QUAST V5.1.0<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>. See below for specific explanations, and see <ext-link ext-link-type="uri" xlink:href="http://quast.sourceforge.net/docs/manual.html">http://quast.sourceforge.net/docs/manual.html</ext-link>for full details. Note that the principled qualities of error-corrected long reads are covered by standard QUAST criteria as well; for example, low haplotype coverage reflects that true variants were mistakenly identified as errors, while error rates and misassemblies reflect that the correction procedure overlooked errors, or even confounded reads in terms of their origin through mistaken correction. As usual, corrected reads and contigs of length less than 500 bp were filtered from the output before evaluation. Note that we ran QUAST with the option –ambiguity-usage one, which appropriately takes into account that our datasets reflect mixed samples (such as polyploid genomes or metagenomes). In addition, for evaluating the real human genome (HG002) and human gut microbiome data, there is no ground truth of the reference genomes. Hence, we applied Merqury<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> to evaluate results based on auxiliary Illumina sequencing reads, in a reference-free manner.</p>
      <p id="Par86">Error rate (ER). The error rate is equal to the sum of mismatch rate and indel rate when mapping the obtained corrected reads or contigs to the reference haplotype sequences. When reference genomes are unknown, consensus quality value (QV) and switch error rate reported from Merqury are used as alternative metrics of approved usefulness<sup><xref ref-type="bibr" rid="CR21">21</xref>,<xref ref-type="bibr" rid="CR51">51</xref>,<xref ref-type="bibr" rid="CR52">52</xref></sup>. Note that the QV metric mainly reflects the base quality but does not consider long-range switch errors because it relies on short k-mer strategies (k = 21 by default).</p>
      <p id="Par87">Haplotype coverage (HC). Haplotype coverage is the percentage of aligned bases in the ground truth haplotypes covered by corrected reads or contigs, which is used to measure the completeness of the assembled contigs or the corrected reads. The k-mer completeness from Merqury is also used as an alternative metric when performing reference-free evaluation.</p>
      <p id="Par88">N50 and NGA50. N50 is defined as the length for which the collection of all corrected reads/contigs of that length or longer covers at least half the given sequences. NGA50 is similar to N50 but can only be calculated when the reference genome is provided. NGA50 only considers the aligned blocks (after breaking reads/contigs at misassembly events and trimming all unaligned nucleotides), which is defined as the length for which the overall size of all aligned blocks of this length or longer equals at least half of the reference haplotypes. Both N50 and NGA50 are used to assess the length distribution of corrected reads and the contiguity of the assemblies. Note that this may be of relatively little interest for corrected reads. We nevertheless display corresponding results because error correction does have an influence on these statistics.</p>
      <p id="Par89">Number of misassemblies (#Misassemblies). The misassembly event in corrected reads or assemblies indicates that left and right flanking sequences align to the true haplotypes with a gap or overlap of more than 1kbp, or align to different strands, or even align to different haplotypes or strains. Here, we report the total number of misassemblies in the given sequence data.</p>
    </sec>
    <sec id="Sec25">
      <title>Reporting summary</title>
      <p id="Par90">Further information on research design is available in the <xref rid="MOESM5" ref-type="media">Nature Portfolio Reporting Summary</xref> linked to this article.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec26">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="41467_2022_34381_MOESM1_ESM.pdf">
            <caption>
              <p>Supplementary Information</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="41467_2022_34381_MOESM2_ESM.pdf">
            <caption>
              <p>Peer Review File</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="41467_2022_34381_MOESM3_ESM.pdf">
            <caption>
              <p>Description of Additional Supplementary Files</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM4">
          <media xlink:href="41467_2022_34381_MOESM4_ESM.xlsx">
            <caption>
              <p>Supplementary Data 1-3</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM5">
          <media xlink:href="41467_2022_34381_MOESM5_ESM.pdf">
            <caption>
              <p>Reporting Summary</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p>The online version contains supplementary material available at 10.1038/s41467-022-34381-8.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>X.L. and X.K. were supported by the Chinese Scholarship Council. A.S. was supported by the Dutch Scientific Organization, through Vidi grant 639.072.309 during the early stages of the project, and from the European Union’s Horizon 2020 research and innovation program under Marie Skłodowska-Curie grant agreements No 956229 (ALPACA) and No 872539 (PANGAIA).</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>X.L. and A.S. developed the method. X.L. implemented the software and conducted the data analysis. X.K. simulated the metagenomic datasets. X.L. and A.S. wrote the manuscript. All authors read and approved the final version of the manuscript.</p>
  </notes>
  <notes notes-type="peer-review">
    <title>Peer review</title>
    <sec id="FPar1">
      <title>Peer review information</title>
      <p id="Par91"><italic>Nature Communications</italic> thanks Erik Garrison and Leena Salmela for their contribution to the peer review of this work. <xref rid="MOESM2" ref-type="media">Peer reviewer reports</xref> are available.</p>
    </sec>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>Open Access funding enabled and organized by Projekt DEAL.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>The authors declare that all of the datasets used in this paper are publicly available. The simulated and real (including Yeast pseudo-diploid genome and NWC metagenome data) long-read raw sequencing data used for benchmarking experiments are publicly available in Zenodo under 10.5281/zenodo.5501454 (10.5281/zenodo.5501455)<sup><xref ref-type="bibr" rid="CR53">53</xref></sup>. The real sequencing data of Microbial 10-plex metagenome was downloaded from <ext-link ext-link-type="uri" xlink:href="https://downloads.pacbcloud.com/public/dataset/microbial_multiplex_dataset_release_SMRT_Link_v6.0.0_with_Express_2.0/">https://downloads.pacbcloud.com/public/dataset/microbial_multiplex_dataset_release_SMRT_Link_v6.0.0_with_Express_2.0/</ext-link>. The real whole genome sequencing data of human individual HG002 (diploid genome) was downloaded from <ext-link ext-link-type="uri" xlink:href="https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/nanopore/downsampled/standard_unsheared/HG002_ucsc_Jan_2019_Guppy_3.4.4.fastq.gz">https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/nanopore/downsampled/standard_unsheared/HG002_ucsc_Jan_2019_Guppy_3.4.4.fastq.gz</ext-link>. The Nanopore reads<sup><xref ref-type="bibr" rid="CR44">44</xref></sup> of the real human gut microbiome sample were downloaded from SRA database under accession number: SRR8427258 (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra/?term=SRR8427258">https://www.ncbi.nlm.nih.gov/sra/?term=SRR8427258</ext-link>), and the corresponding Illumina reads of the same sample<sup><xref ref-type="bibr" rid="CR45">45</xref></sup> were from accession numbers (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra/SRX3765823">https://www.ncbi.nlm.nih.gov/sra/SRX3765823</ext-link>): SRR6807561, SRR6788327. Genome descriptions of simulated sequencing datasets are shown in Supplementary Data <xref rid="MOESM4" ref-type="media">1</xref>. Sequencing coverage information is shown in Supplementary Data <xref rid="MOESM4" ref-type="media">2</xref>. Genome descriptions of real sequencing datasets are shown in Supplementary Data <xref rid="MOESM4" ref-type="media">3</xref>. Raw data for drawing Supplementary Fig. <xref rid="MOESM1" ref-type="media">1 and 2</xref> are provided with this paper and are available in Zenodo under 10.5281/zenodo.7239028 (10.5281/zenodo.7239028).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Code availability</title>
    <p>The source code of VeChat is GPL-3.0 licensed, and publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/HaploKit/vechat">https://github.com/HaploKit/vechat</ext-link>. The results presented in this study can be reproduced from Code Ocean under DOI: 10.24433/CO.2329278.v2 (<ext-link ext-link-type="uri" xlink:href="https://codeocean.com/capsule/7010505/tree/v2">https://codeocean.com/capsule/7010505/tree/v2</ext-link>)<sup><xref ref-type="bibr" rid="CR54">54</xref></sup>.</p>
  </notes>
  <notes id="FPar2" notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par92">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Logsdon</surname>
            <given-names>GA</given-names>
          </name>
          <name>
            <surname>Vollger</surname>
            <given-names>MR</given-names>
          </name>
          <name>
            <surname>Eichler</surname>
            <given-names>EE</given-names>
          </name>
        </person-group>
        <article-title>Long-read human genome sequencing and its applications</article-title>
        <source>Nat. Rev. Genet.</source>
        <year>2020</year>
        <volume>21</volume>
        <fpage>597</fpage>
        <lpage>614</lpage>
        <?supplied-pmid 32504078?>
        <pub-id pub-id-type="pmid">32504078</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schrinner</surname>
            <given-names>SD</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Haplotype threading: accurate polyploid phasing from long reads</article-title>
        <source>Genome Biol.</source>
        <year>2020</year>
        <volume>21</volume>
        <fpage>1</fpage>
        <lpage>22</lpage>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jain</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Nanopore sequencing and assembly of a human genome with ultra-long reads</article-title>
        <source>Nat. Biotechnol.</source>
        <year>2018</year>
        <volume>36</volume>
        <fpage>338</fpage>
        <lpage>345</lpage>
        <?supplied-pmid 29431738?>
        <pub-id pub-id-type="pmid">29431738</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ruan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Fast and accurate long-read assembly with wtdbg2</article-title>
        <source>Nat. Methods</source>
        <year>2020</year>
        <volume>17</volume>
        <fpage>155</fpage>
        <lpage>158</lpage>
        <?supplied-pmid 31819265?>
        <pub-id pub-id-type="pmid">31819265</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shafin</surname>
            <given-names>k</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Nanopore sequencing and the shasta toolkit enable efficient de novo assembly of eleven human genomes</article-title>
        <source>Nat. Biotechnol.</source>
        <year>2020</year>
        <volume>38</volume>
        <fpage>1044</fpage>
        <lpage>1053</lpage>
        <?supplied-pmid 32686750?>
        <pub-id pub-id-type="pmid">32686750</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kolmogorov</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>metaflye: scalable long-read metagenome assembly using repeat graphs</article-title>
        <source>Nat. Methods</source>
        <year>2020</year>
        <volume>17</volume>
        <fpage>1103</fpage>
        <lpage>1110</lpage>
        <?supplied-pmid 33020656?>
        <pub-id pub-id-type="pmid">33020656</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Miga</surname>
            <given-names>KH</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Telomere-to-telomere assembly of a complete human x chromosome</article-title>
        <source>Nature</source>
        <year>2020</year>
        <volume>585</volume>
        <fpage>79</fpage>
        <lpage>84</lpage>
        <?supplied-pmid 32663838?>
        <pub-id pub-id-type="pmid">32663838</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Edge</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Bansal</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Longshot enables accurate variant calling in diploid genomes from single-molecule long read sequencing</article-title>
        <source>Nat. Commun.</source>
        <year>2019</year>
        <volume>10</volume>
        <fpage>1</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="pmid">30602773</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thibodeau</surname>
            <given-names>ML</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Improved structural variant interpretation for hereditary cancer susceptibility using long-read sequencing</article-title>
        <source>Genetics Med.</source>
        <year>2020</year>
        <volume>22</volume>
        <fpage>1892</fpage>
        <lpage>1897</lpage>
        <pub-id pub-id-type="pmid">32624572</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fujimoto</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Whole-genome sequencing with long reads reveals complex structure and origin of structural variation in human genetic variations and somatic mutations in cancer</article-title>
        <source>Genome Med.</source>
        <year>2021</year>
        <volume>13</volume>
        <fpage>1</fpage>
        <lpage>15</lpage>
        <pub-id pub-id-type="pmid">33397400</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hackl</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Hedrich</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Schultz</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Förster</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>proovread: large-scale high-accuracy pacbio correction through iterative short read consensus</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <fpage>3004</fpage>
        <lpage>3011</lpage>
        <?supplied-pmid 25015988?>
        <pub-id pub-id-type="pmid">25015988</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Salmela</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Rivals</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Lordec: accurate and efficient long read error correction</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <fpage>3506</fpage>
        <lpage>3514</lpage>
        <?supplied-pmid 25165095?>
        <pub-id pub-id-type="pmid">25165095</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Firtina</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Bar-Joseph</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Alkan</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Cicek</surname>
            <given-names>AE</given-names>
          </name>
        </person-group>
        <article-title>Hercules: a profile hmm-based hybrid error correction algorithm for long reads</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2018</year>
        <volume>46</volume>
        <fpage>e125</fpage>
        <lpage>e125</lpage>
        <?supplied-pmid 30124947?>
        <pub-id pub-id-type="pmid">30124947</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Morisse</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Lecroq</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Lefebvre</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Hybrid correction of highly noisy long reads using a variable-order de bruijn graph</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <fpage>4213</fpage>
        <lpage>4222</lpage>
        <?supplied-pmid 29955770?>
        <pub-id pub-id-type="pmid">29955770</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vaser</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Sović</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Nagarajan</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Šikić</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Fast and accurate de novo genome assembly from long uncorrected reads</article-title>
        <source>Genome Res.</source>
        <year>2017</year>
        <volume>27</volume>
        <fpage>737</fpage>
        <lpage>746</lpage>
        <?supplied-pmid 28100585?>
        <pub-id pub-id-type="pmid">28100585</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Koren</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Canu: scalable and accurate long-read assembly via adaptive k-mer weighting and repeat separation</article-title>
        <source>Genome Res.</source>
        <year>2017</year>
        <volume>27</volume>
        <fpage>722</fpage>
        <lpage>736</lpage>
        <?supplied-pmid 28298431?>
        <pub-id pub-id-type="pmid">28298431</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bao</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Xie</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Flas: fast and high-throughput algorithm for pacbio long-read self-correction</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <fpage>3953</fpage>
        <lpage>3960</lpage>
        <?supplied-pmid 30895306?>
        <pub-id pub-id-type="pmid">30895306</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Tischler, G. &amp; Myers, E. W. Non hybrid long read consensus using local de bruijn graph assembly. Preprint at <italic>bioRxiv</italic>10.1101/106252 (2017).</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Salmela</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Walve</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Rivals</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Ukkonen</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Accurate self-correction of errors in long reads using de bruijn graphs</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <fpage>799</fpage>
        <lpage>806</lpage>
        <?supplied-pmid 27273673?>
        <pub-id pub-id-type="pmid">27273673</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Morisse</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Marchet</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Limasset</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lecroq</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Lefebvre</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Scalable long read self-correction and assembly polishing with multiple sequence alignment</article-title>
        <source>Scientific reports</source>
        <year>2021</year>
        <volume>11</volume>
        <fpage>1</fpage>
        <lpage>13</lpage>
        <pub-id pub-id-type="pmid">33414495</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luo</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Kang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Schönhuth</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>phasebook: haplotype-aware de novo assembly of diploid genomes from long reads</article-title>
        <source>Genome Biol.</source>
        <year>2021</year>
        <volume>22</volume>
        <fpage>299</fpage>
        <?supplied-pmid 34706745?>
        <pub-id pub-id-type="pmid">34706745</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Paten</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Novak</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Eizenga</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Garrison</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Genome graphs and the evolution of genome inference</article-title>
        <source>Genome Res.</source>
        <year>2017</year>
        <volume>27</volume>
        <fpage>665</fpage>
        <lpage>676</lpage>
        <?supplied-pmid 28360232?>
        <pub-id pub-id-type="pmid">28360232</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Garrison</surname>
            <given-names>E</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Variation graph toolkit improves read mapping by representing genetic variation in the reference</article-title>
        <source>Nat. Biotechnol.</source>
        <year>2018</year>
        <volume>36</volume>
        <fpage>875</fpage>
        <lpage>879</lpage>
        <?supplied-pmid 30125266?>
        <pub-id pub-id-type="pmid">30125266</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Martiniano</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Garrison</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>ER</given-names>
          </name>
          <name>
            <surname>Manica</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Durbin</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Removing reference bias and improving indel calling in ancient dna data analysis by mapping to a sequence variation graph</article-title>
        <source>Genome Biol.</source>
        <year>2020</year>
        <volume>21</volume>
        <fpage>1</fpage>
        <lpage>18</lpage>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sirén</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Pangenomics enables genotyping of known structural variants in 5202 diverse genomes</article-title>
        <source>Science</source>
        <year>2021</year>
        <volume>374</volume>
        <fpage>abg8871</fpage>
        <?supplied-pmid 34914532?>
        <pub-id pub-id-type="pmid">34914532</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rosen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Eizenga</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Paten</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Modelling haplotypes with respect to reference cohort variation graphs</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <fpage>i118</fpage>
        <lpage>i123</lpage>
        <?supplied-pmid 28881971?>
        <pub-id pub-id-type="pmid">28881971</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baaijens</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Van der Roest</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Köster</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Stougie</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Schönhuth</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Full-length de novo viral quasispecies assembly through variation graph construction</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <fpage>5086</fpage>
        <lpage>5094</lpage>
        <?supplied-pmid 31147688?>
        <pub-id pub-id-type="pmid">31147688</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Baaijens, J. A., Stougie, L. &amp; Schönhuth, A. Strain-aware assembly of genomes from mixed samples using flow variation graphs. In <italic>Proc International Conference on Research in Computational Molecular Biology</italic>, 221–222 (Springer, 2020).</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Minimap2: pairwise alignment for nucleotide sequences</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <fpage>3094</fpage>
        <lpage>3100</lpage>
        <?supplied-pmid 29750242?>
        <pub-id pub-id-type="pmid">29750242</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Grasso</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Sharlow</surname>
            <given-names>MF</given-names>
          </name>
        </person-group>
        <article-title>Multiple sequence alignment using partial order graphs</article-title>
        <source>Bioinformatics</source>
        <year>2002</year>
        <volume>18</volume>
        <fpage>452</fpage>
        <lpage>464</lpage>
        <?supplied-pmid 11934745?>
        <pub-id pub-id-type="pmid">11934745</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Generating consensus sequences from partial order multiple sequence alignment graphs</article-title>
        <source>Bioinformatics</source>
        <year>2003</year>
        <volume>19</volume>
        <fpage>999</fpage>
        <lpage>1008</lpage>
        <?supplied-pmid 12761063?>
        <pub-id pub-id-type="pmid">12761063</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rhie</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Walenz</surname>
            <given-names>BP</given-names>
          </name>
          <name>
            <surname>Koren</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Phillippy</surname>
            <given-names>AM</given-names>
          </name>
        </person-group>
        <article-title>Merqury: reference-free quality, completeness, and phasing assessment for genome assemblies</article-title>
        <source>Genome Biol.</source>
        <year>2020</year>
        <volume>21</volume>
        <fpage>1</fpage>
        <lpage>27</lpage>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Giallonardo</surname>
            <given-names>FD</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Full-length haplotype reconstruction to infer the structure of heterogeneous virus populations</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2014</year>
        <volume>42</volume>
        <fpage>e115</fpage>
        <lpage>e115</lpage>
        <?supplied-pmid 24972832?>
        <pub-id pub-id-type="pmid">24972832</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baaijens</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>El Aabidine</surname>
            <given-names>AZ</given-names>
          </name>
          <name>
            <surname>Rivals</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Schönhuth</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>De novo assembly of viral quasispecies using overlap graphs</article-title>
        <source>Genome Res.</source>
        <year>2017</year>
        <volume>27</volume>
        <fpage>835</fpage>
        <lpage>848</lpage>
        <?supplied-pmid 28396522?>
        <pub-id pub-id-type="pmid">28396522</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luo</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Kang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Schönhuth</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Strainline: full-length de novo viral haplotype reconstruction from noisy long reads</article-title>
        <source>Genome Biol.</source>
        <year>2022</year>
        <volume>23</volume>
        <fpage>1</fpage>
        <lpage>27</lpage>
        <pub-id pub-id-type="pmid">34980209</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nurk</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Hicanu: accurate assembly of segmental duplications, satellites, and allelic variants from high-fidelity long reads</article-title>
        <source>Genome Res.</source>
        <year>2020</year>
        <volume>30</volume>
        <fpage>1291</fpage>
        <lpage>1305</lpage>
        <?supplied-pmid 32801147?>
        <pub-id pub-id-type="pmid">32801147</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kolmogorov</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Pevzner</surname>
            <given-names>PA</given-names>
          </name>
        </person-group>
        <article-title>Assembly of long, error-prone reads using repeat graphs</article-title>
        <source>Nat. Biotechnol.</source>
        <year>2019</year>
        <volume>37</volume>
        <fpage>540</fpage>
        <lpage>546</lpage>
        <?supplied-pmid 30936562?>
        <pub-id pub-id-type="pmid">30936562</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ono</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Asai</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Hamada</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Pbsim2: a simulator for long-read sequencers with a novel generative model of quality scores</article-title>
        <source>Bioinformatics</source>
        <year>2021</year>
        <volume>37</volume>
        <fpage>589</fpage>
        <lpage>595</lpage>
        <?supplied-pmid 32976553?>
        <pub-id pub-id-type="pmid">32976553</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jain</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Rodriguez-R</surname>
            <given-names>LM</given-names>
          </name>
          <name>
            <surname>Phillippy</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Konstantinidis</surname>
            <given-names>KT</given-names>
          </name>
          <name>
            <surname>Aluru</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>High throughput ani analysis of 90k prokaryotic genomes reveals clear species boundaries</article-title>
        <source>Nat. Commun.</source>
        <year>2018</year>
        <volume>9</volume>
        <fpage>1</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="pmid">29317637</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fritz</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Camisim: simulating metagenomes and microbial communities</article-title>
        <source>Microbiome</source>
        <year>2019</year>
        <volume>7</volume>
        <fpage>1</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="pmid">30606251</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Quince</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Desman: a new tool for de novo extraction of strains from metagenomes</article-title>
        <source>Genome Biol.</source>
        <year>2017</year>
        <volume>18</volume>
        <fpage>1</fpage>
        <lpage>22</lpage>
        <pub-id pub-id-type="pmid">28077169</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Somerville</surname>
            <given-names>V</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Long-read based de novo assembly of low-complexity metagenome samples results in finished genomes and reveals insights into strain diversity and an active phage system</article-title>
        <source>BMC Microbiol.</source>
        <year>2019</year>
        <volume>19</volume>
        <fpage>1</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="pmid">30616583</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Gu</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>fastp: an ultra-fast all-in-one fastq preprocessor</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <fpage>i884</fpage>
        <lpage>i890</lpage>
        <?supplied-pmid 30423086?>
        <pub-id pub-id-type="pmid">30423086</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Moss</surname>
            <given-names>EL</given-names>
          </name>
          <name>
            <surname>Maghini</surname>
            <given-names>DG</given-names>
          </name>
          <name>
            <surname>Bhatt</surname>
            <given-names>AS</given-names>
          </name>
        </person-group>
        <article-title>Complete, closed bacterial genomes from microbiomes using nanopore sequencing</article-title>
        <source>Nat. Biotechnol.</source>
        <year>2020</year>
        <volume>38</volume>
        <fpage>701</fpage>
        <lpage>707</lpage>
        <?supplied-pmid 32042169?>
        <pub-id pub-id-type="pmid">32042169</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bishara</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>High-quality genome sequences of uncultured microbes by assembly of read clouds</article-title>
        <source>Nat. Biotechnol.</source>
        <year>2018</year>
        <volume>36</volume>
        <fpage>1067</fpage>
        <lpage>1075</lpage>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Minimap and miniasm: fast mapping and de novo assembly for noisy long sequences</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <fpage>2103</fpage>
        <lpage>2110</lpage>
        <?supplied-pmid 27153593?>
        <pub-id pub-id-type="pmid">27153593</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Marijon</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Chikhi</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Varré</surname>
            <given-names>J-S</given-names>
          </name>
        </person-group>
        <article-title>yacrd and fpa: upstream tools for long-read genome assembly</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <fpage>3894</fpage>
        <lpage>3896</lpage>
        <?supplied-pmid 32315402?>
        <pub-id pub-id-type="pmid">32315402</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Myers</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>A fast bit-vector algorithm for approximate string matching based on dynamic programming</article-title>
        <source>J. ACM</source>
        <year>1999</year>
        <volume>46</volume>
        <fpage>395</fpage>
        <lpage>415</lpage>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Šošić</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Šikić</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Edlib: a c/c++ library for fast, exact sequence alignment using edit distance</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <fpage>1394</fpage>
        <lpage>1395</lpage>
        <?supplied-pmid 28453688?>
        <pub-id pub-id-type="pmid">28453688</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mikheenko</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Prjibelski</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Saveliev</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Antipov</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Gurevich</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Versatile genome assembly evaluation with quast-lg</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <fpage>i142</fpage>
        <lpage>i150</lpage>
        <?supplied-pmid 29949969?>
        <pub-id pub-id-type="pmid">29949969</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rhie</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Towards complete and error-free genome assemblies of all vertebrate species</article-title>
        <source>Nature</source>
        <year>2021</year>
        <volume>592</volume>
        <fpage>737</fpage>
        <lpage>746</lpage>
        <?supplied-pmid 33911273?>
        <pub-id pub-id-type="pmid">33911273</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <mixed-citation publication-type="other">Luo, X., Kang, X. &amp; Schönhuth, A. Enhancing long-read-based strain-aware metagenome assembly. <italic>Front. Genet.</italic><bold>13</bold> 868280 (2022).</mixed-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <mixed-citation publication-type="other">Luo, X., Kang, X. &amp; Schönhuth, A. Raw sequencing data used in benchmarking result. <italic>Zenodo</italic>. 10.5281/zenodo.5501455 (2021).</mixed-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <mixed-citation publication-type="other">Luo, X., Kang, X. &amp; Schönhuth, A. Code and environment for reproducing results. <italic>Code Ocean.</italic>10.24433/CO.2329278.v2 (2021).</mixed-citation>
    </ref>
  </ref-list>
</back>
